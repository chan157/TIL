{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.데이터셋 생성하기\n",
    "(xTrain,yTrain),(xTest,yTest)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=xTrain.reshape(60000,784).astype('float32')/255.0\n",
    "xTest=xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain\n",
    "yTrain=np_utils.to_categorical(yTrain)\n",
    "yTest=np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 모델 구성\n",
    "model=Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 모델 학습과정 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_4 to have shape (10,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e4934de8b351>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#4. 모델 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_4 to have shape (10,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "#4. 모델 학습\n",
    "hist=model.fit(xTrain, yTrain, epochs=5, batch_size=32)\n",
    "#batch_size:몇개의 샘플로 가중치를 갱신할것인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.300696055730184, 2.3001652893066407, 2.2998135913848876, 2.299497727839152, 2.2991317680358887]\n",
      "[0.11421666, 0.11236667, 0.11236667, 0.11236667, 0.11236667]\n"
     ]
    }
   ],
   "source": [
    "print(hist.history['loss'])\n",
    "print(hist.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 20us/step\n",
      "[2.124321017074585, 0.30070000886917114]\n"
     ]
    }
   ],
   "source": [
    "#6. 모델 평가\n",
    "res=model.evaluate(xTest, yTest, batch_size=32)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11023965 0.10862794 0.10155054 0.06691364 0.16018663 0.05072782\n",
      "  0.06391407 0.13546948 0.09696775 0.10540249]]\n"
     ]
    }
   ],
   "source": [
    "#모델 예측\n",
    "xhat=xTest[0:1]\n",
    "yhat=model.predict(xhat)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain,yTrain),(xTest,yTest)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal=xTrain[50000:]\n",
    "yVal=yTrain[50000:]\n",
    "xTrain=xTrain[:50000]\n",
    "yTrain=yTrain[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=xTrain.reshape(50000,784).astype('float32')/255.0\n",
    "xVal=xVal.reshape(10000,784).astype('float32')/255.0\n",
    "xTest=xTest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련, 검증 데이터 선택\n",
    "tri=np.random.choice(50000,700)\n",
    "vri=np.random.choice(10000,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain=xTrain[tri] #700건\n",
    "yTrain=yTrain[tri]\n",
    "xVal=xVal[vri]  #300건\n",
    "yVal=yVal[vri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain=np_utils.to_categorical(yTrain)\n",
    "yVal=np_utils.to_categorical(yVal)\n",
    "yTest=np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(input_dim=28*28,units=2,activation='relu'))\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 206us/step - loss: 2.2598 - accuracy: 0.1586 - val_loss: 2.1913 - val_accuracy: 0.2467\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 2.1648 - accuracy: 0.2129 - val_loss: 2.1128 - val_accuracy: 0.2767\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 2.0967 - accuracy: 0.2286 - val_loss: 2.0536 - val_accuracy: 0.2533\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 2.0443 - accuracy: 0.2357 - val_loss: 2.0035 - val_accuracy: 0.2567\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.9968 - accuracy: 0.2414 - val_loss: 1.9612 - val_accuracy: 0.2500\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.9563 - accuracy: 0.2614 - val_loss: 1.9214 - val_accuracy: 0.2467\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.9196 - accuracy: 0.2557 - val_loss: 1.8882 - val_accuracy: 0.2767\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8866 - accuracy: 0.2614 - val_loss: 1.8604 - val_accuracy: 0.2767\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.8570 - accuracy: 0.2886 - val_loss: 1.8306 - val_accuracy: 0.2867\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8304 - accuracy: 0.2757 - val_loss: 1.8068 - val_accuracy: 0.2800\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.8043 - accuracy: 0.2957 - val_loss: 1.7853 - val_accuracy: 0.2733\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.7813 - accuracy: 0.2914 - val_loss: 1.7649 - val_accuracy: 0.2933\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.7609 - accuracy: 0.3200 - val_loss: 1.7457 - val_accuracy: 0.2733\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.7406 - accuracy: 0.3257 - val_loss: 1.7327 - val_accuracy: 0.3000\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.7229 - accuracy: 0.3443 - val_loss: 1.7121 - val_accuracy: 0.2900\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.7063 - accuracy: 0.3514 - val_loss: 1.7005 - val_accuracy: 0.3833\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6902 - accuracy: 0.3771 - val_loss: 1.6851 - val_accuracy: 0.3767\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6743 - accuracy: 0.3886 - val_loss: 1.6752 - val_accuracy: 0.3967\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6596 - accuracy: 0.4043 - val_loss: 1.6582 - val_accuracy: 0.3967\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6464 - accuracy: 0.4086 - val_loss: 1.6487 - val_accuracy: 0.4200\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6324 - accuracy: 0.4229 - val_loss: 1.6374 - val_accuracy: 0.4033\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.6184 - accuracy: 0.4143 - val_loss: 1.6274 - val_accuracy: 0.4100\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6088 - accuracy: 0.4300 - val_loss: 1.6155 - val_accuracy: 0.4333\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5959 - accuracy: 0.4400 - val_loss: 1.6114 - val_accuracy: 0.4133\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.5851 - accuracy: 0.4400 - val_loss: 1.5972 - val_accuracy: 0.4400\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5739 - accuracy: 0.4529 - val_loss: 1.5861 - val_accuracy: 0.4300\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5638 - accuracy: 0.4514 - val_loss: 1.5811 - val_accuracy: 0.4333\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5524 - accuracy: 0.4557 - val_loss: 1.5702 - val_accuracy: 0.4567\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5430 - accuracy: 0.4486 - val_loss: 1.5660 - val_accuracy: 0.4700\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5318 - accuracy: 0.4729 - val_loss: 1.5631 - val_accuracy: 0.4633\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.5236 - accuracy: 0.4757 - val_loss: 1.5445 - val_accuracy: 0.4533\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5146 - accuracy: 0.4743 - val_loss: 1.5366 - val_accuracy: 0.4600\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5043 - accuracy: 0.4771 - val_loss: 1.5314 - val_accuracy: 0.4633\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.4950 - accuracy: 0.4771 - val_loss: 1.5221 - val_accuracy: 0.4633\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4868 - accuracy: 0.4943 - val_loss: 1.5128 - val_accuracy: 0.4733\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4772 - accuracy: 0.4814 - val_loss: 1.5058 - val_accuracy: 0.4700\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4689 - accuracy: 0.4871 - val_loss: 1.5032 - val_accuracy: 0.4767\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4604 - accuracy: 0.4914 - val_loss: 1.4912 - val_accuracy: 0.4600\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4524 - accuracy: 0.4871 - val_loss: 1.4887 - val_accuracy: 0.4800\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4435 - accuracy: 0.4871 - val_loss: 1.4889 - val_accuracy: 0.4733\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4364 - accuracy: 0.5000 - val_loss: 1.4748 - val_accuracy: 0.4900\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.4271 - accuracy: 0.5086 - val_loss: 1.4647 - val_accuracy: 0.4633\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.4207 - accuracy: 0.4986 - val_loss: 1.4592 - val_accuracy: 0.4767\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.4120 - accuracy: 0.5029 - val_loss: 1.4625 - val_accuracy: 0.4767\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.4018 - accuracy: 0.5057 - val_loss: 1.4544 - val_accuracy: 0.4667\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.3965 - accuracy: 0.4914 - val_loss: 1.4531 - val_accuracy: 0.4933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3877 - accuracy: 0.5057 - val_loss: 1.4456 - val_accuracy: 0.5000\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3807 - accuracy: 0.5200 - val_loss: 1.4435 - val_accuracy: 0.4767\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3731 - accuracy: 0.5171 - val_loss: 1.4287 - val_accuracy: 0.4767\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3657 - accuracy: 0.4943 - val_loss: 1.4276 - val_accuracy: 0.4800\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3589 - accuracy: 0.5100 - val_loss: 1.4219 - val_accuracy: 0.4800\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3500 - accuracy: 0.5243 - val_loss: 1.4146 - val_accuracy: 0.4533\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.3420 - accuracy: 0.5100 - val_loss: 1.4130 - val_accuracy: 0.4600\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.3373 - accuracy: 0.5157 - val_loss: 1.4082 - val_accuracy: 0.4933\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3256 - accuracy: 0.5157 - val_loss: 1.4210 - val_accuracy: 0.5000\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3233 - accuracy: 0.5271 - val_loss: 1.4029 - val_accuracy: 0.4967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3165 - accuracy: 0.5171 - val_loss: 1.3996 - val_accuracy: 0.5100\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.3075 - accuracy: 0.5429 - val_loss: 1.3951 - val_accuracy: 0.4900\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.3032 - accuracy: 0.5371 - val_loss: 1.3907 - val_accuracy: 0.5133\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2955 - accuracy: 0.5414 - val_loss: 1.3827 - val_accuracy: 0.4967\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.2893 - accuracy: 0.5386 - val_loss: 1.3795 - val_accuracy: 0.4967\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2825 - accuracy: 0.5371 - val_loss: 1.3829 - val_accuracy: 0.4767\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2754 - accuracy: 0.5329 - val_loss: 1.3806 - val_accuracy: 0.5100\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2702 - accuracy: 0.5471 - val_loss: 1.3757 - val_accuracy: 0.5167\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2647 - accuracy: 0.5614 - val_loss: 1.3689 - val_accuracy: 0.5067\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2567 - accuracy: 0.5371 - val_loss: 1.3765 - val_accuracy: 0.5100\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2541 - accuracy: 0.5571 - val_loss: 1.3654 - val_accuracy: 0.5067\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2465 - accuracy: 0.5557 - val_loss: 1.3719 - val_accuracy: 0.5167\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2403 - accuracy: 0.5543 - val_loss: 1.3661 - val_accuracy: 0.5200\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2343 - accuracy: 0.5786 - val_loss: 1.3623 - val_accuracy: 0.4967\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.2334 - accuracy: 0.5586 - val_loss: 1.3597 - val_accuracy: 0.5100\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2253 - accuracy: 0.5757 - val_loss: 1.3598 - val_accuracy: 0.5100\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.2209 - accuracy: 0.5557 - val_loss: 1.3539 - val_accuracy: 0.5267\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2135 - accuracy: 0.5514 - val_loss: 1.3535 - val_accuracy: 0.5333\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.2096 - accuracy: 0.5657 - val_loss: 1.3555 - val_accuracy: 0.5133\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.2045 - accuracy: 0.5643 - val_loss: 1.3494 - val_accuracy: 0.5400\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.1999 - accuracy: 0.5657 - val_loss: 1.3526 - val_accuracy: 0.5067\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1952 - accuracy: 0.5686 - val_loss: 1.3478 - val_accuracy: 0.5233\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.1915 - accuracy: 0.5743 - val_loss: 1.3440 - val_accuracy: 0.5367\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.1851 - accuracy: 0.5671 - val_loss: 1.3510 - val_accuracy: 0.5167\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.1805 - accuracy: 0.5657 - val_loss: 1.3509 - val_accuracy: 0.5033\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1768 - accuracy: 0.5729 - val_loss: 1.3422 - val_accuracy: 0.5300\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1728 - accuracy: 0.5686 - val_loss: 1.3453 - val_accuracy: 0.5167\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.1701 - accuracy: 0.5686 - val_loss: 1.3431 - val_accuracy: 0.5300\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1655 - accuracy: 0.5757 - val_loss: 1.3394 - val_accuracy: 0.5233\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1592 - accuracy: 0.5857 - val_loss: 1.3378 - val_accuracy: 0.5167\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.1551 - accuracy: 0.5700 - val_loss: 1.3444 - val_accuracy: 0.5300\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.1518 - accuracy: 0.5843 - val_loss: 1.3460 - val_accuracy: 0.5367\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.1479 - accuracy: 0.5871 - val_loss: 1.3387 - val_accuracy: 0.5267\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.1447 - accuracy: 0.5900 - val_loss: 1.3350 - val_accuracy: 0.5333\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1429 - accuracy: 0.5814 - val_loss: 1.3379 - val_accuracy: 0.5333\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.1389 - accuracy: 0.5900 - val_loss: 1.3389 - val_accuracy: 0.5233\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.1352 - accuracy: 0.5914 - val_loss: 1.3403 - val_accuracy: 0.5233\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1303 - accuracy: 0.5914 - val_loss: 1.3381 - val_accuracy: 0.5200\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1274 - accuracy: 0.5700 - val_loss: 1.3372 - val_accuracy: 0.5233\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1247 - accuracy: 0.5914 - val_loss: 1.3347 - val_accuracy: 0.5267\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1197 - accuracy: 0.6000 - val_loss: 1.3341 - val_accuracy: 0.5300\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1171 - accuracy: 0.5900 - val_loss: 1.3408 - val_accuracy: 0.5267\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1145 - accuracy: 0.5814 - val_loss: 1.3351 - val_accuracy: 0.5300\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1116 - accuracy: 0.5971 - val_loss: 1.3381 - val_accuracy: 0.5133\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.1048 - accuracy: 0.5943 - val_loss: 1.3315 - val_accuracy: 0.5400\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.1043 - accuracy: 0.5957 - val_loss: 1.3382 - val_accuracy: 0.5367\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.0990 - accuracy: 0.5900 - val_loss: 1.3307 - val_accuracy: 0.5367\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.0999 - accuracy: 0.6014 - val_loss: 1.3339 - val_accuracy: 0.5233\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.0945 - accuracy: 0.6029 - val_loss: 1.3318 - val_accuracy: 0.5400\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.0889 - accuracy: 0.6100 - val_loss: 1.3345 - val_accuracy: 0.5267\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0898 - accuracy: 0.5929 - val_loss: 1.3345 - val_accuracy: 0.5267\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0858 - accuracy: 0.6129 - val_loss: 1.3383 - val_accuracy: 0.5367\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0842 - accuracy: 0.5986 - val_loss: 1.3333 - val_accuracy: 0.5300\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.0787 - accuracy: 0.6157 - val_loss: 1.3354 - val_accuracy: 0.5300\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.0789 - accuracy: 0.6129 - val_loss: 1.3362 - val_accuracy: 0.5267\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.0748 - accuracy: 0.6100 - val_loss: 1.3324 - val_accuracy: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.0709 - accuracy: 0.6071 - val_loss: 1.3345 - val_accuracy: 0.5233\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.0683 - accuracy: 0.6043 - val_loss: 1.3374 - val_accuracy: 0.5267\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.0647 - accuracy: 0.6057 - val_loss: 1.3391 - val_accuracy: 0.5200\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0642 - accuracy: 0.6129 - val_loss: 1.3327 - val_accuracy: 0.5167\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0582 - accuracy: 0.6243 - val_loss: 1.3402 - val_accuracy: 0.5167\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.0588 - accuracy: 0.6143 - val_loss: 1.3396 - val_accuracy: 0.5167\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.0553 - accuracy: 0.6243 - val_loss: 1.3339 - val_accuracy: 0.5200\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.0528 - accuracy: 0.6129 - val_loss: 1.3404 - val_accuracy: 0.5233\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.0495 - accuracy: 0.6171 - val_loss: 1.3366 - val_accuracy: 0.5233\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 1.0476 - accuracy: 0.6257 - val_loss: 1.3349 - val_accuracy: 0.5167\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.0435 - accuracy: 0.6257 - val_loss: 1.3441 - val_accuracy: 0.5133\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.0451 - accuracy: 0.6229 - val_loss: 1.3411 - val_accuracy: 0.5133\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.0371 - accuracy: 0.6286 - val_loss: 1.3295 - val_accuracy: 0.5300\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.0380 - accuracy: 0.6243 - val_loss: 1.3359 - val_accuracy: 0.5167\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.0347 - accuracy: 0.6271 - val_loss: 1.3420 - val_accuracy: 0.5133\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.0330 - accuracy: 0.6314 - val_loss: 1.3400 - val_accuracy: 0.5100\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.0291 - accuracy: 0.6300 - val_loss: 1.3453 - val_accuracy: 0.5233\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.0289 - accuracy: 0.6229 - val_loss: 1.3386 - val_accuracy: 0.5200\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0261 - accuracy: 0.6229 - val_loss: 1.3365 - val_accuracy: 0.5200\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.0268 - accuracy: 0.6300 - val_loss: 1.3354 - val_accuracy: 0.5367\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0205 - accuracy: 0.6329 - val_loss: 1.3340 - val_accuracy: 0.5100\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.0205 - accuracy: 0.6314 - val_loss: 1.3369 - val_accuracy: 0.5400\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0172 - accuracy: 0.6257 - val_loss: 1.3359 - val_accuracy: 0.5067\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.0156 - accuracy: 0.6371 - val_loss: 1.3354 - val_accuracy: 0.5233\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0140 - accuracy: 0.6329 - val_loss: 1.3359 - val_accuracy: 0.5300\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0101 - accuracy: 0.6343 - val_loss: 1.3369 - val_accuracy: 0.5100\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.0083 - accuracy: 0.6414 - val_loss: 1.3397 - val_accuracy: 0.5300\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0044 - accuracy: 0.6357 - val_loss: 1.3494 - val_accuracy: 0.5133\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.0034 - accuracy: 0.6429 - val_loss: 1.3369 - val_accuracy: 0.5067\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0048 - accuracy: 0.6443 - val_loss: 1.3410 - val_accuracy: 0.5167\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.0017 - accuracy: 0.6500 - val_loss: 1.3382 - val_accuracy: 0.5300\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.9969 - accuracy: 0.6386 - val_loss: 1.3450 - val_accuracy: 0.5100\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.9941 - accuracy: 0.6514 - val_loss: 1.3414 - val_accuracy: 0.5267\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.9935 - accuracy: 0.6471 - val_loss: 1.3456 - val_accuracy: 0.5133\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.9901 - accuracy: 0.6343 - val_loss: 1.3440 - val_accuracy: 0.5167\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9904 - accuracy: 0.6486 - val_loss: 1.3447 - val_accuracy: 0.5300\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9884 - accuracy: 0.6514 - val_loss: 1.3414 - val_accuracy: 0.5400\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9862 - accuracy: 0.6457 - val_loss: 1.3450 - val_accuracy: 0.5200\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9852 - accuracy: 0.6557 - val_loss: 1.3440 - val_accuracy: 0.5200\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9849 - accuracy: 0.6514 - val_loss: 1.3437 - val_accuracy: 0.5200\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.9805 - accuracy: 0.6471 - val_loss: 1.3461 - val_accuracy: 0.5133\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.9793 - accuracy: 0.6486 - val_loss: 1.3409 - val_accuracy: 0.5300\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.9772 - accuracy: 0.6371 - val_loss: 1.3470 - val_accuracy: 0.5100\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9769 - accuracy: 0.6571 - val_loss: 1.3462 - val_accuracy: 0.5400\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9734 - accuracy: 0.6529 - val_loss: 1.3517 - val_accuracy: 0.5167\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.9722 - accuracy: 0.6486 - val_loss: 1.3488 - val_accuracy: 0.5233\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.9688 - accuracy: 0.6643 - val_loss: 1.3459 - val_accuracy: 0.5300\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.9688 - accuracy: 0.6600 - val_loss: 1.3454 - val_accuracy: 0.5200\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9666 - accuracy: 0.6614 - val_loss: 1.3452 - val_accuracy: 0.5333\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9636 - accuracy: 0.6614 - val_loss: 1.3474 - val_accuracy: 0.5200\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9650 - accuracy: 0.6529 - val_loss: 1.3468 - val_accuracy: 0.5367\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.9625 - accuracy: 0.6614 - val_loss: 1.3497 - val_accuracy: 0.5233\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9596 - accuracy: 0.6629 - val_loss: 1.3490 - val_accuracy: 0.5267\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9580 - accuracy: 0.6514 - val_loss: 1.3483 - val_accuracy: 0.5333\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9586 - accuracy: 0.6571 - val_loss: 1.3558 - val_accuracy: 0.5200\n",
      "Epoch 168/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 0.9570 - accuracy: 0.6686 - val_loss: 1.3475 - val_accuracy: 0.5367\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9536 - accuracy: 0.6486 - val_loss: 1.3519 - val_accuracy: 0.5133\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9524 - accuracy: 0.6671 - val_loss: 1.3549 - val_accuracy: 0.5167\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9506 - accuracy: 0.6714 - val_loss: 1.3540 - val_accuracy: 0.5200\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9482 - accuracy: 0.6729 - val_loss: 1.3563 - val_accuracy: 0.5200\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9470 - accuracy: 0.6643 - val_loss: 1.3527 - val_accuracy: 0.5300\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9472 - accuracy: 0.6643 - val_loss: 1.3556 - val_accuracy: 0.5300\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9456 - accuracy: 0.6657 - val_loss: 1.3534 - val_accuracy: 0.5333\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9435 - accuracy: 0.6714 - val_loss: 1.3532 - val_accuracy: 0.5333\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9404 - accuracy: 0.6686 - val_loss: 1.3552 - val_accuracy: 0.5333\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9399 - accuracy: 0.6800 - val_loss: 1.3608 - val_accuracy: 0.5167\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9356 - accuracy: 0.6829 - val_loss: 1.3583 - val_accuracy: 0.5233\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9362 - accuracy: 0.6743 - val_loss: 1.3649 - val_accuracy: 0.5133\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9347 - accuracy: 0.6786 - val_loss: 1.3578 - val_accuracy: 0.5267\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9328 - accuracy: 0.6686 - val_loss: 1.3528 - val_accuracy: 0.5300\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9305 - accuracy: 0.6629 - val_loss: 1.3606 - val_accuracy: 0.5267\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.9301 - accuracy: 0.6786 - val_loss: 1.3620 - val_accuracy: 0.5300\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.9271 - accuracy: 0.6686 - val_loss: 1.3579 - val_accuracy: 0.5300\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9286 - accuracy: 0.6757 - val_loss: 1.3599 - val_accuracy: 0.5467\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9252 - accuracy: 0.6743 - val_loss: 1.3650 - val_accuracy: 0.5333\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9230 - accuracy: 0.6857 - val_loss: 1.3634 - val_accuracy: 0.5400\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.9219 - accuracy: 0.6886 - val_loss: 1.3618 - val_accuracy: 0.5333\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9208 - accuracy: 0.6814 - val_loss: 1.3611 - val_accuracy: 0.5400\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9205 - accuracy: 0.6743 - val_loss: 1.3635 - val_accuracy: 0.5300\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9168 - accuracy: 0.6671 - val_loss: 1.3640 - val_accuracy: 0.5300\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.9162 - accuracy: 0.6843 - val_loss: 1.3609 - val_accuracy: 0.5367\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.9140 - accuracy: 0.6714 - val_loss: 1.3688 - val_accuracy: 0.5233\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.9126 - accuracy: 0.6871 - val_loss: 1.3646 - val_accuracy: 0.5400\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.9106 - accuracy: 0.6771 - val_loss: 1.3608 - val_accuracy: 0.5367\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.9111 - accuracy: 0.6857 - val_loss: 1.3638 - val_accuracy: 0.5300\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9077 - accuracy: 0.6900 - val_loss: 1.3609 - val_accuracy: 0.5367\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.9052 - accuracy: 0.6800 - val_loss: 1.3670 - val_accuracy: 0.5267\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9063 - accuracy: 0.6871 - val_loss: 1.3731 - val_accuracy: 0.5433\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.9034 - accuracy: 0.6871 - val_loss: 1.3691 - val_accuracy: 0.5300\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.9036 - accuracy: 0.6871 - val_loss: 1.3631 - val_accuracy: 0.5233\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.8993 - accuracy: 0.6786 - val_loss: 1.3654 - val_accuracy: 0.5300\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8992 - accuracy: 0.6971 - val_loss: 1.3676 - val_accuracy: 0.5300\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8978 - accuracy: 0.6914 - val_loss: 1.3686 - val_accuracy: 0.5267\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.8971 - accuracy: 0.6871 - val_loss: 1.3630 - val_accuracy: 0.5233\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8947 - accuracy: 0.6929 - val_loss: 1.3695 - val_accuracy: 0.5300\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8938 - accuracy: 0.6914 - val_loss: 1.3671 - val_accuracy: 0.5333\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8910 - accuracy: 0.6929 - val_loss: 1.3692 - val_accuracy: 0.5233\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8909 - accuracy: 0.6886 - val_loss: 1.3672 - val_accuracy: 0.5333\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8879 - accuracy: 0.6871 - val_loss: 1.3731 - val_accuracy: 0.5267\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.8871 - accuracy: 0.6971 - val_loss: 1.3698 - val_accuracy: 0.5233\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8842 - accuracy: 0.6957 - val_loss: 1.3643 - val_accuracy: 0.5367\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8827 - accuracy: 0.7000 - val_loss: 1.3671 - val_accuracy: 0.5367\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.8808 - accuracy: 0.7029 - val_loss: 1.3702 - val_accuracy: 0.5233\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8798 - accuracy: 0.6929 - val_loss: 1.3667 - val_accuracy: 0.5233\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8754 - accuracy: 0.7029 - val_loss: 1.3644 - val_accuracy: 0.5333\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.8766 - accuracy: 0.7043 - val_loss: 1.3647 - val_accuracy: 0.5367\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.8753 - accuracy: 0.7043 - val_loss: 1.3636 - val_accuracy: 0.5400\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8709 - accuracy: 0.7100 - val_loss: 1.3702 - val_accuracy: 0.5300\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8709 - accuracy: 0.6986 - val_loss: 1.3701 - val_accuracy: 0.5433\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8691 - accuracy: 0.7100 - val_loss: 1.3692 - val_accuracy: 0.5333\n",
      "Epoch 223/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 101us/step - loss: 0.8681 - accuracy: 0.7086 - val_loss: 1.3641 - val_accuracy: 0.5500\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8673 - accuracy: 0.7186 - val_loss: 1.3609 - val_accuracy: 0.5467\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8636 - accuracy: 0.7114 - val_loss: 1.3674 - val_accuracy: 0.5400\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8643 - accuracy: 0.7086 - val_loss: 1.3649 - val_accuracy: 0.5400\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8644 - accuracy: 0.7071 - val_loss: 1.3667 - val_accuracy: 0.5367\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8608 - accuracy: 0.7143 - val_loss: 1.3710 - val_accuracy: 0.5367\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8569 - accuracy: 0.7214 - val_loss: 1.3686 - val_accuracy: 0.5400\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8583 - accuracy: 0.7157 - val_loss: 1.3642 - val_accuracy: 0.5467\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8559 - accuracy: 0.7186 - val_loss: 1.3649 - val_accuracy: 0.5367\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8531 - accuracy: 0.7086 - val_loss: 1.3693 - val_accuracy: 0.5433\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8507 - accuracy: 0.7314 - val_loss: 1.3699 - val_accuracy: 0.5433\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8531 - accuracy: 0.7286 - val_loss: 1.3646 - val_accuracy: 0.5433\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.8496 - accuracy: 0.7214 - val_loss: 1.3725 - val_accuracy: 0.5500\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.8479 - accuracy: 0.7271 - val_loss: 1.3633 - val_accuracy: 0.5500\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.8459 - accuracy: 0.7343 - val_loss: 1.3716 - val_accuracy: 0.5467\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.8443 - accuracy: 0.7186 - val_loss: 1.3691 - val_accuracy: 0.5400\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.8444 - accuracy: 0.7186 - val_loss: 1.3652 - val_accuracy: 0.5533\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8417 - accuracy: 0.7214 - val_loss: 1.3628 - val_accuracy: 0.5533\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8396 - accuracy: 0.7386 - val_loss: 1.3655 - val_accuracy: 0.5500\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8375 - accuracy: 0.7257 - val_loss: 1.3644 - val_accuracy: 0.5467\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.8366 - accuracy: 0.7357 - val_loss: 1.3687 - val_accuracy: 0.5500\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8346 - accuracy: 0.7429 - val_loss: 1.3641 - val_accuracy: 0.5433\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8325 - accuracy: 0.7414 - val_loss: 1.3742 - val_accuracy: 0.5500\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8293 - accuracy: 0.7386 - val_loss: 1.3712 - val_accuracy: 0.5433\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.8300 - accuracy: 0.7314 - val_loss: 1.3692 - val_accuracy: 0.5367\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8301 - accuracy: 0.7414 - val_loss: 1.3717 - val_accuracy: 0.5400\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8255 - accuracy: 0.7357 - val_loss: 1.3734 - val_accuracy: 0.5367\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8258 - accuracy: 0.7386 - val_loss: 1.3778 - val_accuracy: 0.5433\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.8227 - accuracy: 0.7443 - val_loss: 1.3851 - val_accuracy: 0.5467\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.8251 - accuracy: 0.7443 - val_loss: 1.3681 - val_accuracy: 0.5467\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.8181 - accuracy: 0.7386 - val_loss: 1.3898 - val_accuracy: 0.5467\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8203 - accuracy: 0.7414 - val_loss: 1.3728 - val_accuracy: 0.5500\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.8176 - accuracy: 0.7414 - val_loss: 1.3689 - val_accuracy: 0.5433\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8155 - accuracy: 0.7414 - val_loss: 1.3708 - val_accuracy: 0.5533\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8148 - accuracy: 0.7486 - val_loss: 1.3738 - val_accuracy: 0.5433\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.8127 - accuracy: 0.7414 - val_loss: 1.3693 - val_accuracy: 0.5367\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8132 - accuracy: 0.7400 - val_loss: 1.3701 - val_accuracy: 0.5500\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8088 - accuracy: 0.7543 - val_loss: 1.3686 - val_accuracy: 0.5500\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8077 - accuracy: 0.7400 - val_loss: 1.3838 - val_accuracy: 0.5533\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8055 - accuracy: 0.7529 - val_loss: 1.3880 - val_accuracy: 0.5467\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8055 - accuracy: 0.7443 - val_loss: 1.3773 - val_accuracy: 0.5400\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8033 - accuracy: 0.7486 - val_loss: 1.3662 - val_accuracy: 0.5533\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8021 - accuracy: 0.7529 - val_loss: 1.3686 - val_accuracy: 0.5433\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8007 - accuracy: 0.7600 - val_loss: 1.3686 - val_accuracy: 0.5333\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7999 - accuracy: 0.7471 - val_loss: 1.3692 - val_accuracy: 0.5400\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7987 - accuracy: 0.7500 - val_loss: 1.3710 - val_accuracy: 0.5600\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7928 - accuracy: 0.7600 - val_loss: 1.3779 - val_accuracy: 0.5567\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7943 - accuracy: 0.7543 - val_loss: 1.3722 - val_accuracy: 0.5500\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7924 - accuracy: 0.7571 - val_loss: 1.3757 - val_accuracy: 0.5667\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7928 - accuracy: 0.7657 - val_loss: 1.3738 - val_accuracy: 0.5500\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7918 - accuracy: 0.7529 - val_loss: 1.3719 - val_accuracy: 0.5600\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7889 - accuracy: 0.7600 - val_loss: 1.3799 - val_accuracy: 0.5533\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7897 - accuracy: 0.7543 - val_loss: 1.3693 - val_accuracy: 0.5500\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7851 - accuracy: 0.7514 - val_loss: 1.3702 - val_accuracy: 0.5467\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.7867 - accuracy: 0.7529 - val_loss: 1.3765 - val_accuracy: 0.5600\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7845 - accuracy: 0.7529 - val_loss: 1.3697 - val_accuracy: 0.5633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7837 - accuracy: 0.7586 - val_loss: 1.3776 - val_accuracy: 0.5600\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7791 - accuracy: 0.7543 - val_loss: 1.3671 - val_accuracy: 0.5400\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7793 - accuracy: 0.7586 - val_loss: 1.3739 - val_accuracy: 0.5567\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7787 - accuracy: 0.7600 - val_loss: 1.3744 - val_accuracy: 0.5567\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7760 - accuracy: 0.7643 - val_loss: 1.3869 - val_accuracy: 0.5400\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7763 - accuracy: 0.7600 - val_loss: 1.3738 - val_accuracy: 0.5533\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7731 - accuracy: 0.7657 - val_loss: 1.3771 - val_accuracy: 0.5500\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7712 - accuracy: 0.7643 - val_loss: 1.3880 - val_accuracy: 0.5533\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7711 - accuracy: 0.7657 - val_loss: 1.3788 - val_accuracy: 0.5467\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7682 - accuracy: 0.7600 - val_loss: 1.3795 - val_accuracy: 0.5600\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7684 - accuracy: 0.7600 - val_loss: 1.3783 - val_accuracy: 0.5500\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7692 - accuracy: 0.7657 - val_loss: 1.3794 - val_accuracy: 0.5467\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7665 - accuracy: 0.7600 - val_loss: 1.3763 - val_accuracy: 0.5733\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7645 - accuracy: 0.7600 - val_loss: 1.3788 - val_accuracy: 0.5500\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7635 - accuracy: 0.7671 - val_loss: 1.3865 - val_accuracy: 0.5500\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7618 - accuracy: 0.7586 - val_loss: 1.3919 - val_accuracy: 0.5667\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.7611 - accuracy: 0.7614 - val_loss: 1.3873 - val_accuracy: 0.5633\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7596 - accuracy: 0.7743 - val_loss: 1.3884 - val_accuracy: 0.5467\n",
      "Epoch 297/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7553 - accuracy: 0.7686 - val_loss: 1.3936 - val_accuracy: 0.5400\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7582 - accuracy: 0.7629 - val_loss: 1.3872 - val_accuracy: 0.5633\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7559 - accuracy: 0.7657 - val_loss: 1.3872 - val_accuracy: 0.5500\n",
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7552 - accuracy: 0.7686 - val_loss: 1.3845 - val_accuracy: 0.5567\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7539 - accuracy: 0.7614 - val_loss: 1.3990 - val_accuracy: 0.5667\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7544 - accuracy: 0.7643 - val_loss: 1.3905 - val_accuracy: 0.5500\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7514 - accuracy: 0.7629 - val_loss: 1.3898 - val_accuracy: 0.5500\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.7509 - accuracy: 0.7557 - val_loss: 1.3981 - val_accuracy: 0.5600\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.7509 - accuracy: 0.7614 - val_loss: 1.3863 - val_accuracy: 0.5533\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.7486 - accuracy: 0.7629 - val_loss: 1.3921 - val_accuracy: 0.5533\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7485 - accuracy: 0.7571 - val_loss: 1.3891 - val_accuracy: 0.5500\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7451 - accuracy: 0.7757 - val_loss: 1.3982 - val_accuracy: 0.5600\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7446 - accuracy: 0.7700 - val_loss: 1.3934 - val_accuracy: 0.5500\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7434 - accuracy: 0.7643 - val_loss: 1.3920 - val_accuracy: 0.5467\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7432 - accuracy: 0.7757 - val_loss: 1.3946 - val_accuracy: 0.5533\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7398 - accuracy: 0.7657 - val_loss: 1.4023 - val_accuracy: 0.5600\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7411 - accuracy: 0.7729 - val_loss: 1.3970 - val_accuracy: 0.5567\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7400 - accuracy: 0.7671 - val_loss: 1.3944 - val_accuracy: 0.5633\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7396 - accuracy: 0.7729 - val_loss: 1.3940 - val_accuracy: 0.5600\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7382 - accuracy: 0.7714 - val_loss: 1.3978 - val_accuracy: 0.5633\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7366 - accuracy: 0.7714 - val_loss: 1.3992 - val_accuracy: 0.5633\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7358 - accuracy: 0.7714 - val_loss: 1.3956 - val_accuracy: 0.5600\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.7338 - accuracy: 0.7686 - val_loss: 1.3993 - val_accuracy: 0.5700\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.7322 - accuracy: 0.7771 - val_loss: 1.3961 - val_accuracy: 0.5633\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7316 - accuracy: 0.7671 - val_loss: 1.4064 - val_accuracy: 0.5600\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.7289 - accuracy: 0.7786 - val_loss: 1.3979 - val_accuracy: 0.5567\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7306 - accuracy: 0.7786 - val_loss: 1.3986 - val_accuracy: 0.5600\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7302 - accuracy: 0.7743 - val_loss: 1.4042 - val_accuracy: 0.5533\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7269 - accuracy: 0.7757 - val_loss: 1.4020 - val_accuracy: 0.5500\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7267 - accuracy: 0.7786 - val_loss: 1.4055 - val_accuracy: 0.5567\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7253 - accuracy: 0.7714 - val_loss: 1.4017 - val_accuracy: 0.5600\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7262 - accuracy: 0.7743 - val_loss: 1.4075 - val_accuracy: 0.5733\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7249 - accuracy: 0.7743 - val_loss: 1.4010 - val_accuracy: 0.5633\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7227 - accuracy: 0.7843 - val_loss: 1.4074 - val_accuracy: 0.5633\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.7233 - accuracy: 0.7771 - val_loss: 1.4066 - val_accuracy: 0.5533\n",
      "Epoch 332/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.7213 - accuracy: 0.7743 - val_loss: 1.4055 - val_accuracy: 0.5600\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7200 - accuracy: 0.7871 - val_loss: 1.4123 - val_accuracy: 0.5767\n",
      "Epoch 334/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 0.7181 - accuracy: 0.7771 - val_loss: 1.4126 - val_accuracy: 0.5500\n",
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7197 - accuracy: 0.7857 - val_loss: 1.4135 - val_accuracy: 0.5467\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7178 - accuracy: 0.7757 - val_loss: 1.4216 - val_accuracy: 0.5700\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7157 - accuracy: 0.7843 - val_loss: 1.4155 - val_accuracy: 0.5500\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7161 - accuracy: 0.7829 - val_loss: 1.4229 - val_accuracy: 0.5600\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7122 - accuracy: 0.7757 - val_loss: 1.4135 - val_accuracy: 0.5633\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7126 - accuracy: 0.7729 - val_loss: 1.4241 - val_accuracy: 0.5533\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7093 - accuracy: 0.7871 - val_loss: 1.4181 - val_accuracy: 0.5500\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7104 - accuracy: 0.7900 - val_loss: 1.4165 - val_accuracy: 0.5600\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7116 - accuracy: 0.7757 - val_loss: 1.4172 - val_accuracy: 0.5600\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7087 - accuracy: 0.7871 - val_loss: 1.4240 - val_accuracy: 0.5600\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7093 - accuracy: 0.7743 - val_loss: 1.4239 - val_accuracy: 0.5667\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7074 - accuracy: 0.7800 - val_loss: 1.4227 - val_accuracy: 0.5567\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7056 - accuracy: 0.7843 - val_loss: 1.4226 - val_accuracy: 0.5567\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7061 - accuracy: 0.7786 - val_loss: 1.4207 - val_accuracy: 0.5567\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7043 - accuracy: 0.7800 - val_loss: 1.4310 - val_accuracy: 0.5667\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7056 - accuracy: 0.7786 - val_loss: 1.4270 - val_accuracy: 0.5567\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7041 - accuracy: 0.7829 - val_loss: 1.4285 - val_accuracy: 0.5500\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.7030 - accuracy: 0.7829 - val_loss: 1.4326 - val_accuracy: 0.5733\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.7010 - accuracy: 0.7786 - val_loss: 1.4237 - val_accuracy: 0.5567\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.7004 - accuracy: 0.7829 - val_loss: 1.4339 - val_accuracy: 0.5600\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.6994 - accuracy: 0.7829 - val_loss: 1.4281 - val_accuracy: 0.5500\n",
      "Epoch 356/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7001 - accuracy: 0.7829 - val_loss: 1.4305 - val_accuracy: 0.5633\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6969 - accuracy: 0.7843 - val_loss: 1.4347 - val_accuracy: 0.5467\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6968 - accuracy: 0.7843 - val_loss: 1.4284 - val_accuracy: 0.5567\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6970 - accuracy: 0.7900 - val_loss: 1.4285 - val_accuracy: 0.5567\n",
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6959 - accuracy: 0.7829 - val_loss: 1.4314 - val_accuracy: 0.5567\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6948 - accuracy: 0.7886 - val_loss: 1.4363 - val_accuracy: 0.5567\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6938 - accuracy: 0.7843 - val_loss: 1.4356 - val_accuracy: 0.5533\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6938 - accuracy: 0.7886 - val_loss: 1.4354 - val_accuracy: 0.5600\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6915 - accuracy: 0.7857 - val_loss: 1.4527 - val_accuracy: 0.5833\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6936 - accuracy: 0.7943 - val_loss: 1.4369 - val_accuracy: 0.5567\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6898 - accuracy: 0.7986 - val_loss: 1.4368 - val_accuracy: 0.5500\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6907 - accuracy: 0.7857 - val_loss: 1.4366 - val_accuracy: 0.5667\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6906 - accuracy: 0.7871 - val_loss: 1.4367 - val_accuracy: 0.5533\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6884 - accuracy: 0.7886 - val_loss: 1.4437 - val_accuracy: 0.5567\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6865 - accuracy: 0.7971 - val_loss: 1.4445 - val_accuracy: 0.5600\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6864 - accuracy: 0.7886 - val_loss: 1.4509 - val_accuracy: 0.5700\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6872 - accuracy: 0.7914 - val_loss: 1.4474 - val_accuracy: 0.5667\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6867 - accuracy: 0.7900 - val_loss: 1.4419 - val_accuracy: 0.5500\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6829 - accuracy: 0.7900 - val_loss: 1.4523 - val_accuracy: 0.5633\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6831 - accuracy: 0.7943 - val_loss: 1.4575 - val_accuracy: 0.5833\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6818 - accuracy: 0.8043 - val_loss: 1.4523 - val_accuracy: 0.5467\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6831 - accuracy: 0.7943 - val_loss: 1.4558 - val_accuracy: 0.5567\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6806 - accuracy: 0.7929 - val_loss: 1.4719 - val_accuracy: 0.5733\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6815 - accuracy: 0.7857 - val_loss: 1.4487 - val_accuracy: 0.5600\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.6785 - accuracy: 0.7914 - val_loss: 1.4567 - val_accuracy: 0.5533\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6760 - accuracy: 0.8014 - val_loss: 1.4576 - val_accuracy: 0.5500\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.6777 - accuracy: 0.7986 - val_loss: 1.4553 - val_accuracy: 0.5567\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6764 - accuracy: 0.8000 - val_loss: 1.4578 - val_accuracy: 0.5467\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6741 - accuracy: 0.7886 - val_loss: 1.4667 - val_accuracy: 0.5600\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6762 - accuracy: 0.7857 - val_loss: 1.4594 - val_accuracy: 0.5733\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6737 - accuracy: 0.7871 - val_loss: 1.4717 - val_accuracy: 0.5900\n",
      "Epoch 387/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.6726 - accuracy: 0.8000 - val_loss: 1.4585 - val_accuracy: 0.5500\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.6732 - accuracy: 0.7957 - val_loss: 1.4570 - val_accuracy: 0.5500\n",
      "Epoch 389/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 0.6718 - accuracy: 0.7900 - val_loss: 1.4639 - val_accuracy: 0.5667\n",
      "Epoch 390/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6703 - accuracy: 0.7900 - val_loss: 1.4569 - val_accuracy: 0.5533\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6687 - accuracy: 0.7900 - val_loss: 1.4645 - val_accuracy: 0.5800\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6677 - accuracy: 0.8014 - val_loss: 1.4565 - val_accuracy: 0.5667\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6689 - accuracy: 0.7943 - val_loss: 1.4689 - val_accuracy: 0.5733\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6655 - accuracy: 0.7971 - val_loss: 1.4765 - val_accuracy: 0.5800\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6670 - accuracy: 0.7929 - val_loss: 1.4622 - val_accuracy: 0.5533\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6657 - accuracy: 0.7914 - val_loss: 1.4634 - val_accuracy: 0.5600\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6637 - accuracy: 0.8000 - val_loss: 1.4667 - val_accuracy: 0.5700\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6664 - accuracy: 0.7971 - val_loss: 1.4617 - val_accuracy: 0.5500\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6650 - accuracy: 0.8057 - val_loss: 1.4673 - val_accuracy: 0.5667\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6637 - accuracy: 0.8029 - val_loss: 1.4682 - val_accuracy: 0.5500\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.6630 - accuracy: 0.7986 - val_loss: 1.4774 - val_accuracy: 0.5600\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6626 - accuracy: 0.8014 - val_loss: 1.4728 - val_accuracy: 0.5633\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6617 - accuracy: 0.7871 - val_loss: 1.4703 - val_accuracy: 0.5533\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.6614 - accuracy: 0.7943 - val_loss: 1.4699 - val_accuracy: 0.5567\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6602 - accuracy: 0.7957 - val_loss: 1.4704 - val_accuracy: 0.5567\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6595 - accuracy: 0.8014 - val_loss: 1.4737 - val_accuracy: 0.5533\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6585 - accuracy: 0.7986 - val_loss: 1.4960 - val_accuracy: 0.5867\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6588 - accuracy: 0.8000 - val_loss: 1.4745 - val_accuracy: 0.5633\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6575 - accuracy: 0.7986 - val_loss: 1.4801 - val_accuracy: 0.5533\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6569 - accuracy: 0.8000 - val_loss: 1.4760 - val_accuracy: 0.5567\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6564 - accuracy: 0.7943 - val_loss: 1.4800 - val_accuracy: 0.5433\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6554 - accuracy: 0.8057 - val_loss: 1.4834 - val_accuracy: 0.5633\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6545 - accuracy: 0.8014 - val_loss: 1.4884 - val_accuracy: 0.5467\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6523 - accuracy: 0.8000 - val_loss: 1.4899 - val_accuracy: 0.5533\n",
      "Epoch 415/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6534 - accuracy: 0.8043 - val_loss: 1.4845 - val_accuracy: 0.5467\n",
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6518 - accuracy: 0.8000 - val_loss: 1.4866 - val_accuracy: 0.5433\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6523 - accuracy: 0.7971 - val_loss: 1.4897 - val_accuracy: 0.5600\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.6517 - accuracy: 0.8043 - val_loss: 1.4853 - val_accuracy: 0.5467\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6491 - accuracy: 0.8029 - val_loss: 1.4844 - val_accuracy: 0.5500\n",
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6469 - accuracy: 0.8057 - val_loss: 1.4904 - val_accuracy: 0.5633\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6492 - accuracy: 0.8000 - val_loss: 1.4878 - val_accuracy: 0.5533\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6482 - accuracy: 0.8071 - val_loss: 1.4846 - val_accuracy: 0.5533\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.6470 - accuracy: 0.8029 - val_loss: 1.4954 - val_accuracy: 0.5433\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.6452 - accuracy: 0.8143 - val_loss: 1.4940 - val_accuracy: 0.5567\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.6480 - accuracy: 0.7986 - val_loss: 1.4912 - val_accuracy: 0.5533\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.6464 - accuracy: 0.8129 - val_loss: 1.5016 - val_accuracy: 0.5533\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6442 - accuracy: 0.8086 - val_loss: 1.4992 - val_accuracy: 0.5667\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6458 - accuracy: 0.8057 - val_loss: 1.5004 - val_accuracy: 0.5433\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6435 - accuracy: 0.8014 - val_loss: 1.5018 - val_accuracy: 0.5600\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6421 - accuracy: 0.8100 - val_loss: 1.5031 - val_accuracy: 0.5400\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6419 - accuracy: 0.8114 - val_loss: 1.5075 - val_accuracy: 0.5533\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6399 - accuracy: 0.8100 - val_loss: 1.5104 - val_accuracy: 0.5600\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6405 - accuracy: 0.8143 - val_loss: 1.5060 - val_accuracy: 0.5633\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6393 - accuracy: 0.8029 - val_loss: 1.5050 - val_accuracy: 0.5533\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6397 - accuracy: 0.8057 - val_loss: 1.5008 - val_accuracy: 0.5467\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6378 - accuracy: 0.8071 - val_loss: 1.5040 - val_accuracy: 0.5533\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6375 - accuracy: 0.8071 - val_loss: 1.5041 - val_accuracy: 0.5600\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6398 - accuracy: 0.8000 - val_loss: 1.5031 - val_accuracy: 0.5600\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6376 - accuracy: 0.8171 - val_loss: 1.5106 - val_accuracy: 0.5500\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6352 - accuracy: 0.8114 - val_loss: 1.5025 - val_accuracy: 0.5533\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6344 - accuracy: 0.8129 - val_loss: 1.5171 - val_accuracy: 0.5533\n",
      "Epoch 442/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6365 - accuracy: 0.8114 - val_loss: 1.5189 - val_accuracy: 0.5800\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6345 - accuracy: 0.8114 - val_loss: 1.5113 - val_accuracy: 0.5433\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6325 - accuracy: 0.8143 - val_loss: 1.5153 - val_accuracy: 0.5467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6316 - accuracy: 0.8086 - val_loss: 1.5294 - val_accuracy: 0.5367\n",
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6344 - accuracy: 0.8086 - val_loss: 1.5189 - val_accuracy: 0.5733\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6320 - accuracy: 0.8157 - val_loss: 1.5223 - val_accuracy: 0.5600\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.6295 - accuracy: 0.8200 - val_loss: 1.5187 - val_accuracy: 0.5433\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6311 - accuracy: 0.8014 - val_loss: 1.5168 - val_accuracy: 0.5433\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6293 - accuracy: 0.8029 - val_loss: 1.5210 - val_accuracy: 0.5433\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6304 - accuracy: 0.8171 - val_loss: 1.5162 - val_accuracy: 0.5700\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6279 - accuracy: 0.8100 - val_loss: 1.5165 - val_accuracy: 0.5500\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6275 - accuracy: 0.8129 - val_loss: 1.5274 - val_accuracy: 0.5500\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6291 - accuracy: 0.8214 - val_loss: 1.5266 - val_accuracy: 0.5500\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.6275 - accuracy: 0.8129 - val_loss: 1.5303 - val_accuracy: 0.5767\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6254 - accuracy: 0.8200 - val_loss: 1.5225 - val_accuracy: 0.5700\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6246 - accuracy: 0.8243 - val_loss: 1.5186 - val_accuracy: 0.5500\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.6251 - accuracy: 0.8157 - val_loss: 1.5307 - val_accuracy: 0.5467\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.6236 - accuracy: 0.8200 - val_loss: 1.5323 - val_accuracy: 0.5733\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6246 - accuracy: 0.8186 - val_loss: 1.5270 - val_accuracy: 0.5500\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6250 - accuracy: 0.8100 - val_loss: 1.5256 - val_accuracy: 0.5500\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6236 - accuracy: 0.8114 - val_loss: 1.5324 - val_accuracy: 0.5500\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.6217 - accuracy: 0.8171 - val_loss: 1.5294 - val_accuracy: 0.5567\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6216 - accuracy: 0.8171 - val_loss: 1.5302 - val_accuracy: 0.5500\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.6219 - accuracy: 0.8086 - val_loss: 1.5315 - val_accuracy: 0.5600\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6202 - accuracy: 0.8186 - val_loss: 1.5328 - val_accuracy: 0.5467\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6197 - accuracy: 0.8157 - val_loss: 1.5391 - val_accuracy: 0.5467\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6195 - accuracy: 0.8143 - val_loss: 1.5402 - val_accuracy: 0.5533\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6194 - accuracy: 0.8143 - val_loss: 1.5454 - val_accuracy: 0.5767\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6178 - accuracy: 0.8229 - val_loss: 1.5431 - val_accuracy: 0.5500\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6174 - accuracy: 0.8214 - val_loss: 1.5426 - val_accuracy: 0.5433\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6168 - accuracy: 0.8271 - val_loss: 1.5468 - val_accuracy: 0.5600\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6161 - accuracy: 0.8229 - val_loss: 1.5464 - val_accuracy: 0.5567\n",
      "Epoch 474/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6154 - accuracy: 0.8257 - val_loss: 1.5448 - val_accuracy: 0.5467\n",
      "Epoch 475/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6143 - accuracy: 0.8257 - val_loss: 1.5518 - val_accuracy: 0.5633\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6157 - accuracy: 0.8143 - val_loss: 1.5478 - val_accuracy: 0.5533\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6139 - accuracy: 0.8200 - val_loss: 1.5515 - val_accuracy: 0.5500\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6142 - accuracy: 0.8257 - val_loss: 1.5523 - val_accuracy: 0.5533\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.6149 - accuracy: 0.8214 - val_loss: 1.5541 - val_accuracy: 0.5533\n",
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6126 - accuracy: 0.8200 - val_loss: 1.5492 - val_accuracy: 0.5433\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6107 - accuracy: 0.8186 - val_loss: 1.5677 - val_accuracy: 0.5333\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6127 - accuracy: 0.8200 - val_loss: 1.5494 - val_accuracy: 0.5467\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6116 - accuracy: 0.8186 - val_loss: 1.5541 - val_accuracy: 0.5567\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6099 - accuracy: 0.8200 - val_loss: 1.5532 - val_accuracy: 0.5700\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6094 - accuracy: 0.8271 - val_loss: 1.5537 - val_accuracy: 0.5533\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6086 - accuracy: 0.8286 - val_loss: 1.5600 - val_accuracy: 0.5567\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6084 - accuracy: 0.8286 - val_loss: 1.5625 - val_accuracy: 0.5533\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6081 - accuracy: 0.8243 - val_loss: 1.5626 - val_accuracy: 0.5667\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6076 - accuracy: 0.8314 - val_loss: 1.5641 - val_accuracy: 0.5467\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6052 - accuracy: 0.8214 - val_loss: 1.5790 - val_accuracy: 0.5733\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6068 - accuracy: 0.8243 - val_loss: 1.5632 - val_accuracy: 0.5700\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6063 - accuracy: 0.8300 - val_loss: 1.5778 - val_accuracy: 0.5533\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.6053 - accuracy: 0.8229 - val_loss: 1.5726 - val_accuracy: 0.5500\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.6031 - accuracy: 0.8271 - val_loss: 1.5714 - val_accuracy: 0.5533\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6054 - accuracy: 0.8214 - val_loss: 1.5776 - val_accuracy: 0.5633\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.6022 - accuracy: 0.8229 - val_loss: 1.5698 - val_accuracy: 0.5567\n",
      "Epoch 497/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6009 - accuracy: 0.8329 - val_loss: 1.5685 - val_accuracy: 0.5467\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6020 - accuracy: 0.8300 - val_loss: 1.5727 - val_accuracy: 0.5533\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6037 - accuracy: 0.8271 - val_loss: 1.5726 - val_accuracy: 0.5500\n",
      "Epoch 500/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.6015 - accuracy: 0.8329 - val_loss: 1.5776 - val_accuracy: 0.5533\n",
      "Epoch 501/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5999 - accuracy: 0.8314 - val_loss: 1.5727 - val_accuracy: 0.5633\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6021 - accuracy: 0.8229 - val_loss: 1.5765 - val_accuracy: 0.5533\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5993 - accuracy: 0.8314 - val_loss: 1.5781 - val_accuracy: 0.5467\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5999 - accuracy: 0.8343 - val_loss: 1.5729 - val_accuracy: 0.5433\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.5997 - accuracy: 0.8229 - val_loss: 1.5805 - val_accuracy: 0.5533\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5987 - accuracy: 0.8286 - val_loss: 1.5801 - val_accuracy: 0.5600\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5976 - accuracy: 0.8300 - val_loss: 1.5865 - val_accuracy: 0.5567\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5977 - accuracy: 0.8343 - val_loss: 1.5889 - val_accuracy: 0.5567\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5957 - accuracy: 0.8357 - val_loss: 1.5866 - val_accuracy: 0.5533\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.5948 - accuracy: 0.8357 - val_loss: 1.5894 - val_accuracy: 0.5533\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5949 - accuracy: 0.8314 - val_loss: 1.5856 - val_accuracy: 0.5567\n",
      "Epoch 512/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5969 - accuracy: 0.8329 - val_loss: 1.5922 - val_accuracy: 0.5600\n",
      "Epoch 513/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5967 - accuracy: 0.8314 - val_loss: 1.5890 - val_accuracy: 0.5500\n",
      "Epoch 514/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5938 - accuracy: 0.8343 - val_loss: 1.5872 - val_accuracy: 0.5567\n",
      "Epoch 515/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.5944 - accuracy: 0.8343 - val_loss: 1.5950 - val_accuracy: 0.5500\n",
      "Epoch 516/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5926 - accuracy: 0.8343 - val_loss: 1.5910 - val_accuracy: 0.5500\n",
      "Epoch 517/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5910 - accuracy: 0.8343 - val_loss: 1.6000 - val_accuracy: 0.5700\n",
      "Epoch 518/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5937 - accuracy: 0.8314 - val_loss: 1.5928 - val_accuracy: 0.5533\n",
      "Epoch 519/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5922 - accuracy: 0.8329 - val_loss: 1.5869 - val_accuracy: 0.5533\n",
      "Epoch 520/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5912 - accuracy: 0.8343 - val_loss: 1.5842 - val_accuracy: 0.5500\n",
      "Epoch 521/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5888 - accuracy: 0.8314 - val_loss: 1.6010 - val_accuracy: 0.5533\n",
      "Epoch 522/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5887 - accuracy: 0.8343 - val_loss: 1.5962 - val_accuracy: 0.5533\n",
      "Epoch 523/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5894 - accuracy: 0.8357 - val_loss: 1.5977 - val_accuracy: 0.5467\n",
      "Epoch 524/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5891 - accuracy: 0.8357 - val_loss: 1.5969 - val_accuracy: 0.5500\n",
      "Epoch 525/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5865 - accuracy: 0.8371 - val_loss: 1.6059 - val_accuracy: 0.5533\n",
      "Epoch 526/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5887 - accuracy: 0.8343 - val_loss: 1.6001 - val_accuracy: 0.5533\n",
      "Epoch 527/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5883 - accuracy: 0.8300 - val_loss: 1.6062 - val_accuracy: 0.5500\n",
      "Epoch 528/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.5855 - accuracy: 0.8329 - val_loss: 1.5994 - val_accuracy: 0.5567\n",
      "Epoch 529/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5858 - accuracy: 0.8343 - val_loss: 1.6123 - val_accuracy: 0.5533\n",
      "Epoch 530/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5866 - accuracy: 0.8343 - val_loss: 1.6092 - val_accuracy: 0.5500\n",
      "Epoch 531/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5853 - accuracy: 0.8357 - val_loss: 1.6138 - val_accuracy: 0.5500\n",
      "Epoch 532/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5862 - accuracy: 0.8343 - val_loss: 1.6170 - val_accuracy: 0.5600\n",
      "Epoch 533/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5845 - accuracy: 0.8371 - val_loss: 1.6185 - val_accuracy: 0.5600\n",
      "Epoch 534/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5861 - accuracy: 0.8414 - val_loss: 1.6159 - val_accuracy: 0.5533\n",
      "Epoch 535/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5834 - accuracy: 0.8357 - val_loss: 1.6094 - val_accuracy: 0.5533\n",
      "Epoch 536/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5834 - accuracy: 0.8400 - val_loss: 1.6211 - val_accuracy: 0.5533\n",
      "Epoch 537/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5823 - accuracy: 0.8443 - val_loss: 1.6211 - val_accuracy: 0.5600\n",
      "Epoch 538/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5812 - accuracy: 0.8414 - val_loss: 1.6108 - val_accuracy: 0.5567\n",
      "Epoch 539/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5823 - accuracy: 0.8443 - val_loss: 1.6225 - val_accuracy: 0.5533\n",
      "Epoch 540/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.5814 - accuracy: 0.8400 - val_loss: 1.6089 - val_accuracy: 0.5500\n",
      "Epoch 541/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.5814 - accuracy: 0.8357 - val_loss: 1.6140 - val_accuracy: 0.5533\n",
      "Epoch 542/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5815 - accuracy: 0.8429 - val_loss: 1.6289 - val_accuracy: 0.5600\n",
      "Epoch 543/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5785 - accuracy: 0.8371 - val_loss: 1.6098 - val_accuracy: 0.5467\n",
      "Epoch 544/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5793 - accuracy: 0.8429 - val_loss: 1.6323 - val_accuracy: 0.5567\n",
      "Epoch 545/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5767 - accuracy: 0.8386 - val_loss: 1.6231 - val_accuracy: 0.5533\n",
      "Epoch 546/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5785 - accuracy: 0.8371 - val_loss: 1.6249 - val_accuracy: 0.5567\n",
      "Epoch 547/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5779 - accuracy: 0.8414 - val_loss: 1.6199 - val_accuracy: 0.5533\n",
      "Epoch 548/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.5778 - accuracy: 0.8500 - val_loss: 1.6302 - val_accuracy: 0.5500\n",
      "Epoch 549/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5750 - accuracy: 0.8457 - val_loss: 1.6318 - val_accuracy: 0.5700\n",
      "Epoch 550/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5785 - accuracy: 0.8357 - val_loss: 1.6241 - val_accuracy: 0.5700\n",
      "Epoch 551/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.5749 - accuracy: 0.8457 - val_loss: 1.6314 - val_accuracy: 0.5533\n",
      "Epoch 552/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.5761 - accuracy: 0.8400 - val_loss: 1.6234 - val_accuracy: 0.5533\n",
      "Epoch 553/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5737 - accuracy: 0.8471 - val_loss: 1.6476 - val_accuracy: 0.5467\n",
      "Epoch 554/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5759 - accuracy: 0.8414 - val_loss: 1.6316 - val_accuracy: 0.5567\n",
      "Epoch 555/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5726 - accuracy: 0.8429 - val_loss: 1.6558 - val_accuracy: 0.5700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5749 - accuracy: 0.8443 - val_loss: 1.6437 - val_accuracy: 0.5567\n",
      "Epoch 557/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5733 - accuracy: 0.8400 - val_loss: 1.6393 - val_accuracy: 0.5567\n",
      "Epoch 558/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5724 - accuracy: 0.8429 - val_loss: 1.6431 - val_accuracy: 0.5400\n",
      "Epoch 559/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5733 - accuracy: 0.8429 - val_loss: 1.6433 - val_accuracy: 0.5567\n",
      "Epoch 560/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5714 - accuracy: 0.8414 - val_loss: 1.6463 - val_accuracy: 0.5567\n",
      "Epoch 561/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5709 - accuracy: 0.8443 - val_loss: 1.6510 - val_accuracy: 0.5467\n",
      "Epoch 562/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5713 - accuracy: 0.8400 - val_loss: 1.6451 - val_accuracy: 0.5533\n",
      "Epoch 563/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.5720 - accuracy: 0.8400 - val_loss: 1.6478 - val_accuracy: 0.5567\n",
      "Epoch 564/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.5697 - accuracy: 0.8414 - val_loss: 1.6556 - val_accuracy: 0.5600\n",
      "Epoch 565/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5676 - accuracy: 0.8371 - val_loss: 1.6583 - val_accuracy: 0.5567\n",
      "Epoch 566/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5687 - accuracy: 0.8486 - val_loss: 1.6396 - val_accuracy: 0.5500\n",
      "Epoch 567/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5688 - accuracy: 0.8414 - val_loss: 1.6432 - val_accuracy: 0.5433\n",
      "Epoch 568/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5643 - accuracy: 0.8457 - val_loss: 1.6461 - val_accuracy: 0.5500\n",
      "Epoch 569/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5660 - accuracy: 0.8414 - val_loss: 1.6578 - val_accuracy: 0.5533\n",
      "Epoch 570/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5674 - accuracy: 0.8443 - val_loss: 1.6487 - val_accuracy: 0.5467\n",
      "Epoch 571/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5657 - accuracy: 0.8443 - val_loss: 1.6462 - val_accuracy: 0.5433\n",
      "Epoch 572/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5662 - accuracy: 0.8443 - val_loss: 1.6561 - val_accuracy: 0.5533\n",
      "Epoch 573/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5643 - accuracy: 0.8514 - val_loss: 1.6511 - val_accuracy: 0.5500\n",
      "Epoch 574/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5624 - accuracy: 0.8400 - val_loss: 1.6626 - val_accuracy: 0.5667\n",
      "Epoch 575/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5646 - accuracy: 0.8457 - val_loss: 1.6498 - val_accuracy: 0.5467\n",
      "Epoch 576/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5623 - accuracy: 0.8443 - val_loss: 1.6523 - val_accuracy: 0.5500\n",
      "Epoch 577/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5626 - accuracy: 0.8486 - val_loss: 1.6572 - val_accuracy: 0.5467\n",
      "Epoch 578/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5634 - accuracy: 0.8543 - val_loss: 1.6589 - val_accuracy: 0.5467\n",
      "Epoch 579/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5613 - accuracy: 0.8529 - val_loss: 1.6575 - val_accuracy: 0.5500\n",
      "Epoch 580/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5600 - accuracy: 0.8543 - val_loss: 1.6584 - val_accuracy: 0.5500\n",
      "Epoch 581/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5591 - accuracy: 0.8500 - val_loss: 1.6534 - val_accuracy: 0.5467\n",
      "Epoch 582/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5602 - accuracy: 0.8443 - val_loss: 1.6570 - val_accuracy: 0.5467\n",
      "Epoch 583/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5592 - accuracy: 0.8586 - val_loss: 1.6596 - val_accuracy: 0.5433\n",
      "Epoch 584/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.5581 - accuracy: 0.8514 - val_loss: 1.6600 - val_accuracy: 0.5433\n",
      "Epoch 585/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.5578 - accuracy: 0.8529 - val_loss: 1.6715 - val_accuracy: 0.5567\n",
      "Epoch 586/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.5590 - accuracy: 0.8543 - val_loss: 1.6647 - val_accuracy: 0.5500\n",
      "Epoch 587/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5573 - accuracy: 0.8486 - val_loss: 1.6660 - val_accuracy: 0.5467\n",
      "Epoch 588/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5591 - accuracy: 0.8543 - val_loss: 1.6713 - val_accuracy: 0.5567\n",
      "Epoch 589/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5561 - accuracy: 0.8471 - val_loss: 1.6746 - val_accuracy: 0.5500\n",
      "Epoch 590/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5558 - accuracy: 0.8471 - val_loss: 1.6666 - val_accuracy: 0.5433\n",
      "Epoch 591/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5545 - accuracy: 0.8529 - val_loss: 1.6731 - val_accuracy: 0.5467\n",
      "Epoch 592/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.5569 - accuracy: 0.8557 - val_loss: 1.6682 - val_accuracy: 0.5500\n",
      "Epoch 593/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.5557 - accuracy: 0.8571 - val_loss: 1.6695 - val_accuracy: 0.5467\n",
      "Epoch 594/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5555 - accuracy: 0.8514 - val_loss: 1.6742 - val_accuracy: 0.5467\n",
      "Epoch 595/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5542 - accuracy: 0.8543 - val_loss: 1.6766 - val_accuracy: 0.5433\n",
      "Epoch 596/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5541 - accuracy: 0.8471 - val_loss: 1.6774 - val_accuracy: 0.5500\n",
      "Epoch 597/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.5534 - accuracy: 0.8543 - val_loss: 1.6769 - val_accuracy: 0.5533\n",
      "Epoch 598/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.5506 - accuracy: 0.8557 - val_loss: 1.6969 - val_accuracy: 0.5267\n",
      "Epoch 599/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.5535 - accuracy: 0.8514 - val_loss: 1.6823 - val_accuracy: 0.5500\n",
      "Epoch 600/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5508 - accuracy: 0.8543 - val_loss: 1.6765 - val_accuracy: 0.5500\n",
      "Epoch 601/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5498 - accuracy: 0.8543 - val_loss: 1.6832 - val_accuracy: 0.5533\n",
      "Epoch 602/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5506 - accuracy: 0.8557 - val_loss: 1.6814 - val_accuracy: 0.5500\n",
      "Epoch 603/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5497 - accuracy: 0.8586 - val_loss: 1.6775 - val_accuracy: 0.5467\n",
      "Epoch 604/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5526 - accuracy: 0.8529 - val_loss: 1.6806 - val_accuracy: 0.5567\n",
      "Epoch 605/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5474 - accuracy: 0.8543 - val_loss: 1.6906 - val_accuracy: 0.5533\n",
      "Epoch 606/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5489 - accuracy: 0.8557 - val_loss: 1.6920 - val_accuracy: 0.5567\n",
      "Epoch 607/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5502 - accuracy: 0.8571 - val_loss: 1.6872 - val_accuracy: 0.5467\n",
      "Epoch 608/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5498 - accuracy: 0.8529 - val_loss: 1.6874 - val_accuracy: 0.5467\n",
      "Epoch 609/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5478 - accuracy: 0.8600 - val_loss: 1.6975 - val_accuracy: 0.5467\n",
      "Epoch 610/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5462 - accuracy: 0.8500 - val_loss: 1.6965 - val_accuracy: 0.5600\n",
      "Epoch 611/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.5468 - accuracy: 0.8557 - val_loss: 1.6898 - val_accuracy: 0.5533\n",
      "Epoch 612/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5472 - accuracy: 0.8600 - val_loss: 1.6893 - val_accuracy: 0.5500\n",
      "Epoch 613/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5462 - accuracy: 0.8571 - val_loss: 1.6979 - val_accuracy: 0.5567\n",
      "Epoch 614/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.5475 - accuracy: 0.8586 - val_loss: 1.7008 - val_accuracy: 0.5567\n",
      "Epoch 615/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5460 - accuracy: 0.8614 - val_loss: 1.7000 - val_accuracy: 0.5533\n",
      "Epoch 616/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5453 - accuracy: 0.8543 - val_loss: 1.7006 - val_accuracy: 0.5533\n",
      "Epoch 617/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5441 - accuracy: 0.8586 - val_loss: 1.7050 - val_accuracy: 0.5567\n",
      "Epoch 618/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5432 - accuracy: 0.8543 - val_loss: 1.6996 - val_accuracy: 0.5500\n",
      "Epoch 619/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5425 - accuracy: 0.8586 - val_loss: 1.7042 - val_accuracy: 0.5533\n",
      "Epoch 620/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5407 - accuracy: 0.8543 - val_loss: 1.6974 - val_accuracy: 0.5500\n",
      "Epoch 621/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5425 - accuracy: 0.8543 - val_loss: 1.7020 - val_accuracy: 0.5467\n",
      "Epoch 622/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5420 - accuracy: 0.8543 - val_loss: 1.7177 - val_accuracy: 0.5567\n",
      "Epoch 623/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5412 - accuracy: 0.8586 - val_loss: 1.6996 - val_accuracy: 0.5533\n",
      "Epoch 624/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.5409 - accuracy: 0.8586 - val_loss: 1.7092 - val_accuracy: 0.5500\n",
      "Epoch 625/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5434 - accuracy: 0.8571 - val_loss: 1.7101 - val_accuracy: 0.5467\n",
      "Epoch 626/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5414 - accuracy: 0.8529 - val_loss: 1.6977 - val_accuracy: 0.5600\n",
      "Epoch 627/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5403 - accuracy: 0.8629 - val_loss: 1.7080 - val_accuracy: 0.5533\n",
      "Epoch 628/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5404 - accuracy: 0.8586 - val_loss: 1.7100 - val_accuracy: 0.5500\n",
      "Epoch 629/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5403 - accuracy: 0.8586 - val_loss: 1.7074 - val_accuracy: 0.5467\n",
      "Epoch 630/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5401 - accuracy: 0.8629 - val_loss: 1.7088 - val_accuracy: 0.5500\n",
      "Epoch 631/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5389 - accuracy: 0.8614 - val_loss: 1.7291 - val_accuracy: 0.5467\n",
      "Epoch 632/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5385 - accuracy: 0.8629 - val_loss: 1.7227 - val_accuracy: 0.5500\n",
      "Epoch 633/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5385 - accuracy: 0.8643 - val_loss: 1.7160 - val_accuracy: 0.5467\n",
      "Epoch 634/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.5375 - accuracy: 0.8571 - val_loss: 1.7162 - val_accuracy: 0.5500\n",
      "Epoch 635/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.5366 - accuracy: 0.8600 - val_loss: 1.7121 - val_accuracy: 0.5500\n",
      "Epoch 636/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5362 - accuracy: 0.8571 - val_loss: 1.7192 - val_accuracy: 0.5467\n",
      "Epoch 637/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5380 - accuracy: 0.8600 - val_loss: 1.7221 - val_accuracy: 0.5567\n",
      "Epoch 638/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.5350 - accuracy: 0.8614 - val_loss: 1.7277 - val_accuracy: 0.5467\n",
      "Epoch 639/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.5355 - accuracy: 0.8571 - val_loss: 1.7190 - val_accuracy: 0.5467\n",
      "Epoch 640/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5356 - accuracy: 0.8543 - val_loss: 1.7227 - val_accuracy: 0.5467\n",
      "Epoch 641/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5347 - accuracy: 0.8571 - val_loss: 1.7108 - val_accuracy: 0.5533\n",
      "Epoch 642/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.5344 - accuracy: 0.8614 - val_loss: 1.7350 - val_accuracy: 0.5500\n",
      "Epoch 643/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5353 - accuracy: 0.8571 - val_loss: 1.7277 - val_accuracy: 0.5500\n",
      "Epoch 644/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5333 - accuracy: 0.8586 - val_loss: 1.7222 - val_accuracy: 0.5567\n",
      "Epoch 645/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5340 - accuracy: 0.8586 - val_loss: 1.7324 - val_accuracy: 0.5567\n",
      "Epoch 646/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5337 - accuracy: 0.8586 - val_loss: 1.7293 - val_accuracy: 0.5467\n",
      "Epoch 647/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5335 - accuracy: 0.8657 - val_loss: 1.7372 - val_accuracy: 0.5467\n",
      "Epoch 648/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5316 - accuracy: 0.8643 - val_loss: 1.7446 - val_accuracy: 0.5467\n",
      "Epoch 649/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5324 - accuracy: 0.8614 - val_loss: 1.7314 - val_accuracy: 0.5533\n",
      "Epoch 650/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5324 - accuracy: 0.8657 - val_loss: 1.7488 - val_accuracy: 0.5500\n",
      "Epoch 651/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.5309 - accuracy: 0.8586 - val_loss: 1.7313 - val_accuracy: 0.5533\n",
      "Epoch 652/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.5303 - accuracy: 0.8629 - val_loss: 1.7431 - val_accuracy: 0.5433\n",
      "Epoch 653/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 0.5296 - accuracy: 0.8614 - val_loss: 1.7439 - val_accuracy: 0.5500\n",
      "Epoch 654/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5318 - accuracy: 0.8586 - val_loss: 1.7463 - val_accuracy: 0.5467\n",
      "Epoch 655/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5306 - accuracy: 0.8629 - val_loss: 1.7441 - val_accuracy: 0.5400\n",
      "Epoch 656/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5297 - accuracy: 0.8586 - val_loss: 1.7381 - val_accuracy: 0.5533\n",
      "Epoch 657/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5275 - accuracy: 0.8671 - val_loss: 1.7519 - val_accuracy: 0.5467\n",
      "Epoch 658/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5292 - accuracy: 0.8571 - val_loss: 1.7451 - val_accuracy: 0.5533\n",
      "Epoch 659/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5267 - accuracy: 0.8657 - val_loss: 1.7482 - val_accuracy: 0.5433\n",
      "Epoch 660/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5267 - accuracy: 0.8643 - val_loss: 1.7542 - val_accuracy: 0.5500\n",
      "Epoch 661/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.5270 - accuracy: 0.8671 - val_loss: 1.7520 - val_accuracy: 0.5500\n",
      "Epoch 662/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5280 - accuracy: 0.8643 - val_loss: 1.7527 - val_accuracy: 0.5433\n",
      "Epoch 663/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5253 - accuracy: 0.8586 - val_loss: 1.7655 - val_accuracy: 0.5533\n",
      "Epoch 664/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5283 - accuracy: 0.8557 - val_loss: 1.7538 - val_accuracy: 0.5467\n",
      "Epoch 665/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5255 - accuracy: 0.8657 - val_loss: 1.7480 - val_accuracy: 0.5500\n",
      "Epoch 666/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5258 - accuracy: 0.8671 - val_loss: 1.7548 - val_accuracy: 0.5467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5241 - accuracy: 0.8614 - val_loss: 1.7560 - val_accuracy: 0.5500\n",
      "Epoch 668/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5248 - accuracy: 0.8643 - val_loss: 1.7608 - val_accuracy: 0.5400\n",
      "Epoch 669/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.5257 - accuracy: 0.8614 - val_loss: 1.7548 - val_accuracy: 0.5500\n",
      "Epoch 670/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5241 - accuracy: 0.8629 - val_loss: 1.7511 - val_accuracy: 0.5467\n",
      "Epoch 671/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5238 - accuracy: 0.8629 - val_loss: 1.7669 - val_accuracy: 0.5500\n",
      "Epoch 672/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5238 - accuracy: 0.8629 - val_loss: 1.7579 - val_accuracy: 0.5533\n",
      "Epoch 673/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5225 - accuracy: 0.8600 - val_loss: 1.7600 - val_accuracy: 0.5500\n",
      "Epoch 674/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5216 - accuracy: 0.8686 - val_loss: 1.7604 - val_accuracy: 0.5433\n",
      "Epoch 675/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5201 - accuracy: 0.8586 - val_loss: 1.7560 - val_accuracy: 0.5433\n",
      "Epoch 676/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5217 - accuracy: 0.8614 - val_loss: 1.7637 - val_accuracy: 0.5467\n",
      "Epoch 677/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5204 - accuracy: 0.8729 - val_loss: 1.7669 - val_accuracy: 0.5500\n",
      "Epoch 678/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5217 - accuracy: 0.8657 - val_loss: 1.7857 - val_accuracy: 0.5433\n",
      "Epoch 679/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5212 - accuracy: 0.8643 - val_loss: 1.7747 - val_accuracy: 0.5433\n",
      "Epoch 680/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5194 - accuracy: 0.8657 - val_loss: 1.7692 - val_accuracy: 0.5433\n",
      "Epoch 681/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.5200 - accuracy: 0.8643 - val_loss: 1.7740 - val_accuracy: 0.5467\n",
      "Epoch 682/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5204 - accuracy: 0.8643 - val_loss: 1.7657 - val_accuracy: 0.5500\n",
      "Epoch 683/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5194 - accuracy: 0.8671 - val_loss: 1.7865 - val_accuracy: 0.5467\n",
      "Epoch 684/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.5200 - accuracy: 0.8657 - val_loss: 1.7739 - val_accuracy: 0.5500\n",
      "Epoch 685/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5179 - accuracy: 0.8629 - val_loss: 1.7760 - val_accuracy: 0.5533\n",
      "Epoch 686/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.5190 - accuracy: 0.8671 - val_loss: 1.7756 - val_accuracy: 0.5467\n",
      "Epoch 687/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.5174 - accuracy: 0.8643 - val_loss: 1.7838 - val_accuracy: 0.5400\n",
      "Epoch 688/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5180 - accuracy: 0.8643 - val_loss: 1.7866 - val_accuracy: 0.5400\n",
      "Epoch 689/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5183 - accuracy: 0.8671 - val_loss: 1.7788 - val_accuracy: 0.5467\n",
      "Epoch 690/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5162 - accuracy: 0.8657 - val_loss: 1.7727 - val_accuracy: 0.5467\n",
      "Epoch 691/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.5176 - accuracy: 0.8671 - val_loss: 1.7800 - val_accuracy: 0.5500\n",
      "Epoch 692/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5171 - accuracy: 0.8671 - val_loss: 1.7829 - val_accuracy: 0.5467\n",
      "Epoch 693/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5155 - accuracy: 0.8686 - val_loss: 1.7908 - val_accuracy: 0.5333\n",
      "Epoch 694/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5164 - accuracy: 0.8671 - val_loss: 1.7775 - val_accuracy: 0.5467\n",
      "Epoch 695/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5147 - accuracy: 0.8671 - val_loss: 1.7811 - val_accuracy: 0.5467\n",
      "Epoch 696/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5143 - accuracy: 0.8657 - val_loss: 1.7969 - val_accuracy: 0.5333\n",
      "Epoch 697/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.5143 - accuracy: 0.8657 - val_loss: 1.7875 - val_accuracy: 0.5467\n",
      "Epoch 698/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.5142 - accuracy: 0.8614 - val_loss: 1.7973 - val_accuracy: 0.5433\n",
      "Epoch 699/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5131 - accuracy: 0.8714 - val_loss: 1.7987 - val_accuracy: 0.5400\n",
      "Epoch 700/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.5131 - accuracy: 0.8671 - val_loss: 1.8033 - val_accuracy: 0.5467\n",
      "Epoch 701/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.5126 - accuracy: 0.8714 - val_loss: 1.7964 - val_accuracy: 0.5367\n",
      "Epoch 702/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5131 - accuracy: 0.8629 - val_loss: 1.8126 - val_accuracy: 0.5367\n",
      "Epoch 703/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.5119 - accuracy: 0.8643 - val_loss: 1.8190 - val_accuracy: 0.5467\n",
      "Epoch 704/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.5108 - accuracy: 0.8686 - val_loss: 1.8083 - val_accuracy: 0.5433\n",
      "Epoch 705/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.5065 - accuracy: 0.8643 - val_loss: 1.7980 - val_accuracy: 0.5333\n",
      "Epoch 706/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.5075 - accuracy: 0.8686 - val_loss: 1.8165 - val_accuracy: 0.5500\n",
      "Epoch 707/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5052 - accuracy: 0.8714 - val_loss: 1.8187 - val_accuracy: 0.5400\n",
      "Epoch 708/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.5063 - accuracy: 0.8671 - val_loss: 1.8088 - val_accuracy: 0.5467\n",
      "Epoch 709/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.5059 - accuracy: 0.8686 - val_loss: 1.8275 - val_accuracy: 0.5367\n",
      "Epoch 710/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.5044 - accuracy: 0.8671 - val_loss: 1.8058 - val_accuracy: 0.5433\n",
      "Epoch 711/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5045 - accuracy: 0.8714 - val_loss: 1.8110 - val_accuracy: 0.5433\n",
      "Epoch 712/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.5040 - accuracy: 0.8729 - val_loss: 1.8237 - val_accuracy: 0.5467\n",
      "Epoch 713/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.5038 - accuracy: 0.8671 - val_loss: 1.8261 - val_accuracy: 0.5333\n",
      "Epoch 714/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.86 - 0s 106us/step - loss: 0.5018 - accuracy: 0.8671 - val_loss: 1.8254 - val_accuracy: 0.5433\n",
      "Epoch 715/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.5020 - accuracy: 0.8643 - val_loss: 1.8228 - val_accuracy: 0.5467\n",
      "Epoch 716/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5010 - accuracy: 0.8700 - val_loss: 1.8252 - val_accuracy: 0.5400\n",
      "Epoch 717/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.5007 - accuracy: 0.8657 - val_loss: 1.8377 - val_accuracy: 0.5433\n",
      "Epoch 718/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.5011 - accuracy: 0.8714 - val_loss: 1.8413 - val_accuracy: 0.5433\n",
      "Epoch 719/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.5003 - accuracy: 0.8700 - val_loss: 1.8449 - val_accuracy: 0.5400\n",
      "Epoch 720/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4985 - accuracy: 0.8700 - val_loss: 1.8392 - val_accuracy: 0.5400\n",
      "Epoch 721/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4985 - accuracy: 0.8700 - val_loss: 1.8388 - val_accuracy: 0.5467\n",
      "Epoch 722/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 97us/step - loss: 0.5003 - accuracy: 0.8657 - val_loss: 1.8404 - val_accuracy: 0.5433\n",
      "Epoch 723/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4989 - accuracy: 0.8700 - val_loss: 1.8389 - val_accuracy: 0.5367\n",
      "Epoch 724/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.4990 - accuracy: 0.8714 - val_loss: 1.8403 - val_accuracy: 0.5433\n",
      "Epoch 725/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4982 - accuracy: 0.8671 - val_loss: 1.8366 - val_accuracy: 0.5467\n",
      "Epoch 726/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4979 - accuracy: 0.8729 - val_loss: 1.8370 - val_accuracy: 0.5433\n",
      "Epoch 727/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4981 - accuracy: 0.8700 - val_loss: 1.8475 - val_accuracy: 0.5433\n",
      "Epoch 728/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4973 - accuracy: 0.8700 - val_loss: 1.8434 - val_accuracy: 0.5400\n",
      "Epoch 729/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4966 - accuracy: 0.8714 - val_loss: 1.8433 - val_accuracy: 0.5400\n",
      "Epoch 730/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4951 - accuracy: 0.8714 - val_loss: 1.8363 - val_accuracy: 0.5400\n",
      "Epoch 731/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4952 - accuracy: 0.8700 - val_loss: 1.8559 - val_accuracy: 0.5400\n",
      "Epoch 732/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4948 - accuracy: 0.8714 - val_loss: 1.8527 - val_accuracy: 0.5400\n",
      "Epoch 733/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4943 - accuracy: 0.8700 - val_loss: 1.8396 - val_accuracy: 0.5367\n",
      "Epoch 734/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4935 - accuracy: 0.8714 - val_loss: 1.8597 - val_accuracy: 0.5333\n",
      "Epoch 735/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4929 - accuracy: 0.8714 - val_loss: 1.8651 - val_accuracy: 0.5400\n",
      "Epoch 736/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4925 - accuracy: 0.8629 - val_loss: 1.8747 - val_accuracy: 0.5333\n",
      "Epoch 737/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4935 - accuracy: 0.8700 - val_loss: 1.8479 - val_accuracy: 0.5433\n",
      "Epoch 738/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4921 - accuracy: 0.8700 - val_loss: 1.8630 - val_accuracy: 0.5400\n",
      "Epoch 739/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4914 - accuracy: 0.8743 - val_loss: 1.8770 - val_accuracy: 0.5300\n",
      "Epoch 740/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4918 - accuracy: 0.8714 - val_loss: 1.8609 - val_accuracy: 0.5367\n",
      "Epoch 741/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4926 - accuracy: 0.8714 - val_loss: 1.8653 - val_accuracy: 0.5433\n",
      "Epoch 742/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4904 - accuracy: 0.8729 - val_loss: 1.8611 - val_accuracy: 0.5433\n",
      "Epoch 743/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4891 - accuracy: 0.8686 - val_loss: 1.8743 - val_accuracy: 0.5400\n",
      "Epoch 744/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4902 - accuracy: 0.8714 - val_loss: 1.8737 - val_accuracy: 0.5400\n",
      "Epoch 745/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4901 - accuracy: 0.8714 - val_loss: 1.8775 - val_accuracy: 0.5400\n",
      "Epoch 746/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.4910 - accuracy: 0.8729 - val_loss: 1.8726 - val_accuracy: 0.5367\n",
      "Epoch 747/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4913 - accuracy: 0.8743 - val_loss: 1.8737 - val_accuracy: 0.5300\n",
      "Epoch 748/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4898 - accuracy: 0.8714 - val_loss: 1.8776 - val_accuracy: 0.5400\n",
      "Epoch 749/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4880 - accuracy: 0.8771 - val_loss: 1.8770 - val_accuracy: 0.5333\n",
      "Epoch 750/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4874 - accuracy: 0.8743 - val_loss: 1.8837 - val_accuracy: 0.5367\n",
      "Epoch 751/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4886 - accuracy: 0.8743 - val_loss: 1.8882 - val_accuracy: 0.5267\n",
      "Epoch 752/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4868 - accuracy: 0.8743 - val_loss: 1.8961 - val_accuracy: 0.5267\n",
      "Epoch 753/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4854 - accuracy: 0.8714 - val_loss: 1.8947 - val_accuracy: 0.5333\n",
      "Epoch 754/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4880 - accuracy: 0.8729 - val_loss: 1.9005 - val_accuracy: 0.5300\n",
      "Epoch 755/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4860 - accuracy: 0.8729 - val_loss: 1.8932 - val_accuracy: 0.5300\n",
      "Epoch 756/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4857 - accuracy: 0.8786 - val_loss: 1.8853 - val_accuracy: 0.5400\n",
      "Epoch 757/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4876 - accuracy: 0.8729 - val_loss: 1.8917 - val_accuracy: 0.5400\n",
      "Epoch 758/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4835 - accuracy: 0.8771 - val_loss: 1.8904 - val_accuracy: 0.5333\n",
      "Epoch 759/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4860 - accuracy: 0.8729 - val_loss: 1.8895 - val_accuracy: 0.5333\n",
      "Epoch 760/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4838 - accuracy: 0.8743 - val_loss: 1.9006 - val_accuracy: 0.5200\n",
      "Epoch 761/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4858 - accuracy: 0.8771 - val_loss: 1.8886 - val_accuracy: 0.5367\n",
      "Epoch 762/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4820 - accuracy: 0.8714 - val_loss: 1.9007 - val_accuracy: 0.5367\n",
      "Epoch 763/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4836 - accuracy: 0.8771 - val_loss: 1.8985 - val_accuracy: 0.5333\n",
      "Epoch 764/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4832 - accuracy: 0.8771 - val_loss: 1.8986 - val_accuracy: 0.5367\n",
      "Epoch 765/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4817 - accuracy: 0.8757 - val_loss: 1.9146 - val_accuracy: 0.5300\n",
      "Epoch 766/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4827 - accuracy: 0.8800 - val_loss: 1.9047 - val_accuracy: 0.5400\n",
      "Epoch 767/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4823 - accuracy: 0.8771 - val_loss: 1.9037 - val_accuracy: 0.5300\n",
      "Epoch 768/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.4812 - accuracy: 0.8743 - val_loss: 1.9150 - val_accuracy: 0.5233\n",
      "Epoch 769/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4800 - accuracy: 0.8729 - val_loss: 1.9090 - val_accuracy: 0.5400\n",
      "Epoch 770/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4805 - accuracy: 0.8743 - val_loss: 1.9107 - val_accuracy: 0.5400\n",
      "Epoch 771/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4800 - accuracy: 0.8757 - val_loss: 1.9042 - val_accuracy: 0.5333\n",
      "Epoch 772/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4815 - accuracy: 0.8771 - val_loss: 1.9075 - val_accuracy: 0.5367\n",
      "Epoch 773/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4789 - accuracy: 0.8743 - val_loss: 1.9181 - val_accuracy: 0.5267\n",
      "Epoch 774/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4788 - accuracy: 0.8743 - val_loss: 1.9239 - val_accuracy: 0.5233\n",
      "Epoch 775/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.4778 - accuracy: 0.8786 - val_loss: 1.9144 - val_accuracy: 0.5233\n",
      "Epoch 776/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.4776 - accuracy: 0.8771 - val_loss: 1.9180 - val_accuracy: 0.5233\n",
      "Epoch 777/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4786 - accuracy: 0.8757 - val_loss: 1.9049 - val_accuracy: 0.5300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 778/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4785 - accuracy: 0.8771 - val_loss: 1.9079 - val_accuracy: 0.5233\n",
      "Epoch 779/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4785 - accuracy: 0.8771 - val_loss: 1.9137 - val_accuracy: 0.5333\n",
      "Epoch 780/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4785 - accuracy: 0.8729 - val_loss: 1.9156 - val_accuracy: 0.5333\n",
      "Epoch 781/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4761 - accuracy: 0.8786 - val_loss: 1.9257 - val_accuracy: 0.5267\n",
      "Epoch 782/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4771 - accuracy: 0.8743 - val_loss: 1.9146 - val_accuracy: 0.5300\n",
      "Epoch 783/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4759 - accuracy: 0.8786 - val_loss: 1.9234 - val_accuracy: 0.5333\n",
      "Epoch 784/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4766 - accuracy: 0.8714 - val_loss: 1.9257 - val_accuracy: 0.5333\n",
      "Epoch 785/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.4755 - accuracy: 0.8729 - val_loss: 1.9357 - val_accuracy: 0.5233\n",
      "Epoch 786/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4752 - accuracy: 0.8829 - val_loss: 1.9274 - val_accuracy: 0.5367\n",
      "Epoch 787/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4754 - accuracy: 0.8771 - val_loss: 1.9365 - val_accuracy: 0.5133\n",
      "Epoch 788/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4755 - accuracy: 0.8729 - val_loss: 1.9323 - val_accuracy: 0.5333\n",
      "Epoch 789/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4753 - accuracy: 0.8771 - val_loss: 1.9242 - val_accuracy: 0.5300\n",
      "Epoch 790/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.4735 - accuracy: 0.8771 - val_loss: 1.9293 - val_accuracy: 0.5300\n",
      "Epoch 791/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.4735 - accuracy: 0.8771 - val_loss: 1.9378 - val_accuracy: 0.5367\n",
      "Epoch 792/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4729 - accuracy: 0.8814 - val_loss: 1.9370 - val_accuracy: 0.5200\n",
      "Epoch 793/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.4727 - accuracy: 0.8771 - val_loss: 1.9350 - val_accuracy: 0.5200\n",
      "Epoch 794/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4715 - accuracy: 0.8729 - val_loss: 1.9502 - val_accuracy: 0.5233\n",
      "Epoch 795/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4706 - accuracy: 0.8814 - val_loss: 1.9324 - val_accuracy: 0.5133\n",
      "Epoch 796/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4722 - accuracy: 0.8786 - val_loss: 1.9383 - val_accuracy: 0.5267\n",
      "Epoch 797/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4723 - accuracy: 0.8757 - val_loss: 1.9371 - val_accuracy: 0.5233\n",
      "Epoch 798/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4717 - accuracy: 0.8786 - val_loss: 1.9302 - val_accuracy: 0.5267\n",
      "Epoch 799/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4718 - accuracy: 0.8771 - val_loss: 1.9438 - val_accuracy: 0.5267\n",
      "Epoch 800/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4710 - accuracy: 0.8771 - val_loss: 1.9414 - val_accuracy: 0.5133\n",
      "Epoch 801/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4711 - accuracy: 0.8743 - val_loss: 1.9496 - val_accuracy: 0.5200\n",
      "Epoch 802/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4695 - accuracy: 0.8771 - val_loss: 1.9392 - val_accuracy: 0.5333\n",
      "Epoch 803/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4701 - accuracy: 0.8786 - val_loss: 1.9424 - val_accuracy: 0.5233\n",
      "Epoch 804/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4692 - accuracy: 0.8786 - val_loss: 1.9537 - val_accuracy: 0.5267\n",
      "Epoch 805/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4693 - accuracy: 0.8800 - val_loss: 1.9446 - val_accuracy: 0.5267\n",
      "Epoch 806/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4696 - accuracy: 0.8843 - val_loss: 1.9382 - val_accuracy: 0.5333\n",
      "Epoch 807/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4676 - accuracy: 0.8771 - val_loss: 1.9488 - val_accuracy: 0.5300\n",
      "Epoch 808/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4683 - accuracy: 0.8800 - val_loss: 1.9550 - val_accuracy: 0.5300\n",
      "Epoch 809/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4701 - accuracy: 0.8829 - val_loss: 1.9527 - val_accuracy: 0.5233\n",
      "Epoch 810/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4689 - accuracy: 0.8829 - val_loss: 1.9529 - val_accuracy: 0.5333\n",
      "Epoch 811/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.4672 - accuracy: 0.8800 - val_loss: 1.9444 - val_accuracy: 0.5300\n",
      "Epoch 812/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4668 - accuracy: 0.8829 - val_loss: 1.9764 - val_accuracy: 0.5133\n",
      "Epoch 813/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4669 - accuracy: 0.8814 - val_loss: 1.9589 - val_accuracy: 0.5333\n",
      "Epoch 814/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4662 - accuracy: 0.8814 - val_loss: 1.9618 - val_accuracy: 0.5333\n",
      "Epoch 815/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4666 - accuracy: 0.8771 - val_loss: 1.9572 - val_accuracy: 0.5267\n",
      "Epoch 816/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.4662 - accuracy: 0.8800 - val_loss: 1.9675 - val_accuracy: 0.5100\n",
      "Epoch 817/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.4659 - accuracy: 0.8800 - val_loss: 1.9565 - val_accuracy: 0.5300\n",
      "Epoch 818/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4649 - accuracy: 0.8757 - val_loss: 1.9600 - val_accuracy: 0.5267\n",
      "Epoch 819/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4665 - accuracy: 0.8800 - val_loss: 1.9587 - val_accuracy: 0.5267\n",
      "Epoch 820/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4636 - accuracy: 0.8814 - val_loss: 1.9674 - val_accuracy: 0.5200\n",
      "Epoch 821/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.4645 - accuracy: 0.8814 - val_loss: 1.9792 - val_accuracy: 0.5167\n",
      "Epoch 822/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.4630 - accuracy: 0.8771 - val_loss: 1.9712 - val_accuracy: 0.5200\n",
      "Epoch 823/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4639 - accuracy: 0.8829 - val_loss: 1.9774 - val_accuracy: 0.5200\n",
      "Epoch 824/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4606 - accuracy: 0.8857 - val_loss: 1.9746 - val_accuracy: 0.5300\n",
      "Epoch 825/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4630 - accuracy: 0.8771 - val_loss: 1.9623 - val_accuracy: 0.5267\n",
      "Epoch 826/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4619 - accuracy: 0.8786 - val_loss: 1.9737 - val_accuracy: 0.5233\n",
      "Epoch 827/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.4626 - accuracy: 0.8800 - val_loss: 1.9721 - val_accuracy: 0.5267\n",
      "Epoch 828/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4624 - accuracy: 0.8814 - val_loss: 1.9732 - val_accuracy: 0.5233\n",
      "Epoch 829/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4625 - accuracy: 0.8786 - val_loss: 1.9694 - val_accuracy: 0.5267\n",
      "Epoch 830/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4637 - accuracy: 0.8771 - val_loss: 1.9824 - val_accuracy: 0.5200\n",
      "Epoch 831/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4624 - accuracy: 0.8786 - val_loss: 1.9764 - val_accuracy: 0.5167\n",
      "Epoch 832/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4610 - accuracy: 0.8814 - val_loss: 1.9798 - val_accuracy: 0.5167\n",
      "Epoch 833/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 0.4615 - accuracy: 0.8829 - val_loss: 1.9804 - val_accuracy: 0.5267\n",
      "Epoch 834/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4624 - accuracy: 0.8786 - val_loss: 2.0002 - val_accuracy: 0.5200\n",
      "Epoch 835/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4603 - accuracy: 0.8857 - val_loss: 1.9799 - val_accuracy: 0.5267\n",
      "Epoch 836/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4607 - accuracy: 0.8800 - val_loss: 1.9750 - val_accuracy: 0.5300\n",
      "Epoch 837/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4599 - accuracy: 0.8800 - val_loss: 1.9765 - val_accuracy: 0.5200\n",
      "Epoch 838/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.4596 - accuracy: 0.8814 - val_loss: 1.9755 - val_accuracy: 0.5267\n",
      "Epoch 839/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.4602 - accuracy: 0.8800 - val_loss: 1.9895 - val_accuracy: 0.5200\n",
      "Epoch 840/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4584 - accuracy: 0.8843 - val_loss: 1.9846 - val_accuracy: 0.5300\n",
      "Epoch 841/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4593 - accuracy: 0.8843 - val_loss: 1.9835 - val_accuracy: 0.5300\n",
      "Epoch 842/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4574 - accuracy: 0.8800 - val_loss: 1.9952 - val_accuracy: 0.5167\n",
      "Epoch 843/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4582 - accuracy: 0.8814 - val_loss: 1.9961 - val_accuracy: 0.5167\n",
      "Epoch 844/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4578 - accuracy: 0.8871 - val_loss: 1.9936 - val_accuracy: 0.5200\n",
      "Epoch 845/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4576 - accuracy: 0.8814 - val_loss: 1.9810 - val_accuracy: 0.5267\n",
      "Epoch 846/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4572 - accuracy: 0.8814 - val_loss: 1.9936 - val_accuracy: 0.5267\n",
      "Epoch 847/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4568 - accuracy: 0.8814 - val_loss: 2.0038 - val_accuracy: 0.5100\n",
      "Epoch 848/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4571 - accuracy: 0.8814 - val_loss: 2.0134 - val_accuracy: 0.5167\n",
      "Epoch 849/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4567 - accuracy: 0.8829 - val_loss: 2.0009 - val_accuracy: 0.5200\n",
      "Epoch 850/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4573 - accuracy: 0.8843 - val_loss: 2.0036 - val_accuracy: 0.5200\n",
      "Epoch 851/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4555 - accuracy: 0.8900 - val_loss: 2.0039 - val_accuracy: 0.5100\n",
      "Epoch 852/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4557 - accuracy: 0.8800 - val_loss: 1.9940 - val_accuracy: 0.5267\n",
      "Epoch 853/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4537 - accuracy: 0.8800 - val_loss: 2.0035 - val_accuracy: 0.5167\n",
      "Epoch 854/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.4562 - accuracy: 0.8786 - val_loss: 2.0037 - val_accuracy: 0.5200\n",
      "Epoch 855/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4552 - accuracy: 0.8829 - val_loss: 2.0063 - val_accuracy: 0.5133\n",
      "Epoch 856/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.4551 - accuracy: 0.8871 - val_loss: 2.0145 - val_accuracy: 0.5100\n",
      "Epoch 857/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.4530 - accuracy: 0.8800 - val_loss: 2.0073 - val_accuracy: 0.5267\n",
      "Epoch 858/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.4553 - accuracy: 0.8800 - val_loss: 2.0169 - val_accuracy: 0.5167\n",
      "Epoch 859/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4540 - accuracy: 0.8843 - val_loss: 2.0061 - val_accuracy: 0.5200\n",
      "Epoch 860/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4528 - accuracy: 0.8814 - val_loss: 2.0100 - val_accuracy: 0.5200\n",
      "Epoch 861/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4527 - accuracy: 0.8857 - val_loss: 2.0235 - val_accuracy: 0.5067\n",
      "Epoch 862/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4531 - accuracy: 0.8800 - val_loss: 2.0089 - val_accuracy: 0.5233\n",
      "Epoch 863/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.4529 - accuracy: 0.8843 - val_loss: 2.0335 - val_accuracy: 0.5100\n",
      "Epoch 864/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4521 - accuracy: 0.8800 - val_loss: 2.0215 - val_accuracy: 0.5133\n",
      "Epoch 865/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4509 - accuracy: 0.8843 - val_loss: 2.0237 - val_accuracy: 0.5200\n",
      "Epoch 866/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4519 - accuracy: 0.8857 - val_loss: 2.0205 - val_accuracy: 0.5167\n",
      "Epoch 867/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4531 - accuracy: 0.8843 - val_loss: 2.0180 - val_accuracy: 0.5133\n",
      "Epoch 868/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4518 - accuracy: 0.8857 - val_loss: 2.0193 - val_accuracy: 0.5100\n",
      "Epoch 869/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4505 - accuracy: 0.8857 - val_loss: 2.0319 - val_accuracy: 0.5167\n",
      "Epoch 870/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4517 - accuracy: 0.8843 - val_loss: 2.0145 - val_accuracy: 0.5267\n",
      "Epoch 871/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4507 - accuracy: 0.8829 - val_loss: 2.0164 - val_accuracy: 0.5200\n",
      "Epoch 872/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4507 - accuracy: 0.8829 - val_loss: 2.0191 - val_accuracy: 0.5233\n",
      "Epoch 873/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4503 - accuracy: 0.8857 - val_loss: 2.0201 - val_accuracy: 0.5200\n",
      "Epoch 874/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4493 - accuracy: 0.8857 - val_loss: 2.0225 - val_accuracy: 0.5200\n",
      "Epoch 875/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4486 - accuracy: 0.8829 - val_loss: 2.0288 - val_accuracy: 0.5133\n",
      "Epoch 876/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4491 - accuracy: 0.8829 - val_loss: 2.0292 - val_accuracy: 0.5167\n",
      "Epoch 877/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4487 - accuracy: 0.8829 - val_loss: 2.0469 - val_accuracy: 0.5133\n",
      "Epoch 878/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.4478 - accuracy: 0.8843 - val_loss: 2.0376 - val_accuracy: 0.5100\n",
      "Epoch 879/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4479 - accuracy: 0.8871 - val_loss: 2.0394 - val_accuracy: 0.5100\n",
      "Epoch 880/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4482 - accuracy: 0.8829 - val_loss: 2.0376 - val_accuracy: 0.5100\n",
      "Epoch 881/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4487 - accuracy: 0.8871 - val_loss: 2.0277 - val_accuracy: 0.5200\n",
      "Epoch 882/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4491 - accuracy: 0.8843 - val_loss: 2.0453 - val_accuracy: 0.5100\n",
      "Epoch 883/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4472 - accuracy: 0.8814 - val_loss: 2.0330 - val_accuracy: 0.5133\n",
      "Epoch 884/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.4460 - accuracy: 0.8843 - val_loss: 2.0340 - val_accuracy: 0.5133\n",
      "Epoch 885/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.4456 - accuracy: 0.8857 - val_loss: 2.0403 - val_accuracy: 0.5133\n",
      "Epoch 886/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4466 - accuracy: 0.8829 - val_loss: 2.0416 - val_accuracy: 0.5167\n",
      "Epoch 887/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4464 - accuracy: 0.8857 - val_loss: 2.0413 - val_accuracy: 0.5133\n",
      "Epoch 888/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4459 - accuracy: 0.8843 - val_loss: 2.0459 - val_accuracy: 0.5067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 889/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4458 - accuracy: 0.8857 - val_loss: 2.0359 - val_accuracy: 0.5133\n",
      "Epoch 890/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4450 - accuracy: 0.8786 - val_loss: 2.0447 - val_accuracy: 0.5133\n",
      "Epoch 891/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4440 - accuracy: 0.8814 - val_loss: 2.0385 - val_accuracy: 0.5233\n",
      "Epoch 892/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4452 - accuracy: 0.8857 - val_loss: 2.0604 - val_accuracy: 0.5100\n",
      "Epoch 893/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4447 - accuracy: 0.8900 - val_loss: 2.0464 - val_accuracy: 0.5067\n",
      "Epoch 894/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4447 - accuracy: 0.8886 - val_loss: 2.0551 - val_accuracy: 0.5000\n",
      "Epoch 895/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4452 - accuracy: 0.8857 - val_loss: 2.0548 - val_accuracy: 0.5100\n",
      "Epoch 896/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4441 - accuracy: 0.8929 - val_loss: 2.0612 - val_accuracy: 0.5067\n",
      "Epoch 897/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4436 - accuracy: 0.8914 - val_loss: 2.0518 - val_accuracy: 0.5100\n",
      "Epoch 898/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.4438 - accuracy: 0.8843 - val_loss: 2.0562 - val_accuracy: 0.5100\n",
      "Epoch 899/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4433 - accuracy: 0.8900 - val_loss: 2.0727 - val_accuracy: 0.5100\n",
      "Epoch 900/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4433 - accuracy: 0.8929 - val_loss: 2.0622 - val_accuracy: 0.5133\n",
      "Epoch 901/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4419 - accuracy: 0.8871 - val_loss: 2.0641 - val_accuracy: 0.5133\n",
      "Epoch 902/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4413 - accuracy: 0.8871 - val_loss: 2.0601 - val_accuracy: 0.5167\n",
      "Epoch 903/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4414 - accuracy: 0.8886 - val_loss: 2.0671 - val_accuracy: 0.5100\n",
      "Epoch 904/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4428 - accuracy: 0.8829 - val_loss: 2.0573 - val_accuracy: 0.5133\n",
      "Epoch 905/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4408 - accuracy: 0.8857 - val_loss: 2.0648 - val_accuracy: 0.5133\n",
      "Epoch 906/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4403 - accuracy: 0.8843 - val_loss: 2.0775 - val_accuracy: 0.5067\n",
      "Epoch 907/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4412 - accuracy: 0.8829 - val_loss: 2.0527 - val_accuracy: 0.5100\n",
      "Epoch 908/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4390 - accuracy: 0.8871 - val_loss: 2.0640 - val_accuracy: 0.5100\n",
      "Epoch 909/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4402 - accuracy: 0.8857 - val_loss: 2.0728 - val_accuracy: 0.5033\n",
      "Epoch 910/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4384 - accuracy: 0.8914 - val_loss: 2.0782 - val_accuracy: 0.4933\n",
      "Epoch 911/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4399 - accuracy: 0.8914 - val_loss: 2.0796 - val_accuracy: 0.5033\n",
      "Epoch 912/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4401 - accuracy: 0.8871 - val_loss: 2.0682 - val_accuracy: 0.5033\n",
      "Epoch 913/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4401 - accuracy: 0.8871 - val_loss: 2.0651 - val_accuracy: 0.5067\n",
      "Epoch 914/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4392 - accuracy: 0.8886 - val_loss: 2.0790 - val_accuracy: 0.5033\n",
      "Epoch 915/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4396 - accuracy: 0.8886 - val_loss: 2.0823 - val_accuracy: 0.5033\n",
      "Epoch 916/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4392 - accuracy: 0.8914 - val_loss: 2.0793 - val_accuracy: 0.5067\n",
      "Epoch 917/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4387 - accuracy: 0.8914 - val_loss: 2.0875 - val_accuracy: 0.5067\n",
      "Epoch 918/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 0.4377 - accuracy: 0.8843 - val_loss: 2.0916 - val_accuracy: 0.5133\n",
      "Epoch 919/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4377 - accuracy: 0.8886 - val_loss: 2.0911 - val_accuracy: 0.5000\n",
      "Epoch 920/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4371 - accuracy: 0.8886 - val_loss: 2.0799 - val_accuracy: 0.5033\n",
      "Epoch 921/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4380 - accuracy: 0.8929 - val_loss: 2.0884 - val_accuracy: 0.5100\n",
      "Epoch 922/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4366 - accuracy: 0.8914 - val_loss: 2.0864 - val_accuracy: 0.5067\n",
      "Epoch 923/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4366 - accuracy: 0.8886 - val_loss: 2.0951 - val_accuracy: 0.5133\n",
      "Epoch 924/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4382 - accuracy: 0.8871 - val_loss: 2.0964 - val_accuracy: 0.5033\n",
      "Epoch 925/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4379 - accuracy: 0.8900 - val_loss: 2.0872 - val_accuracy: 0.5033\n",
      "Epoch 926/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4364 - accuracy: 0.8929 - val_loss: 2.0931 - val_accuracy: 0.5067\n",
      "Epoch 927/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4369 - accuracy: 0.8900 - val_loss: 2.0902 - val_accuracy: 0.5033\n",
      "Epoch 928/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4354 - accuracy: 0.8900 - val_loss: 2.1079 - val_accuracy: 0.5000\n",
      "Epoch 929/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4370 - accuracy: 0.8914 - val_loss: 2.0873 - val_accuracy: 0.5067\n",
      "Epoch 930/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4363 - accuracy: 0.8900 - val_loss: 2.0901 - val_accuracy: 0.5100\n",
      "Epoch 931/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4345 - accuracy: 0.8886 - val_loss: 2.1044 - val_accuracy: 0.5167\n",
      "Epoch 932/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4350 - accuracy: 0.8871 - val_loss: 2.1076 - val_accuracy: 0.5033\n",
      "Epoch 933/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4338 - accuracy: 0.8900 - val_loss: 2.0992 - val_accuracy: 0.4933\n",
      "Epoch 934/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4358 - accuracy: 0.8886 - val_loss: 2.1186 - val_accuracy: 0.5067\n",
      "Epoch 935/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4345 - accuracy: 0.8914 - val_loss: 2.1107 - val_accuracy: 0.5100\n",
      "Epoch 936/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4327 - accuracy: 0.8929 - val_loss: 2.0999 - val_accuracy: 0.5067\n",
      "Epoch 937/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4342 - accuracy: 0.8929 - val_loss: 2.1115 - val_accuracy: 0.5000\n",
      "Epoch 938/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4325 - accuracy: 0.8857 - val_loss: 2.1251 - val_accuracy: 0.5033\n",
      "Epoch 939/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4348 - accuracy: 0.8929 - val_loss: 2.1159 - val_accuracy: 0.4967\n",
      "Epoch 940/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4335 - accuracy: 0.8943 - val_loss: 2.0981 - val_accuracy: 0.4967\n",
      "Epoch 941/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.4316 - accuracy: 0.8914 - val_loss: 2.1105 - val_accuracy: 0.5000\n",
      "Epoch 942/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4310 - accuracy: 0.8886 - val_loss: 2.1175 - val_accuracy: 0.5000\n",
      "Epoch 943/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4305 - accuracy: 0.8914 - val_loss: 2.1082 - val_accuracy: 0.4900\n",
      "Epoch 944/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.4324 - accuracy: 0.8900 - val_loss: 2.1083 - val_accuracy: 0.5067\n",
      "Epoch 945/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4323 - accuracy: 0.8886 - val_loss: 2.0951 - val_accuracy: 0.5067\n",
      "Epoch 946/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4322 - accuracy: 0.8886 - val_loss: 2.1101 - val_accuracy: 0.5000\n",
      "Epoch 947/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4308 - accuracy: 0.8914 - val_loss: 2.1118 - val_accuracy: 0.5000\n",
      "Epoch 948/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4314 - accuracy: 0.8886 - val_loss: 2.1267 - val_accuracy: 0.5067\n",
      "Epoch 949/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4314 - accuracy: 0.8914 - val_loss: 2.1240 - val_accuracy: 0.5067\n",
      "Epoch 950/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4306 - accuracy: 0.8914 - val_loss: 2.1221 - val_accuracy: 0.4967\n",
      "Epoch 951/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4293 - accuracy: 0.8986 - val_loss: 2.1179 - val_accuracy: 0.4933\n",
      "Epoch 952/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4301 - accuracy: 0.8929 - val_loss: 2.1283 - val_accuracy: 0.4967\n",
      "Epoch 953/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4299 - accuracy: 0.8871 - val_loss: 2.1074 - val_accuracy: 0.5000\n",
      "Epoch 954/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4299 - accuracy: 0.8929 - val_loss: 2.1334 - val_accuracy: 0.5067\n",
      "Epoch 955/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4300 - accuracy: 0.8929 - val_loss: 2.1186 - val_accuracy: 0.4967\n",
      "Epoch 956/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4298 - accuracy: 0.8857 - val_loss: 2.1370 - val_accuracy: 0.5000\n",
      "Epoch 957/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4294 - accuracy: 0.8914 - val_loss: 2.1159 - val_accuracy: 0.4967\n",
      "Epoch 958/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4286 - accuracy: 0.8900 - val_loss: 2.1235 - val_accuracy: 0.4967\n",
      "Epoch 959/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4286 - accuracy: 0.8929 - val_loss: 2.1323 - val_accuracy: 0.5033\n",
      "Epoch 960/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4274 - accuracy: 0.8929 - val_loss: 2.1302 - val_accuracy: 0.5000\n",
      "Epoch 961/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4269 - accuracy: 0.8914 - val_loss: 2.1251 - val_accuracy: 0.4900\n",
      "Epoch 962/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4287 - accuracy: 0.8914 - val_loss: 2.1122 - val_accuracy: 0.5033\n",
      "Epoch 963/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4277 - accuracy: 0.8929 - val_loss: 2.1314 - val_accuracy: 0.5033\n",
      "Epoch 964/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4277 - accuracy: 0.8886 - val_loss: 2.1279 - val_accuracy: 0.4967\n",
      "Epoch 965/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4264 - accuracy: 0.8929 - val_loss: 2.1197 - val_accuracy: 0.5067\n",
      "Epoch 966/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4277 - accuracy: 0.8943 - val_loss: 2.1369 - val_accuracy: 0.5033\n",
      "Epoch 967/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4276 - accuracy: 0.9000 - val_loss: 2.1297 - val_accuracy: 0.4900\n",
      "Epoch 968/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.4269 - accuracy: 0.8929 - val_loss: 2.1445 - val_accuracy: 0.4967\n",
      "Epoch 969/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.4262 - accuracy: 0.8943 - val_loss: 2.1364 - val_accuracy: 0.4900\n",
      "Epoch 970/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4254 - accuracy: 0.8957 - val_loss: 2.1363 - val_accuracy: 0.4967\n",
      "Epoch 971/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4253 - accuracy: 0.8871 - val_loss: 2.1467 - val_accuracy: 0.5067\n",
      "Epoch 972/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4251 - accuracy: 0.8986 - val_loss: 2.1415 - val_accuracy: 0.5200\n",
      "Epoch 973/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4258 - accuracy: 0.8914 - val_loss: 2.1440 - val_accuracy: 0.5033\n",
      "Epoch 974/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4258 - accuracy: 0.8886 - val_loss: 2.1541 - val_accuracy: 0.5067\n",
      "Epoch 975/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4258 - accuracy: 0.8943 - val_loss: 2.1459 - val_accuracy: 0.5033\n",
      "Epoch 976/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4245 - accuracy: 0.8929 - val_loss: 2.1399 - val_accuracy: 0.4967\n",
      "Epoch 977/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4237 - accuracy: 0.8957 - val_loss: 2.1422 - val_accuracy: 0.5000\n",
      "Epoch 978/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.4232 - accuracy: 0.9000 - val_loss: 2.1432 - val_accuracy: 0.5000\n",
      "Epoch 979/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4253 - accuracy: 0.8929 - val_loss: 2.1492 - val_accuracy: 0.4967\n",
      "Epoch 980/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4230 - accuracy: 0.8929 - val_loss: 2.1530 - val_accuracy: 0.5000\n",
      "Epoch 981/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4234 - accuracy: 0.8886 - val_loss: 2.1507 - val_accuracy: 0.5033\n",
      "Epoch 982/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4236 - accuracy: 0.8943 - val_loss: 2.1592 - val_accuracy: 0.4900\n",
      "Epoch 983/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4236 - accuracy: 0.8943 - val_loss: 2.1454 - val_accuracy: 0.4867\n",
      "Epoch 984/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.4218 - accuracy: 0.8957 - val_loss: 2.1511 - val_accuracy: 0.4900\n",
      "Epoch 985/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4225 - accuracy: 0.8943 - val_loss: 2.1509 - val_accuracy: 0.4933\n",
      "Epoch 986/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4231 - accuracy: 0.8929 - val_loss: 2.1567 - val_accuracy: 0.4967\n",
      "Epoch 987/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.4205 - accuracy: 0.8971 - val_loss: 2.1634 - val_accuracy: 0.4933\n",
      "Epoch 988/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.4226 - accuracy: 0.8929 - val_loss: 2.1693 - val_accuracy: 0.5033\n",
      "Epoch 989/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4216 - accuracy: 0.8914 - val_loss: 2.1634 - val_accuracy: 0.5100\n",
      "Epoch 990/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4208 - accuracy: 0.8957 - val_loss: 2.1660 - val_accuracy: 0.5067\n",
      "Epoch 991/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4208 - accuracy: 0.8957 - val_loss: 2.1626 - val_accuracy: 0.4867\n",
      "Epoch 992/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4221 - accuracy: 0.8943 - val_loss: 2.1614 - val_accuracy: 0.4967\n",
      "Epoch 993/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4209 - accuracy: 0.9014 - val_loss: 2.1594 - val_accuracy: 0.5000\n",
      "Epoch 994/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4198 - accuracy: 0.8957 - val_loss: 2.1711 - val_accuracy: 0.5000\n",
      "Epoch 995/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4214 - accuracy: 0.8971 - val_loss: 2.1698 - val_accuracy: 0.4900\n",
      "Epoch 996/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4192 - accuracy: 0.8971 - val_loss: 2.1699 - val_accuracy: 0.4967\n",
      "Epoch 997/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4195 - accuracy: 0.8929 - val_loss: 2.1749 - val_accuracy: 0.4933\n",
      "Epoch 998/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4203 - accuracy: 0.8914 - val_loss: 2.1847 - val_accuracy: 0.5000\n",
      "Epoch 999/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4191 - accuracy: 0.8943 - val_loss: 2.1622 - val_accuracy: 0.4900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.4202 - accuracy: 0.8929 - val_loss: 2.1659 - val_accuracy: 0.4933\n",
      "Epoch 1001/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4181 - accuracy: 0.8929 - val_loss: 2.1677 - val_accuracy: 0.4933\n",
      "Epoch 1002/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4189 - accuracy: 0.8943 - val_loss: 2.1807 - val_accuracy: 0.5000\n",
      "Epoch 1003/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4187 - accuracy: 0.8957 - val_loss: 2.1851 - val_accuracy: 0.5000\n",
      "Epoch 1004/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4187 - accuracy: 0.8971 - val_loss: 2.1832 - val_accuracy: 0.4900\n",
      "Epoch 1005/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4174 - accuracy: 0.8929 - val_loss: 2.1874 - val_accuracy: 0.4900\n",
      "Epoch 1006/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4191 - accuracy: 0.8943 - val_loss: 2.1871 - val_accuracy: 0.4967\n",
      "Epoch 1007/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4176 - accuracy: 0.8900 - val_loss: 2.1931 - val_accuracy: 0.4900\n",
      "Epoch 1008/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4172 - accuracy: 0.8971 - val_loss: 2.1907 - val_accuracy: 0.4833\n",
      "Epoch 1009/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4180 - accuracy: 0.8900 - val_loss: 2.1913 - val_accuracy: 0.4833\n",
      "Epoch 1010/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4165 - accuracy: 0.8971 - val_loss: 2.1830 - val_accuracy: 0.4967\n",
      "Epoch 1011/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4174 - accuracy: 0.8957 - val_loss: 2.2001 - val_accuracy: 0.4967\n",
      "Epoch 1012/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4163 - accuracy: 0.9014 - val_loss: 2.1994 - val_accuracy: 0.4967\n",
      "Epoch 1013/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4167 - accuracy: 0.8957 - val_loss: 2.1826 - val_accuracy: 0.4933\n",
      "Epoch 1014/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4175 - accuracy: 0.8957 - val_loss: 2.1956 - val_accuracy: 0.4833\n",
      "Epoch 1015/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4165 - accuracy: 0.8986 - val_loss: 2.1968 - val_accuracy: 0.4867\n",
      "Epoch 1016/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4166 - accuracy: 0.8971 - val_loss: 2.1999 - val_accuracy: 0.4967\n",
      "Epoch 1017/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4159 - accuracy: 0.9000 - val_loss: 2.2033 - val_accuracy: 0.4933\n",
      "Epoch 1018/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4167 - accuracy: 0.8957 - val_loss: 2.1955 - val_accuracy: 0.4833\n",
      "Epoch 1019/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4155 - accuracy: 0.8957 - val_loss: 2.1983 - val_accuracy: 0.4833\n",
      "Epoch 1020/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4148 - accuracy: 0.8986 - val_loss: 2.1986 - val_accuracy: 0.4867\n",
      "Epoch 1021/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4147 - accuracy: 0.8971 - val_loss: 2.2091 - val_accuracy: 0.4867\n",
      "Epoch 1022/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4153 - accuracy: 0.8986 - val_loss: 2.2051 - val_accuracy: 0.4900\n",
      "Epoch 1023/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4147 - accuracy: 0.9000 - val_loss: 2.2035 - val_accuracy: 0.5000\n",
      "Epoch 1024/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4133 - accuracy: 0.8957 - val_loss: 2.2115 - val_accuracy: 0.4967\n",
      "Epoch 1025/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4141 - accuracy: 0.8986 - val_loss: 2.2084 - val_accuracy: 0.4933\n",
      "Epoch 1026/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4138 - accuracy: 0.9000 - val_loss: 2.2028 - val_accuracy: 0.4867\n",
      "Epoch 1027/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4136 - accuracy: 0.9000 - val_loss: 2.1924 - val_accuracy: 0.4933\n",
      "Epoch 1028/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.4135 - accuracy: 0.9000 - val_loss: 2.1938 - val_accuracy: 0.4967\n",
      "Epoch 1029/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4145 - accuracy: 0.8929 - val_loss: 2.2234 - val_accuracy: 0.5000\n",
      "Epoch 1030/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4127 - accuracy: 0.9043 - val_loss: 2.1979 - val_accuracy: 0.4967\n",
      "Epoch 1031/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4127 - accuracy: 0.8957 - val_loss: 2.2101 - val_accuracy: 0.4933\n",
      "Epoch 1032/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4134 - accuracy: 0.8986 - val_loss: 2.2090 - val_accuracy: 0.4867\n",
      "Epoch 1033/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4117 - accuracy: 0.8986 - val_loss: 2.2176 - val_accuracy: 0.4933\n",
      "Epoch 1034/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4111 - accuracy: 0.8971 - val_loss: 2.2075 - val_accuracy: 0.4933\n",
      "Epoch 1035/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4116 - accuracy: 0.9000 - val_loss: 2.2303 - val_accuracy: 0.4967\n",
      "Epoch 1036/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4125 - accuracy: 0.9043 - val_loss: 2.2196 - val_accuracy: 0.4800\n",
      "Epoch 1037/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4117 - accuracy: 0.8971 - val_loss: 2.2328 - val_accuracy: 0.4967\n",
      "Epoch 1038/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4113 - accuracy: 0.8986 - val_loss: 2.2239 - val_accuracy: 0.4900\n",
      "Epoch 1039/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4115 - accuracy: 0.8986 - val_loss: 2.2180 - val_accuracy: 0.4933\n",
      "Epoch 1040/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4097 - accuracy: 0.8986 - val_loss: 2.2202 - val_accuracy: 0.4867\n",
      "Epoch 1041/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4107 - accuracy: 0.9000 - val_loss: 2.2216 - val_accuracy: 0.4900\n",
      "Epoch 1042/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4109 - accuracy: 0.9000 - val_loss: 2.2267 - val_accuracy: 0.4900\n",
      "Epoch 1043/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.4103 - accuracy: 0.9014 - val_loss: 2.2275 - val_accuracy: 0.4867\n",
      "Epoch 1044/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4097 - accuracy: 0.9029 - val_loss: 2.2296 - val_accuracy: 0.4867\n",
      "Epoch 1045/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.4101 - accuracy: 0.9000 - val_loss: 2.2368 - val_accuracy: 0.4933\n",
      "Epoch 1046/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4093 - accuracy: 0.9014 - val_loss: 2.2417 - val_accuracy: 0.4800\n",
      "Epoch 1047/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.4090 - accuracy: 0.9000 - val_loss: 2.2306 - val_accuracy: 0.4900\n",
      "Epoch 1048/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4085 - accuracy: 0.9000 - val_loss: 2.2255 - val_accuracy: 0.4900\n",
      "Epoch 1049/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4096 - accuracy: 0.9000 - val_loss: 2.2332 - val_accuracy: 0.4900\n",
      "Epoch 1050/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.4089 - accuracy: 0.8971 - val_loss: 2.2378 - val_accuracy: 0.4900\n",
      "Epoch 1051/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4091 - accuracy: 0.9043 - val_loss: 2.2315 - val_accuracy: 0.4900\n",
      "Epoch 1052/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4102 - accuracy: 0.9000 - val_loss: 2.2347 - val_accuracy: 0.4867\n",
      "Epoch 1053/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4099 - accuracy: 0.8986 - val_loss: 2.2398 - val_accuracy: 0.4867\n",
      "Epoch 1054/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.4081 - accuracy: 0.9014 - val_loss: 2.2356 - val_accuracy: 0.4867\n",
      "Epoch 1055/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 103us/step - loss: 0.4087 - accuracy: 0.9014 - val_loss: 2.2504 - val_accuracy: 0.4900\n",
      "Epoch 1056/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4086 - accuracy: 0.9000 - val_loss: 2.2601 - val_accuracy: 0.4967\n",
      "Epoch 1057/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4076 - accuracy: 0.9014 - val_loss: 2.2513 - val_accuracy: 0.4833\n",
      "Epoch 1058/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4079 - accuracy: 0.8986 - val_loss: 2.2439 - val_accuracy: 0.4833\n",
      "Epoch 1059/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4079 - accuracy: 0.9014 - val_loss: 2.2465 - val_accuracy: 0.4867\n",
      "Epoch 1060/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4070 - accuracy: 0.8971 - val_loss: 2.2580 - val_accuracy: 0.4833\n",
      "Epoch 1061/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4063 - accuracy: 0.9043 - val_loss: 2.2488 - val_accuracy: 0.5000\n",
      "Epoch 1062/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4067 - accuracy: 0.9029 - val_loss: 2.2501 - val_accuracy: 0.4867\n",
      "Epoch 1063/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4064 - accuracy: 0.9014 - val_loss: 2.2472 - val_accuracy: 0.4867\n",
      "Epoch 1064/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4065 - accuracy: 0.9014 - val_loss: 2.2598 - val_accuracy: 0.4900\n",
      "Epoch 1065/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4068 - accuracy: 0.9057 - val_loss: 2.2589 - val_accuracy: 0.4833\n",
      "Epoch 1066/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4043 - accuracy: 0.9014 - val_loss: 2.2647 - val_accuracy: 0.4967\n",
      "Epoch 1067/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4052 - accuracy: 0.9014 - val_loss: 2.2665 - val_accuracy: 0.4900\n",
      "Epoch 1068/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4054 - accuracy: 0.8986 - val_loss: 2.2543 - val_accuracy: 0.4933\n",
      "Epoch 1069/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4054 - accuracy: 0.9014 - val_loss: 2.2635 - val_accuracy: 0.4867\n",
      "Epoch 1070/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4043 - accuracy: 0.9029 - val_loss: 2.2590 - val_accuracy: 0.4867\n",
      "Epoch 1071/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4052 - accuracy: 0.8986 - val_loss: 2.2642 - val_accuracy: 0.4833\n",
      "Epoch 1072/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.4065 - accuracy: 0.9014 - val_loss: 2.2575 - val_accuracy: 0.4933\n",
      "Epoch 1073/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.4039 - accuracy: 0.9014 - val_loss: 2.2583 - val_accuracy: 0.4967\n",
      "Epoch 1074/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4060 - accuracy: 0.9000 - val_loss: 2.2724 - val_accuracy: 0.4800\n",
      "Epoch 1075/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4025 - accuracy: 0.8943 - val_loss: 2.2605 - val_accuracy: 0.4900\n",
      "Epoch 1076/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4051 - accuracy: 0.9029 - val_loss: 2.2623 - val_accuracy: 0.4833\n",
      "Epoch 1077/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4044 - accuracy: 0.9014 - val_loss: 2.2594 - val_accuracy: 0.4900\n",
      "Epoch 1078/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4045 - accuracy: 0.9014 - val_loss: 2.2577 - val_accuracy: 0.4933\n",
      "Epoch 1079/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.4031 - accuracy: 0.8986 - val_loss: 2.2620 - val_accuracy: 0.4833\n",
      "Epoch 1080/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4027 - accuracy: 0.9014 - val_loss: 2.2591 - val_accuracy: 0.4833\n",
      "Epoch 1081/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.4034 - accuracy: 0.8986 - val_loss: 2.2745 - val_accuracy: 0.4900\n",
      "Epoch 1082/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4030 - accuracy: 0.9057 - val_loss: 2.2700 - val_accuracy: 0.4867\n",
      "Epoch 1083/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4022 - accuracy: 0.9029 - val_loss: 2.2794 - val_accuracy: 0.4933\n",
      "Epoch 1084/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.4025 - accuracy: 0.9014 - val_loss: 2.2746 - val_accuracy: 0.4833\n",
      "Epoch 1085/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.4019 - accuracy: 0.9043 - val_loss: 2.2686 - val_accuracy: 0.4900\n",
      "Epoch 1086/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4017 - accuracy: 0.9057 - val_loss: 2.2666 - val_accuracy: 0.4833\n",
      "Epoch 1087/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.4020 - accuracy: 0.9029 - val_loss: 2.2777 - val_accuracy: 0.4867\n",
      "Epoch 1088/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4009 - accuracy: 0.9014 - val_loss: 2.2841 - val_accuracy: 0.5000\n",
      "Epoch 1089/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4005 - accuracy: 0.9014 - val_loss: 2.2747 - val_accuracy: 0.4900\n",
      "Epoch 1090/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.4010 - accuracy: 0.9000 - val_loss: 2.2784 - val_accuracy: 0.4867\n",
      "Epoch 1091/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.4015 - accuracy: 0.9029 - val_loss: 2.2820 - val_accuracy: 0.4900\n",
      "Epoch 1092/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.4012 - accuracy: 0.9014 - val_loss: 2.2748 - val_accuracy: 0.4900\n",
      "Epoch 1093/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4023 - accuracy: 0.9043 - val_loss: 2.2769 - val_accuracy: 0.4867\n",
      "Epoch 1094/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3997 - accuracy: 0.9029 - val_loss: 2.2930 - val_accuracy: 0.4933\n",
      "Epoch 1095/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.4004 - accuracy: 0.9000 - val_loss: 2.2743 - val_accuracy: 0.4833\n",
      "Epoch 1096/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4011 - accuracy: 0.9043 - val_loss: 2.2887 - val_accuracy: 0.4867\n",
      "Epoch 1097/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3996 - accuracy: 0.9071 - val_loss: 2.2937 - val_accuracy: 0.4900\n",
      "Epoch 1098/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3994 - accuracy: 0.9000 - val_loss: 2.2925 - val_accuracy: 0.4900\n",
      "Epoch 1099/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.4004 - accuracy: 0.9029 - val_loss: 2.2984 - val_accuracy: 0.4833\n",
      "Epoch 1100/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.4004 - accuracy: 0.9071 - val_loss: 2.2922 - val_accuracy: 0.4900\n",
      "Epoch 1101/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3984 - accuracy: 0.9029 - val_loss: 2.2997 - val_accuracy: 0.4900\n",
      "Epoch 1102/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3986 - accuracy: 0.9071 - val_loss: 2.2994 - val_accuracy: 0.4900\n",
      "Epoch 1103/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3972 - accuracy: 0.9014 - val_loss: 2.2920 - val_accuracy: 0.4900\n",
      "Epoch 1104/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3985 - accuracy: 0.9057 - val_loss: 2.2971 - val_accuracy: 0.4867\n",
      "Epoch 1105/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3987 - accuracy: 0.9000 - val_loss: 2.3131 - val_accuracy: 0.4967\n",
      "Epoch 1106/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3990 - accuracy: 0.9043 - val_loss: 2.2919 - val_accuracy: 0.4833\n",
      "Epoch 1107/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3980 - accuracy: 0.9029 - val_loss: 2.3108 - val_accuracy: 0.4833\n",
      "Epoch 1108/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3977 - accuracy: 0.9043 - val_loss: 2.3042 - val_accuracy: 0.4767\n",
      "Epoch 1109/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3978 - accuracy: 0.9000 - val_loss: 2.3196 - val_accuracy: 0.4767\n",
      "Epoch 1110/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.3979 - accuracy: 0.9043 - val_loss: 2.3152 - val_accuracy: 0.4900\n",
      "Epoch 1111/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3985 - accuracy: 0.9014 - val_loss: 2.2953 - val_accuracy: 0.4933\n",
      "Epoch 1112/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3986 - accuracy: 0.9057 - val_loss: 2.3017 - val_accuracy: 0.4900\n",
      "Epoch 1113/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3972 - accuracy: 0.9043 - val_loss: 2.3033 - val_accuracy: 0.4767\n",
      "Epoch 1114/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3969 - accuracy: 0.9000 - val_loss: 2.3079 - val_accuracy: 0.4800\n",
      "Epoch 1115/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3971 - accuracy: 0.9029 - val_loss: 2.3065 - val_accuracy: 0.4800\n",
      "Epoch 1116/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3972 - accuracy: 0.9000 - val_loss: 2.3246 - val_accuracy: 0.4900\n",
      "Epoch 1117/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3963 - accuracy: 0.9057 - val_loss: 2.3107 - val_accuracy: 0.4933\n",
      "Epoch 1118/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3966 - accuracy: 0.9029 - val_loss: 2.3170 - val_accuracy: 0.4900\n",
      "Epoch 1119/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3964 - accuracy: 0.9029 - val_loss: 2.3188 - val_accuracy: 0.4867\n",
      "Epoch 1120/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3973 - accuracy: 0.9057 - val_loss: 2.3100 - val_accuracy: 0.4900\n",
      "Epoch 1121/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3957 - accuracy: 0.9029 - val_loss: 2.3204 - val_accuracy: 0.4900\n",
      "Epoch 1122/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3960 - accuracy: 0.9043 - val_loss: 2.3124 - val_accuracy: 0.4867\n",
      "Epoch 1123/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3952 - accuracy: 0.9043 - val_loss: 2.3320 - val_accuracy: 0.4933\n",
      "Epoch 1124/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3949 - accuracy: 0.9043 - val_loss: 2.3115 - val_accuracy: 0.4800\n",
      "Epoch 1125/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3939 - accuracy: 0.9043 - val_loss: 2.3161 - val_accuracy: 0.4867\n",
      "Epoch 1126/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3954 - accuracy: 0.9029 - val_loss: 2.3153 - val_accuracy: 0.4900\n",
      "Epoch 1127/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3942 - accuracy: 0.9029 - val_loss: 2.3335 - val_accuracy: 0.4967\n",
      "Epoch 1128/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3944 - accuracy: 0.9043 - val_loss: 2.3238 - val_accuracy: 0.4867\n",
      "Epoch 1129/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3962 - accuracy: 0.9029 - val_loss: 2.3225 - val_accuracy: 0.4867\n",
      "Epoch 1130/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3936 - accuracy: 0.9029 - val_loss: 2.3253 - val_accuracy: 0.4833\n",
      "Epoch 1131/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3934 - accuracy: 0.9086 - val_loss: 2.3308 - val_accuracy: 0.4867\n",
      "Epoch 1132/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3928 - accuracy: 0.9057 - val_loss: 2.3271 - val_accuracy: 0.4867\n",
      "Epoch 1133/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3937 - accuracy: 0.9071 - val_loss: 2.3181 - val_accuracy: 0.4933\n",
      "Epoch 1134/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3919 - accuracy: 0.9071 - val_loss: 2.3324 - val_accuracy: 0.4867\n",
      "Epoch 1135/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3925 - accuracy: 0.9043 - val_loss: 2.3335 - val_accuracy: 0.4933\n",
      "Epoch 1136/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3929 - accuracy: 0.9014 - val_loss: 2.3433 - val_accuracy: 0.4800\n",
      "Epoch 1137/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3921 - accuracy: 0.9057 - val_loss: 2.3356 - val_accuracy: 0.4833\n",
      "Epoch 1138/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3938 - accuracy: 0.9029 - val_loss: 2.3341 - val_accuracy: 0.4900\n",
      "Epoch 1139/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3929 - accuracy: 0.9043 - val_loss: 2.3423 - val_accuracy: 0.4900\n",
      "Epoch 1140/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3924 - accuracy: 0.9071 - val_loss: 2.3368 - val_accuracy: 0.4833\n",
      "Epoch 1141/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3918 - accuracy: 0.9100 - val_loss: 2.3427 - val_accuracy: 0.4867\n",
      "Epoch 1142/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3918 - accuracy: 0.9014 - val_loss: 2.3473 - val_accuracy: 0.4867\n",
      "Epoch 1143/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3913 - accuracy: 0.9057 - val_loss: 2.3501 - val_accuracy: 0.4800\n",
      "Epoch 1144/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3920 - accuracy: 0.9043 - val_loss: 2.3551 - val_accuracy: 0.4833\n",
      "Epoch 1145/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3910 - accuracy: 0.9071 - val_loss: 2.3532 - val_accuracy: 0.4900\n",
      "Epoch 1146/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3911 - accuracy: 0.9043 - val_loss: 2.3518 - val_accuracy: 0.4867\n",
      "Epoch 1147/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3925 - accuracy: 0.9043 - val_loss: 2.3474 - val_accuracy: 0.4900\n",
      "Epoch 1148/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3901 - accuracy: 0.9071 - val_loss: 2.3620 - val_accuracy: 0.4900\n",
      "Epoch 1149/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3903 - accuracy: 0.9086 - val_loss: 2.3512 - val_accuracy: 0.4867\n",
      "Epoch 1150/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3899 - accuracy: 0.9057 - val_loss: 2.3487 - val_accuracy: 0.4767\n",
      "Epoch 1151/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3908 - accuracy: 0.9043 - val_loss: 2.3585 - val_accuracy: 0.4833\n",
      "Epoch 1152/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3898 - accuracy: 0.9071 - val_loss: 2.3596 - val_accuracy: 0.4900\n",
      "Epoch 1153/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3893 - accuracy: 0.9057 - val_loss: 2.3541 - val_accuracy: 0.4933\n",
      "Epoch 1154/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3905 - accuracy: 0.9057 - val_loss: 2.3689 - val_accuracy: 0.4833\n",
      "Epoch 1155/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3894 - accuracy: 0.9071 - val_loss: 2.3672 - val_accuracy: 0.4833\n",
      "Epoch 1156/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3894 - accuracy: 0.9057 - val_loss: 2.3580 - val_accuracy: 0.4767\n",
      "Epoch 1157/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3897 - accuracy: 0.9071 - val_loss: 2.3579 - val_accuracy: 0.4833\n",
      "Epoch 1158/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3884 - accuracy: 0.9043 - val_loss: 2.3538 - val_accuracy: 0.4833\n",
      "Epoch 1159/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3896 - accuracy: 0.9043 - val_loss: 2.3522 - val_accuracy: 0.4833\n",
      "Epoch 1160/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3909 - accuracy: 0.9043 - val_loss: 2.3579 - val_accuracy: 0.4900\n",
      "Epoch 1161/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3884 - accuracy: 0.9100 - val_loss: 2.3568 - val_accuracy: 0.4800\n",
      "Epoch 1162/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3894 - accuracy: 0.9071 - val_loss: 2.3605 - val_accuracy: 0.4933\n",
      "Epoch 1163/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3887 - accuracy: 0.9057 - val_loss: 2.3681 - val_accuracy: 0.4933\n",
      "Epoch 1164/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3895 - accuracy: 0.9043 - val_loss: 2.3725 - val_accuracy: 0.4867\n",
      "Epoch 1165/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 0.3882 - accuracy: 0.9057 - val_loss: 2.3756 - val_accuracy: 0.4900\n",
      "Epoch 1166/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3870 - accuracy: 0.9086 - val_loss: 2.3596 - val_accuracy: 0.4933\n",
      "Epoch 1167/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3878 - accuracy: 0.9057 - val_loss: 2.3637 - val_accuracy: 0.4867\n",
      "Epoch 1168/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3874 - accuracy: 0.9057 - val_loss: 2.3749 - val_accuracy: 0.4833\n",
      "Epoch 1169/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3881 - accuracy: 0.9071 - val_loss: 2.3741 - val_accuracy: 0.4900\n",
      "Epoch 1170/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3871 - accuracy: 0.9071 - val_loss: 2.3652 - val_accuracy: 0.4800\n",
      "Epoch 1171/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3865 - accuracy: 0.9100 - val_loss: 2.3667 - val_accuracy: 0.4867\n",
      "Epoch 1172/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3884 - accuracy: 0.9100 - val_loss: 2.3739 - val_accuracy: 0.4767\n",
      "Epoch 1173/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3867 - accuracy: 0.9043 - val_loss: 2.3931 - val_accuracy: 0.4900\n",
      "Epoch 1174/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3865 - accuracy: 0.9086 - val_loss: 2.3864 - val_accuracy: 0.4967\n",
      "Epoch 1175/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3866 - accuracy: 0.9100 - val_loss: 2.3854 - val_accuracy: 0.4767\n",
      "Epoch 1176/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3861 - accuracy: 0.9071 - val_loss: 2.3895 - val_accuracy: 0.4900\n",
      "Epoch 1177/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3860 - accuracy: 0.9086 - val_loss: 2.3728 - val_accuracy: 0.4867\n",
      "Epoch 1178/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3856 - accuracy: 0.9043 - val_loss: 2.3886 - val_accuracy: 0.4800\n",
      "Epoch 1179/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3859 - accuracy: 0.9057 - val_loss: 2.3833 - val_accuracy: 0.4900\n",
      "Epoch 1180/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3853 - accuracy: 0.9014 - val_loss: 2.3876 - val_accuracy: 0.4800\n",
      "Epoch 1181/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3871 - accuracy: 0.9086 - val_loss: 2.3915 - val_accuracy: 0.4767\n",
      "Epoch 1182/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3855 - accuracy: 0.9071 - val_loss: 2.3851 - val_accuracy: 0.4767\n",
      "Epoch 1183/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3844 - accuracy: 0.9057 - val_loss: 2.3815 - val_accuracy: 0.4833\n",
      "Epoch 1184/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3857 - accuracy: 0.9043 - val_loss: 2.3801 - val_accuracy: 0.4767\n",
      "Epoch 1185/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3844 - accuracy: 0.9100 - val_loss: 2.3882 - val_accuracy: 0.4833\n",
      "Epoch 1186/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3845 - accuracy: 0.9071 - val_loss: 2.3957 - val_accuracy: 0.4800\n",
      "Epoch 1187/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3849 - accuracy: 0.9057 - val_loss: 2.4039 - val_accuracy: 0.4933\n",
      "Epoch 1188/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3837 - accuracy: 0.9071 - val_loss: 2.3820 - val_accuracy: 0.4800\n",
      "Epoch 1189/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3848 - accuracy: 0.9057 - val_loss: 2.4048 - val_accuracy: 0.4767\n",
      "Epoch 1190/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3851 - accuracy: 0.9086 - val_loss: 2.4052 - val_accuracy: 0.4767\n",
      "Epoch 1191/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3826 - accuracy: 0.9100 - val_loss: 2.4036 - val_accuracy: 0.4767\n",
      "Epoch 1192/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3827 - accuracy: 0.9057 - val_loss: 2.4028 - val_accuracy: 0.4767\n",
      "Epoch 1193/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3843 - accuracy: 0.9071 - val_loss: 2.3974 - val_accuracy: 0.4767\n",
      "Epoch 1194/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3829 - accuracy: 0.9071 - val_loss: 2.4127 - val_accuracy: 0.4867\n",
      "Epoch 1195/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3823 - accuracy: 0.9071 - val_loss: 2.4000 - val_accuracy: 0.4733\n",
      "Epoch 1196/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3831 - accuracy: 0.9057 - val_loss: 2.4144 - val_accuracy: 0.4967\n",
      "Epoch 1197/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3824 - accuracy: 0.9043 - val_loss: 2.4101 - val_accuracy: 0.4767\n",
      "Epoch 1198/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3831 - accuracy: 0.9071 - val_loss: 2.4076 - val_accuracy: 0.4833\n",
      "Epoch 1199/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3821 - accuracy: 0.9071 - val_loss: 2.4074 - val_accuracy: 0.4767\n",
      "Epoch 1200/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3829 - accuracy: 0.9086 - val_loss: 2.4239 - val_accuracy: 0.4800\n",
      "Epoch 1201/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3824 - accuracy: 0.9086 - val_loss: 2.4075 - val_accuracy: 0.4767\n",
      "Epoch 1202/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3817 - accuracy: 0.9071 - val_loss: 2.4081 - val_accuracy: 0.4767\n",
      "Epoch 1203/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3822 - accuracy: 0.9071 - val_loss: 2.4118 - val_accuracy: 0.4767\n",
      "Epoch 1204/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3818 - accuracy: 0.9100 - val_loss: 2.4112 - val_accuracy: 0.4767\n",
      "Epoch 1205/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3824 - accuracy: 0.9071 - val_loss: 2.4164 - val_accuracy: 0.4767\n",
      "Epoch 1206/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3819 - accuracy: 0.9086 - val_loss: 2.4063 - val_accuracy: 0.4767\n",
      "Epoch 1207/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3804 - accuracy: 0.9086 - val_loss: 2.4277 - val_accuracy: 0.4867\n",
      "Epoch 1208/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3811 - accuracy: 0.9086 - val_loss: 2.4125 - val_accuracy: 0.4767\n",
      "Epoch 1209/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3809 - accuracy: 0.9057 - val_loss: 2.4101 - val_accuracy: 0.4800\n",
      "Epoch 1210/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3807 - accuracy: 0.9086 - val_loss: 2.4365 - val_accuracy: 0.4833\n",
      "Epoch 1211/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3810 - accuracy: 0.9086 - val_loss: 2.4201 - val_accuracy: 0.4767\n",
      "Epoch 1212/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3812 - accuracy: 0.9057 - val_loss: 2.4324 - val_accuracy: 0.4800\n",
      "Epoch 1213/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3808 - accuracy: 0.9100 - val_loss: 2.4181 - val_accuracy: 0.4767\n",
      "Epoch 1214/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3813 - accuracy: 0.9100 - val_loss: 2.4213 - val_accuracy: 0.4767\n",
      "Epoch 1215/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3796 - accuracy: 0.9043 - val_loss: 2.4192 - val_accuracy: 0.4800\n",
      "Epoch 1216/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3801 - accuracy: 0.9071 - val_loss: 2.4287 - val_accuracy: 0.4833\n",
      "Epoch 1217/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3795 - accuracy: 0.9086 - val_loss: 2.4337 - val_accuracy: 0.4767\n",
      "Epoch 1218/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3791 - accuracy: 0.9071 - val_loss: 2.4362 - val_accuracy: 0.4767\n",
      "Epoch 1219/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3789 - accuracy: 0.9071 - val_loss: 2.4348 - val_accuracy: 0.4800\n",
      "Epoch 1220/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 86us/step - loss: 0.3792 - accuracy: 0.9071 - val_loss: 2.4288 - val_accuracy: 0.4767\n",
      "Epoch 1221/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3800 - accuracy: 0.9071 - val_loss: 2.4312 - val_accuracy: 0.4800\n",
      "Epoch 1222/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3785 - accuracy: 0.9100 - val_loss: 2.4333 - val_accuracy: 0.4767\n",
      "Epoch 1223/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3783 - accuracy: 0.9057 - val_loss: 2.4370 - val_accuracy: 0.4767\n",
      "Epoch 1224/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3791 - accuracy: 0.9086 - val_loss: 2.4350 - val_accuracy: 0.4767\n",
      "Epoch 1225/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3794 - accuracy: 0.9071 - val_loss: 2.4447 - val_accuracy: 0.4767\n",
      "Epoch 1226/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3782 - accuracy: 0.9043 - val_loss: 2.4320 - val_accuracy: 0.4767\n",
      "Epoch 1227/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3779 - accuracy: 0.9086 - val_loss: 2.4418 - val_accuracy: 0.4767\n",
      "Epoch 1228/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3771 - accuracy: 0.9100 - val_loss: 2.4423 - val_accuracy: 0.4967\n",
      "Epoch 1229/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3783 - accuracy: 0.9086 - val_loss: 2.4568 - val_accuracy: 0.4800\n",
      "Epoch 1230/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3776 - accuracy: 0.9086 - val_loss: 2.4386 - val_accuracy: 0.4800\n",
      "Epoch 1231/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3772 - accuracy: 0.9086 - val_loss: 2.4501 - val_accuracy: 0.4767\n",
      "Epoch 1232/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3772 - accuracy: 0.9114 - val_loss: 2.4602 - val_accuracy: 0.4867\n",
      "Epoch 1233/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3780 - accuracy: 0.9086 - val_loss: 2.4543 - val_accuracy: 0.4800\n",
      "Epoch 1234/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3776 - accuracy: 0.9100 - val_loss: 2.4476 - val_accuracy: 0.4833\n",
      "Epoch 1235/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3762 - accuracy: 0.9100 - val_loss: 2.4476 - val_accuracy: 0.4767\n",
      "Epoch 1236/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3763 - accuracy: 0.9086 - val_loss: 2.4484 - val_accuracy: 0.4767\n",
      "Epoch 1237/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3762 - accuracy: 0.9100 - val_loss: 2.4515 - val_accuracy: 0.4767\n",
      "Epoch 1238/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3763 - accuracy: 0.9086 - val_loss: 2.4511 - val_accuracy: 0.4733\n",
      "Epoch 1239/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3770 - accuracy: 0.9086 - val_loss: 2.4629 - val_accuracy: 0.4867\n",
      "Epoch 1240/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3758 - accuracy: 0.9071 - val_loss: 2.4439 - val_accuracy: 0.4767\n",
      "Epoch 1241/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3763 - accuracy: 0.9100 - val_loss: 2.4486 - val_accuracy: 0.4767\n",
      "Epoch 1242/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3756 - accuracy: 0.9086 - val_loss: 2.4596 - val_accuracy: 0.4767\n",
      "Epoch 1243/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3762 - accuracy: 0.9071 - val_loss: 2.4650 - val_accuracy: 0.4767\n",
      "Epoch 1244/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3747 - accuracy: 0.9086 - val_loss: 2.4632 - val_accuracy: 0.4867\n",
      "Epoch 1245/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3748 - accuracy: 0.9086 - val_loss: 2.4566 - val_accuracy: 0.4767\n",
      "Epoch 1246/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3748 - accuracy: 0.9086 - val_loss: 2.4721 - val_accuracy: 0.4867\n",
      "Epoch 1247/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3752 - accuracy: 0.9114 - val_loss: 2.4615 - val_accuracy: 0.4767\n",
      "Epoch 1248/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3745 - accuracy: 0.9114 - val_loss: 2.4574 - val_accuracy: 0.4967\n",
      "Epoch 1249/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3753 - accuracy: 0.9086 - val_loss: 2.4599 - val_accuracy: 0.4800\n",
      "Epoch 1250/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3746 - accuracy: 0.9100 - val_loss: 2.4650 - val_accuracy: 0.4767\n",
      "Epoch 1251/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3751 - accuracy: 0.9086 - val_loss: 2.4753 - val_accuracy: 0.4833\n",
      "Epoch 1252/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3746 - accuracy: 0.9071 - val_loss: 2.4730 - val_accuracy: 0.4933\n",
      "Epoch 1253/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3735 - accuracy: 0.9086 - val_loss: 2.4600 - val_accuracy: 0.4700\n",
      "Epoch 1254/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3743 - accuracy: 0.9100 - val_loss: 2.4703 - val_accuracy: 0.4767\n",
      "Epoch 1255/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3737 - accuracy: 0.9100 - val_loss: 2.4825 - val_accuracy: 0.4767\n",
      "Epoch 1256/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3733 - accuracy: 0.9100 - val_loss: 2.4745 - val_accuracy: 0.4767\n",
      "Epoch 1257/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3734 - accuracy: 0.9071 - val_loss: 2.4707 - val_accuracy: 0.4767\n",
      "Epoch 1258/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3739 - accuracy: 0.9100 - val_loss: 2.4762 - val_accuracy: 0.4767\n",
      "Epoch 1259/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3737 - accuracy: 0.9071 - val_loss: 2.4861 - val_accuracy: 0.4767\n",
      "Epoch 1260/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3734 - accuracy: 0.9129 - val_loss: 2.4804 - val_accuracy: 0.4767\n",
      "Epoch 1261/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3728 - accuracy: 0.9114 - val_loss: 2.4813 - val_accuracy: 0.4767\n",
      "Epoch 1262/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3719 - accuracy: 0.9129 - val_loss: 2.4734 - val_accuracy: 0.4767\n",
      "Epoch 1263/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3740 - accuracy: 0.9057 - val_loss: 2.4883 - val_accuracy: 0.4767\n",
      "Epoch 1264/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3728 - accuracy: 0.9100 - val_loss: 2.4887 - val_accuracy: 0.4767\n",
      "Epoch 1265/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3722 - accuracy: 0.9100 - val_loss: 2.4777 - val_accuracy: 0.4767\n",
      "Epoch 1266/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3728 - accuracy: 0.9071 - val_loss: 2.4883 - val_accuracy: 0.4767\n",
      "Epoch 1267/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3719 - accuracy: 0.9086 - val_loss: 2.4946 - val_accuracy: 0.4767\n",
      "Epoch 1268/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3722 - accuracy: 0.9100 - val_loss: 2.4876 - val_accuracy: 0.4800\n",
      "Epoch 1269/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3720 - accuracy: 0.9114 - val_loss: 2.5028 - val_accuracy: 0.4700\n",
      "Epoch 1270/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3728 - accuracy: 0.9086 - val_loss: 2.4872 - val_accuracy: 0.4767\n",
      "Epoch 1271/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3718 - accuracy: 0.9100 - val_loss: 2.4936 - val_accuracy: 0.4833\n",
      "Epoch 1272/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3711 - accuracy: 0.9100 - val_loss: 2.4954 - val_accuracy: 0.4767\n",
      "Epoch 1273/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3705 - accuracy: 0.9129 - val_loss: 2.5013 - val_accuracy: 0.4867\n",
      "Epoch 1274/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3712 - accuracy: 0.9114 - val_loss: 2.4970 - val_accuracy: 0.4767\n",
      "Epoch 1275/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 101us/step - loss: 0.3710 - accuracy: 0.9114 - val_loss: 2.5029 - val_accuracy: 0.4733\n",
      "Epoch 1276/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3706 - accuracy: 0.9114 - val_loss: 2.4965 - val_accuracy: 0.4767\n",
      "Epoch 1277/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3701 - accuracy: 0.9086 - val_loss: 2.4995 - val_accuracy: 0.4767\n",
      "Epoch 1278/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3708 - accuracy: 0.9100 - val_loss: 2.5014 - val_accuracy: 0.4800\n",
      "Epoch 1279/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3708 - accuracy: 0.9114 - val_loss: 2.5012 - val_accuracy: 0.4867\n",
      "Epoch 1280/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3704 - accuracy: 0.9100 - val_loss: 2.4913 - val_accuracy: 0.4767\n",
      "Epoch 1281/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3702 - accuracy: 0.9100 - val_loss: 2.5037 - val_accuracy: 0.4767\n",
      "Epoch 1282/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3697 - accuracy: 0.9100 - val_loss: 2.5040 - val_accuracy: 0.4767\n",
      "Epoch 1283/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3697 - accuracy: 0.9114 - val_loss: 2.5232 - val_accuracy: 0.4767\n",
      "Epoch 1284/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3686 - accuracy: 0.9114 - val_loss: 2.4889 - val_accuracy: 0.4767\n",
      "Epoch 1285/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3690 - accuracy: 0.9100 - val_loss: 2.5137 - val_accuracy: 0.4767\n",
      "Epoch 1286/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3686 - accuracy: 0.9129 - val_loss: 2.5233 - val_accuracy: 0.4800\n",
      "Epoch 1287/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3680 - accuracy: 0.9114 - val_loss: 2.5240 - val_accuracy: 0.4733\n",
      "Epoch 1288/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3690 - accuracy: 0.9100 - val_loss: 2.5188 - val_accuracy: 0.4767\n",
      "Epoch 1289/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3686 - accuracy: 0.9114 - val_loss: 2.5269 - val_accuracy: 0.4767\n",
      "Epoch 1290/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3685 - accuracy: 0.9100 - val_loss: 2.5178 - val_accuracy: 0.4867\n",
      "Epoch 1291/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.3697 - accuracy: 0.9100 - val_loss: 2.5188 - val_accuracy: 0.4767\n",
      "Epoch 1292/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3680 - accuracy: 0.9086 - val_loss: 2.5129 - val_accuracy: 0.4800\n",
      "Epoch 1293/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3672 - accuracy: 0.9071 - val_loss: 2.5141 - val_accuracy: 0.4767\n",
      "Epoch 1294/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3679 - accuracy: 0.9100 - val_loss: 2.5146 - val_accuracy: 0.4767\n",
      "Epoch 1295/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3683 - accuracy: 0.9114 - val_loss: 2.5248 - val_accuracy: 0.4767\n",
      "Epoch 1296/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3675 - accuracy: 0.9129 - val_loss: 2.5198 - val_accuracy: 0.4733\n",
      "Epoch 1297/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3674 - accuracy: 0.9114 - val_loss: 2.5270 - val_accuracy: 0.4733\n",
      "Epoch 1298/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3673 - accuracy: 0.9129 - val_loss: 2.5320 - val_accuracy: 0.4733\n",
      "Epoch 1299/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3672 - accuracy: 0.9114 - val_loss: 2.5186 - val_accuracy: 0.4733\n",
      "Epoch 1300/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3662 - accuracy: 0.9086 - val_loss: 2.5383 - val_accuracy: 0.4767\n",
      "Epoch 1301/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3671 - accuracy: 0.9129 - val_loss: 2.5281 - val_accuracy: 0.4767\n",
      "Epoch 1302/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3674 - accuracy: 0.9129 - val_loss: 2.5262 - val_accuracy: 0.4767\n",
      "Epoch 1303/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3670 - accuracy: 0.9100 - val_loss: 2.5321 - val_accuracy: 0.4767\n",
      "Epoch 1304/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3666 - accuracy: 0.9086 - val_loss: 2.5282 - val_accuracy: 0.4767\n",
      "Epoch 1305/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3678 - accuracy: 0.9100 - val_loss: 2.5236 - val_accuracy: 0.4733\n",
      "Epoch 1306/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3666 - accuracy: 0.9071 - val_loss: 2.5364 - val_accuracy: 0.4800\n",
      "Epoch 1307/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3667 - accuracy: 0.9100 - val_loss: 2.5386 - val_accuracy: 0.4767\n",
      "Epoch 1308/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3670 - accuracy: 0.9129 - val_loss: 2.5353 - val_accuracy: 0.4767\n",
      "Epoch 1309/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3664 - accuracy: 0.9100 - val_loss: 2.5410 - val_accuracy: 0.4767\n",
      "Epoch 1310/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3657 - accuracy: 0.9114 - val_loss: 2.5380 - val_accuracy: 0.4767\n",
      "Epoch 1311/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3653 - accuracy: 0.9071 - val_loss: 2.5516 - val_accuracy: 0.4800\n",
      "Epoch 1312/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3658 - accuracy: 0.9086 - val_loss: 2.5278 - val_accuracy: 0.4800\n",
      "Epoch 1313/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3648 - accuracy: 0.9114 - val_loss: 2.5362 - val_accuracy: 0.4733\n",
      "Epoch 1314/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3655 - accuracy: 0.9114 - val_loss: 2.5319 - val_accuracy: 0.4700\n",
      "Epoch 1315/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3657 - accuracy: 0.9114 - val_loss: 2.5306 - val_accuracy: 0.4667\n",
      "Epoch 1316/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3651 - accuracy: 0.9100 - val_loss: 2.5462 - val_accuracy: 0.4733\n",
      "Epoch 1317/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3643 - accuracy: 0.9086 - val_loss: 2.5559 - val_accuracy: 0.4700\n",
      "Epoch 1318/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3640 - accuracy: 0.9100 - val_loss: 2.5572 - val_accuracy: 0.4767\n",
      "Epoch 1319/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3650 - accuracy: 0.9129 - val_loss: 2.5486 - val_accuracy: 0.4733\n",
      "Epoch 1320/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3643 - accuracy: 0.9114 - val_loss: 2.5443 - val_accuracy: 0.4767\n",
      "Epoch 1321/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3654 - accuracy: 0.9100 - val_loss: 2.5537 - val_accuracy: 0.4767\n",
      "Epoch 1322/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3645 - accuracy: 0.9100 - val_loss: 2.5433 - val_accuracy: 0.4767\n",
      "Epoch 1323/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3644 - accuracy: 0.9114 - val_loss: 2.5569 - val_accuracy: 0.4733\n",
      "Epoch 1324/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3641 - accuracy: 0.9100 - val_loss: 2.5485 - val_accuracy: 0.4767\n",
      "Epoch 1325/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3643 - accuracy: 0.9100 - val_loss: 2.5517 - val_accuracy: 0.4733\n",
      "Epoch 1326/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3647 - accuracy: 0.9100 - val_loss: 2.5472 - val_accuracy: 0.4767\n",
      "Epoch 1327/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3626 - accuracy: 0.9100 - val_loss: 2.5480 - val_accuracy: 0.4667\n",
      "Epoch 1328/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3625 - accuracy: 0.9114 - val_loss: 2.5628 - val_accuracy: 0.4667\n",
      "Epoch 1329/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3621 - accuracy: 0.9114 - val_loss: 2.5542 - val_accuracy: 0.4733\n",
      "Epoch 1330/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 0.3636 - accuracy: 0.9071 - val_loss: 2.5620 - val_accuracy: 0.4733\n",
      "Epoch 1331/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3633 - accuracy: 0.9100 - val_loss: 2.5611 - val_accuracy: 0.4700\n",
      "Epoch 1332/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3629 - accuracy: 0.9100 - val_loss: 2.5661 - val_accuracy: 0.4733\n",
      "Epoch 1333/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3633 - accuracy: 0.9114 - val_loss: 2.5628 - val_accuracy: 0.4767\n",
      "Epoch 1334/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3626 - accuracy: 0.9114 - val_loss: 2.5689 - val_accuracy: 0.4733\n",
      "Epoch 1335/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3632 - accuracy: 0.9100 - val_loss: 2.5654 - val_accuracy: 0.4767\n",
      "Epoch 1336/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3624 - accuracy: 0.9114 - val_loss: 2.5591 - val_accuracy: 0.4767\n",
      "Epoch 1337/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3623 - accuracy: 0.9100 - val_loss: 2.5724 - val_accuracy: 0.4700\n",
      "Epoch 1338/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3613 - accuracy: 0.9129 - val_loss: 2.5871 - val_accuracy: 0.4767\n",
      "Epoch 1339/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3618 - accuracy: 0.9129 - val_loss: 2.5770 - val_accuracy: 0.4700\n",
      "Epoch 1340/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3615 - accuracy: 0.9129 - val_loss: 2.5699 - val_accuracy: 0.4667\n",
      "Epoch 1341/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3617 - accuracy: 0.9114 - val_loss: 2.5773 - val_accuracy: 0.4800\n",
      "Epoch 1342/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3613 - accuracy: 0.9114 - val_loss: 2.5697 - val_accuracy: 0.4733\n",
      "Epoch 1343/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3600 - accuracy: 0.9100 - val_loss: 2.5791 - val_accuracy: 0.4667\n",
      "Epoch 1344/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3613 - accuracy: 0.9100 - val_loss: 2.5892 - val_accuracy: 0.4733\n",
      "Epoch 1345/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3610 - accuracy: 0.9129 - val_loss: 2.5769 - val_accuracy: 0.4633\n",
      "Epoch 1346/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3613 - accuracy: 0.9114 - val_loss: 2.5837 - val_accuracy: 0.4667\n",
      "Epoch 1347/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3618 - accuracy: 0.9100 - val_loss: 2.5801 - val_accuracy: 0.4700\n",
      "Epoch 1348/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3611 - accuracy: 0.9114 - val_loss: 2.5880 - val_accuracy: 0.4733\n",
      "Epoch 1349/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3606 - accuracy: 0.9114 - val_loss: 2.5812 - val_accuracy: 0.4700\n",
      "Epoch 1350/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3602 - accuracy: 0.9100 - val_loss: 2.5868 - val_accuracy: 0.4700\n",
      "Epoch 1351/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3603 - accuracy: 0.9129 - val_loss: 2.5841 - val_accuracy: 0.4667\n",
      "Epoch 1352/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3602 - accuracy: 0.9100 - val_loss: 2.5855 - val_accuracy: 0.4700\n",
      "Epoch 1353/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3609 - accuracy: 0.9100 - val_loss: 2.6043 - val_accuracy: 0.4633\n",
      "Epoch 1354/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3603 - accuracy: 0.9114 - val_loss: 2.5967 - val_accuracy: 0.4733\n",
      "Epoch 1355/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3602 - accuracy: 0.9129 - val_loss: 2.5837 - val_accuracy: 0.4700\n",
      "Epoch 1356/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3606 - accuracy: 0.9071 - val_loss: 2.6001 - val_accuracy: 0.4767\n",
      "Epoch 1357/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3601 - accuracy: 0.9114 - val_loss: 2.5895 - val_accuracy: 0.4700\n",
      "Epoch 1358/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3595 - accuracy: 0.9114 - val_loss: 2.5958 - val_accuracy: 0.4733\n",
      "Epoch 1359/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3585 - accuracy: 0.9114 - val_loss: 2.6018 - val_accuracy: 0.4767\n",
      "Epoch 1360/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3587 - accuracy: 0.9114 - val_loss: 2.6016 - val_accuracy: 0.4633\n",
      "Epoch 1361/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3598 - accuracy: 0.9114 - val_loss: 2.6011 - val_accuracy: 0.4700\n",
      "Epoch 1362/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3587 - accuracy: 0.9114 - val_loss: 2.5978 - val_accuracy: 0.4700\n",
      "Epoch 1363/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3596 - accuracy: 0.9100 - val_loss: 2.6009 - val_accuracy: 0.4700\n",
      "Epoch 1364/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3585 - accuracy: 0.9114 - val_loss: 2.5957 - val_accuracy: 0.4700\n",
      "Epoch 1365/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3589 - accuracy: 0.9129 - val_loss: 2.6081 - val_accuracy: 0.4700\n",
      "Epoch 1366/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3591 - accuracy: 0.9100 - val_loss: 2.6121 - val_accuracy: 0.4700\n",
      "Epoch 1367/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3586 - accuracy: 0.9129 - val_loss: 2.6114 - val_accuracy: 0.4667\n",
      "Epoch 1368/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3581 - accuracy: 0.9114 - val_loss: 2.6072 - val_accuracy: 0.4700\n",
      "Epoch 1369/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3578 - accuracy: 0.9129 - val_loss: 2.6133 - val_accuracy: 0.4733\n",
      "Epoch 1370/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3577 - accuracy: 0.9129 - val_loss: 2.6157 - val_accuracy: 0.4700\n",
      "Epoch 1371/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3577 - accuracy: 0.9114 - val_loss: 2.6117 - val_accuracy: 0.4667\n",
      "Epoch 1372/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3575 - accuracy: 0.9114 - val_loss: 2.6093 - val_accuracy: 0.4733\n",
      "Epoch 1373/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3582 - accuracy: 0.9114 - val_loss: 2.6018 - val_accuracy: 0.4700\n",
      "Epoch 1374/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3569 - accuracy: 0.9114 - val_loss: 2.6174 - val_accuracy: 0.4700\n",
      "Epoch 1375/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3584 - accuracy: 0.9114 - val_loss: 2.6199 - val_accuracy: 0.4667\n",
      "Epoch 1376/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3571 - accuracy: 0.9129 - val_loss: 2.6140 - val_accuracy: 0.4633\n",
      "Epoch 1377/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3576 - accuracy: 0.9114 - val_loss: 2.6114 - val_accuracy: 0.4633\n",
      "Epoch 1378/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3563 - accuracy: 0.9114 - val_loss: 2.6190 - val_accuracy: 0.4733\n",
      "Epoch 1379/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3569 - accuracy: 0.9100 - val_loss: 2.6207 - val_accuracy: 0.4700\n",
      "Epoch 1380/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3566 - accuracy: 0.9129 - val_loss: 2.6220 - val_accuracy: 0.4733\n",
      "Epoch 1381/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3566 - accuracy: 0.9100 - val_loss: 2.6158 - val_accuracy: 0.4733\n",
      "Epoch 1382/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3565 - accuracy: 0.9114 - val_loss: 2.6039 - val_accuracy: 0.4667\n",
      "Epoch 1383/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3571 - accuracy: 0.9100 - val_loss: 2.6217 - val_accuracy: 0.4633\n",
      "Epoch 1384/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3557 - accuracy: 0.9114 - val_loss: 2.6134 - val_accuracy: 0.4600\n",
      "Epoch 1385/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 86us/step - loss: 0.3558 - accuracy: 0.9114 - val_loss: 2.6237 - val_accuracy: 0.4700\n",
      "Epoch 1386/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3561 - accuracy: 0.9100 - val_loss: 2.6332 - val_accuracy: 0.4700\n",
      "Epoch 1387/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3548 - accuracy: 0.9129 - val_loss: 2.6258 - val_accuracy: 0.4633\n",
      "Epoch 1388/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3553 - accuracy: 0.9114 - val_loss: 2.6211 - val_accuracy: 0.4633\n",
      "Epoch 1389/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3554 - accuracy: 0.9114 - val_loss: 2.6392 - val_accuracy: 0.4667\n",
      "Epoch 1390/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3552 - accuracy: 0.9114 - val_loss: 2.6325 - val_accuracy: 0.4733\n",
      "Epoch 1391/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3545 - accuracy: 0.9129 - val_loss: 2.6387 - val_accuracy: 0.4700\n",
      "Epoch 1392/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3552 - accuracy: 0.9129 - val_loss: 2.6247 - val_accuracy: 0.4633\n",
      "Epoch 1393/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3554 - accuracy: 0.9129 - val_loss: 2.6500 - val_accuracy: 0.4767\n",
      "Epoch 1394/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3556 - accuracy: 0.9114 - val_loss: 2.6252 - val_accuracy: 0.4600\n",
      "Epoch 1395/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3546 - accuracy: 0.9129 - val_loss: 2.6428 - val_accuracy: 0.4700\n",
      "Epoch 1396/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3552 - accuracy: 0.9114 - val_loss: 2.6348 - val_accuracy: 0.4733\n",
      "Epoch 1397/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3551 - accuracy: 0.9129 - val_loss: 2.6382 - val_accuracy: 0.4733\n",
      "Epoch 1398/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3543 - accuracy: 0.9114 - val_loss: 2.6269 - val_accuracy: 0.4600\n",
      "Epoch 1399/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3534 - accuracy: 0.9129 - val_loss: 2.6382 - val_accuracy: 0.4667\n",
      "Epoch 1400/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3536 - accuracy: 0.9114 - val_loss: 2.6386 - val_accuracy: 0.4733\n",
      "Epoch 1401/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3523 - accuracy: 0.9100 - val_loss: 2.6410 - val_accuracy: 0.4700\n",
      "Epoch 1402/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3540 - accuracy: 0.9100 - val_loss: 2.6532 - val_accuracy: 0.4633\n",
      "Epoch 1403/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3542 - accuracy: 0.9129 - val_loss: 2.6379 - val_accuracy: 0.4633\n",
      "Epoch 1404/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3534 - accuracy: 0.9114 - val_loss: 2.6367 - val_accuracy: 0.4700\n",
      "Epoch 1405/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3527 - accuracy: 0.9100 - val_loss: 2.6472 - val_accuracy: 0.4600\n",
      "Epoch 1406/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3536 - accuracy: 0.9114 - val_loss: 2.6372 - val_accuracy: 0.4667\n",
      "Epoch 1407/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3535 - accuracy: 0.9129 - val_loss: 2.6500 - val_accuracy: 0.4667\n",
      "Epoch 1408/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3536 - accuracy: 0.9129 - val_loss: 2.6541 - val_accuracy: 0.4700\n",
      "Epoch 1409/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3531 - accuracy: 0.9100 - val_loss: 2.6631 - val_accuracy: 0.4667\n",
      "Epoch 1410/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3522 - accuracy: 0.9114 - val_loss: 2.6610 - val_accuracy: 0.4633\n",
      "Epoch 1411/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3531 - accuracy: 0.9114 - val_loss: 2.6656 - val_accuracy: 0.4700\n",
      "Epoch 1412/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3530 - accuracy: 0.9114 - val_loss: 2.6620 - val_accuracy: 0.4733\n",
      "Epoch 1413/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3526 - accuracy: 0.9114 - val_loss: 2.6498 - val_accuracy: 0.4633\n",
      "Epoch 1414/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3527 - accuracy: 0.9129 - val_loss: 2.6631 - val_accuracy: 0.4633\n",
      "Epoch 1415/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3535 - accuracy: 0.9114 - val_loss: 2.6512 - val_accuracy: 0.4667\n",
      "Epoch 1416/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3524 - accuracy: 0.9114 - val_loss: 2.6553 - val_accuracy: 0.4667\n",
      "Epoch 1417/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3517 - accuracy: 0.9129 - val_loss: 2.6756 - val_accuracy: 0.4667\n",
      "Epoch 1418/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3523 - accuracy: 0.9129 - val_loss: 2.6611 - val_accuracy: 0.4733\n",
      "Epoch 1419/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3519 - accuracy: 0.9129 - val_loss: 2.6539 - val_accuracy: 0.4633\n",
      "Epoch 1420/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3516 - accuracy: 0.9114 - val_loss: 2.6666 - val_accuracy: 0.4600\n",
      "Epoch 1421/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3526 - accuracy: 0.9114 - val_loss: 2.6598 - val_accuracy: 0.4633\n",
      "Epoch 1422/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3518 - accuracy: 0.9129 - val_loss: 2.6657 - val_accuracy: 0.4633\n",
      "Epoch 1423/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3509 - accuracy: 0.9114 - val_loss: 2.6811 - val_accuracy: 0.4700\n",
      "Epoch 1424/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3509 - accuracy: 0.9114 - val_loss: 2.6612 - val_accuracy: 0.4600\n",
      "Epoch 1425/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3506 - accuracy: 0.9114 - val_loss: 2.6717 - val_accuracy: 0.4600\n",
      "Epoch 1426/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3521 - accuracy: 0.9143 - val_loss: 2.6710 - val_accuracy: 0.4667\n",
      "Epoch 1427/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3513 - accuracy: 0.9129 - val_loss: 2.6773 - val_accuracy: 0.4700\n",
      "Epoch 1428/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3514 - accuracy: 0.9114 - val_loss: 2.6762 - val_accuracy: 0.4667\n",
      "Epoch 1429/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3507 - accuracy: 0.9114 - val_loss: 2.6692 - val_accuracy: 0.4667\n",
      "Epoch 1430/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3499 - accuracy: 0.9129 - val_loss: 2.6591 - val_accuracy: 0.4633\n",
      "Epoch 1431/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3505 - accuracy: 0.9129 - val_loss: 2.6709 - val_accuracy: 0.4633\n",
      "Epoch 1432/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3502 - accuracy: 0.9114 - val_loss: 2.6863 - val_accuracy: 0.4667\n",
      "Epoch 1433/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3513 - accuracy: 0.9114 - val_loss: 2.6773 - val_accuracy: 0.4633\n",
      "Epoch 1434/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3490 - accuracy: 0.9129 - val_loss: 2.6845 - val_accuracy: 0.4667\n",
      "Epoch 1435/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3497 - accuracy: 0.9114 - val_loss: 2.6828 - val_accuracy: 0.4633\n",
      "Epoch 1436/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3496 - accuracy: 0.9114 - val_loss: 2.6819 - val_accuracy: 0.4633\n",
      "Epoch 1437/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3499 - accuracy: 0.9114 - val_loss: 2.6837 - val_accuracy: 0.4633\n",
      "Epoch 1438/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3501 - accuracy: 0.9114 - val_loss: 2.6846 - val_accuracy: 0.4733\n",
      "Epoch 1439/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3496 - accuracy: 0.9114 - val_loss: 2.6957 - val_accuracy: 0.4633\n",
      "Epoch 1440/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 87us/step - loss: 0.3480 - accuracy: 0.9129 - val_loss: 2.6996 - val_accuracy: 0.4600\n",
      "Epoch 1441/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3504 - accuracy: 0.9114 - val_loss: 2.6986 - val_accuracy: 0.4733\n",
      "Epoch 1442/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3497 - accuracy: 0.9114 - val_loss: 2.6969 - val_accuracy: 0.4633\n",
      "Epoch 1443/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3488 - accuracy: 0.9114 - val_loss: 2.6956 - val_accuracy: 0.4700\n",
      "Epoch 1444/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3500 - accuracy: 0.9114 - val_loss: 2.6871 - val_accuracy: 0.4633\n",
      "Epoch 1445/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3491 - accuracy: 0.9129 - val_loss: 2.6887 - val_accuracy: 0.4633\n",
      "Epoch 1446/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3489 - accuracy: 0.9143 - val_loss: 2.6957 - val_accuracy: 0.4667\n",
      "Epoch 1447/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3483 - accuracy: 0.9100 - val_loss: 2.7015 - val_accuracy: 0.4667\n",
      "Epoch 1448/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3495 - accuracy: 0.9129 - val_loss: 2.7043 - val_accuracy: 0.4667\n",
      "Epoch 1449/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3484 - accuracy: 0.9129 - val_loss: 2.6973 - val_accuracy: 0.4633\n",
      "Epoch 1450/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3490 - accuracy: 0.9114 - val_loss: 2.7021 - val_accuracy: 0.4633\n",
      "Epoch 1451/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3492 - accuracy: 0.9114 - val_loss: 2.6950 - val_accuracy: 0.4633\n",
      "Epoch 1452/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3478 - accuracy: 0.9143 - val_loss: 2.6946 - val_accuracy: 0.4633\n",
      "Epoch 1453/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3486 - accuracy: 0.9100 - val_loss: 2.7074 - val_accuracy: 0.4633\n",
      "Epoch 1454/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3488 - accuracy: 0.9114 - val_loss: 2.6949 - val_accuracy: 0.4600\n",
      "Epoch 1455/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3487 - accuracy: 0.9114 - val_loss: 2.7143 - val_accuracy: 0.4633\n",
      "Epoch 1456/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3473 - accuracy: 0.9129 - val_loss: 2.7068 - val_accuracy: 0.4700\n",
      "Epoch 1457/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3470 - accuracy: 0.9143 - val_loss: 2.7175 - val_accuracy: 0.4667\n",
      "Epoch 1458/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3483 - accuracy: 0.9143 - val_loss: 2.7036 - val_accuracy: 0.4633\n",
      "Epoch 1459/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3478 - accuracy: 0.9129 - val_loss: 2.7018 - val_accuracy: 0.4667\n",
      "Epoch 1460/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3468 - accuracy: 0.9114 - val_loss: 2.7110 - val_accuracy: 0.4600\n",
      "Epoch 1461/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3470 - accuracy: 0.9114 - val_loss: 2.7195 - val_accuracy: 0.4633\n",
      "Epoch 1462/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3463 - accuracy: 0.9114 - val_loss: 2.7177 - val_accuracy: 0.4667\n",
      "Epoch 1463/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3472 - accuracy: 0.9114 - val_loss: 2.7121 - val_accuracy: 0.4567\n",
      "Epoch 1464/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3467 - accuracy: 0.9129 - val_loss: 2.7268 - val_accuracy: 0.4667\n",
      "Epoch 1465/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3464 - accuracy: 0.9129 - val_loss: 2.7241 - val_accuracy: 0.4633\n",
      "Epoch 1466/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3465 - accuracy: 0.9129 - val_loss: 2.7240 - val_accuracy: 0.4667\n",
      "Epoch 1467/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3452 - accuracy: 0.9114 - val_loss: 2.7202 - val_accuracy: 0.4633\n",
      "Epoch 1468/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3457 - accuracy: 0.9114 - val_loss: 2.7267 - val_accuracy: 0.4633\n",
      "Epoch 1469/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3464 - accuracy: 0.9129 - val_loss: 2.7120 - val_accuracy: 0.4667\n",
      "Epoch 1470/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3456 - accuracy: 0.9114 - val_loss: 2.7296 - val_accuracy: 0.4633\n",
      "Epoch 1471/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3469 - accuracy: 0.9114 - val_loss: 2.7303 - val_accuracy: 0.4733\n",
      "Epoch 1472/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3449 - accuracy: 0.9129 - val_loss: 2.7429 - val_accuracy: 0.4700\n",
      "Epoch 1473/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3455 - accuracy: 0.9129 - val_loss: 2.7355 - val_accuracy: 0.4633\n",
      "Epoch 1474/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3446 - accuracy: 0.9129 - val_loss: 2.7279 - val_accuracy: 0.4600\n",
      "Epoch 1475/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3469 - accuracy: 0.9114 - val_loss: 2.7206 - val_accuracy: 0.4600\n",
      "Epoch 1476/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3454 - accuracy: 0.9143 - val_loss: 2.7362 - val_accuracy: 0.4667\n",
      "Epoch 1477/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3458 - accuracy: 0.9114 - val_loss: 2.7302 - val_accuracy: 0.4633\n",
      "Epoch 1478/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3448 - accuracy: 0.9114 - val_loss: 2.7421 - val_accuracy: 0.4633\n",
      "Epoch 1479/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3459 - accuracy: 0.9129 - val_loss: 2.7298 - val_accuracy: 0.4633\n",
      "Epoch 1480/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3444 - accuracy: 0.9129 - val_loss: 2.7435 - val_accuracy: 0.4633\n",
      "Epoch 1481/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3455 - accuracy: 0.9114 - val_loss: 2.7455 - val_accuracy: 0.4633\n",
      "Epoch 1482/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3455 - accuracy: 0.9129 - val_loss: 2.7451 - val_accuracy: 0.4667\n",
      "Epoch 1483/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3444 - accuracy: 0.9114 - val_loss: 2.7374 - val_accuracy: 0.4667\n",
      "Epoch 1484/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3441 - accuracy: 0.9114 - val_loss: 2.7333 - val_accuracy: 0.4633\n",
      "Epoch 1485/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3432 - accuracy: 0.9114 - val_loss: 2.7302 - val_accuracy: 0.4633\n",
      "Epoch 1486/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3440 - accuracy: 0.9157 - val_loss: 2.7280 - val_accuracy: 0.4633\n",
      "Epoch 1487/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3439 - accuracy: 0.9129 - val_loss: 2.7403 - val_accuracy: 0.4600\n",
      "Epoch 1488/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3443 - accuracy: 0.9114 - val_loss: 2.7417 - val_accuracy: 0.4633\n",
      "Epoch 1489/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3431 - accuracy: 0.9114 - val_loss: 2.7536 - val_accuracy: 0.4633\n",
      "Epoch 1490/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3444 - accuracy: 0.9129 - val_loss: 2.7418 - val_accuracy: 0.4667\n",
      "Epoch 1491/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3437 - accuracy: 0.9129 - val_loss: 2.7496 - val_accuracy: 0.4633\n",
      "Epoch 1492/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3439 - accuracy: 0.9129 - val_loss: 2.7409 - val_accuracy: 0.4633\n",
      "Epoch 1493/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3434 - accuracy: 0.9129 - val_loss: 2.7398 - val_accuracy: 0.4633\n",
      "Epoch 1494/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3432 - accuracy: 0.9143 - val_loss: 2.7478 - val_accuracy: 0.4700\n",
      "Epoch 1495/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 0.3434 - accuracy: 0.9114 - val_loss: 2.7440 - val_accuracy: 0.4633\n",
      "Epoch 1496/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3430 - accuracy: 0.9114 - val_loss: 2.7597 - val_accuracy: 0.4633\n",
      "Epoch 1497/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3432 - accuracy: 0.9129 - val_loss: 2.7555 - val_accuracy: 0.4667\n",
      "Epoch 1498/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3420 - accuracy: 0.9129 - val_loss: 2.7583 - val_accuracy: 0.4700\n",
      "Epoch 1499/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3437 - accuracy: 0.9114 - val_loss: 2.7673 - val_accuracy: 0.4633\n",
      "Epoch 1500/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3418 - accuracy: 0.9129 - val_loss: 2.7584 - val_accuracy: 0.4633\n",
      "Epoch 1501/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3426 - accuracy: 0.9129 - val_loss: 2.7557 - val_accuracy: 0.4633\n",
      "Epoch 1502/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3418 - accuracy: 0.9129 - val_loss: 2.7535 - val_accuracy: 0.4600\n",
      "Epoch 1503/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3425 - accuracy: 0.9114 - val_loss: 2.7658 - val_accuracy: 0.4633\n",
      "Epoch 1504/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3424 - accuracy: 0.9129 - val_loss: 2.7658 - val_accuracy: 0.4667\n",
      "Epoch 1505/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3423 - accuracy: 0.9129 - val_loss: 2.7566 - val_accuracy: 0.4667\n",
      "Epoch 1506/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3427 - accuracy: 0.9143 - val_loss: 2.7685 - val_accuracy: 0.4633\n",
      "Epoch 1507/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3408 - accuracy: 0.9129 - val_loss: 2.7714 - val_accuracy: 0.4700\n",
      "Epoch 1508/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3426 - accuracy: 0.9129 - val_loss: 2.7713 - val_accuracy: 0.4667\n",
      "Epoch 1509/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3407 - accuracy: 0.9143 - val_loss: 2.7648 - val_accuracy: 0.4633\n",
      "Epoch 1510/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3409 - accuracy: 0.9129 - val_loss: 2.7702 - val_accuracy: 0.4700\n",
      "Epoch 1511/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3418 - accuracy: 0.9129 - val_loss: 2.7619 - val_accuracy: 0.4633\n",
      "Epoch 1512/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3421 - accuracy: 0.9129 - val_loss: 2.7645 - val_accuracy: 0.4600\n",
      "Epoch 1513/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3412 - accuracy: 0.9129 - val_loss: 2.7635 - val_accuracy: 0.4600\n",
      "Epoch 1514/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3407 - accuracy: 0.9114 - val_loss: 2.7732 - val_accuracy: 0.4667\n",
      "Epoch 1515/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3413 - accuracy: 0.9114 - val_loss: 2.7737 - val_accuracy: 0.4667\n",
      "Epoch 1516/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3416 - accuracy: 0.9114 - val_loss: 2.7837 - val_accuracy: 0.4733\n",
      "Epoch 1517/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3410 - accuracy: 0.9114 - val_loss: 2.7642 - val_accuracy: 0.4600\n",
      "Epoch 1518/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3409 - accuracy: 0.9114 - val_loss: 2.7684 - val_accuracy: 0.4633\n",
      "Epoch 1519/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3398 - accuracy: 0.9157 - val_loss: 2.8042 - val_accuracy: 0.4567\n",
      "Epoch 1520/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3395 - accuracy: 0.9114 - val_loss: 2.7768 - val_accuracy: 0.4667\n",
      "Epoch 1521/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3401 - accuracy: 0.9129 - val_loss: 2.7769 - val_accuracy: 0.4633\n",
      "Epoch 1522/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3404 - accuracy: 0.9129 - val_loss: 2.7813 - val_accuracy: 0.4633\n",
      "Epoch 1523/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3396 - accuracy: 0.9143 - val_loss: 2.7802 - val_accuracy: 0.4600\n",
      "Epoch 1524/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3394 - accuracy: 0.9129 - val_loss: 2.7810 - val_accuracy: 0.4633\n",
      "Epoch 1525/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3401 - accuracy: 0.9157 - val_loss: 2.7814 - val_accuracy: 0.4633\n",
      "Epoch 1526/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3400 - accuracy: 0.9129 - val_loss: 2.7821 - val_accuracy: 0.4667\n",
      "Epoch 1527/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3394 - accuracy: 0.9129 - val_loss: 2.7941 - val_accuracy: 0.4733\n",
      "Epoch 1528/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3397 - accuracy: 0.9129 - val_loss: 2.7932 - val_accuracy: 0.4667\n",
      "Epoch 1529/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3400 - accuracy: 0.9114 - val_loss: 2.7929 - val_accuracy: 0.4633\n",
      "Epoch 1530/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3388 - accuracy: 0.9157 - val_loss: 2.7998 - val_accuracy: 0.4700\n",
      "Epoch 1531/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3396 - accuracy: 0.9114 - val_loss: 2.7893 - val_accuracy: 0.4633\n",
      "Epoch 1532/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3388 - accuracy: 0.9143 - val_loss: 2.8010 - val_accuracy: 0.4633\n",
      "Epoch 1533/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3399 - accuracy: 0.9143 - val_loss: 2.7977 - val_accuracy: 0.4633\n",
      "Epoch 1534/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3390 - accuracy: 0.9114 - val_loss: 2.7952 - val_accuracy: 0.4600\n",
      "Epoch 1535/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3387 - accuracy: 0.9129 - val_loss: 2.7972 - val_accuracy: 0.4600\n",
      "Epoch 1536/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3389 - accuracy: 0.9129 - val_loss: 2.7890 - val_accuracy: 0.4667\n",
      "Epoch 1537/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3388 - accuracy: 0.9129 - val_loss: 2.7977 - val_accuracy: 0.4667\n",
      "Epoch 1538/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3384 - accuracy: 0.9129 - val_loss: 2.7983 - val_accuracy: 0.4633\n",
      "Epoch 1539/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3393 - accuracy: 0.9129 - val_loss: 2.8078 - val_accuracy: 0.4667\n",
      "Epoch 1540/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3383 - accuracy: 0.9143 - val_loss: 2.7974 - val_accuracy: 0.4667\n",
      "Epoch 1541/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3377 - accuracy: 0.9114 - val_loss: 2.8132 - val_accuracy: 0.4700\n",
      "Epoch 1542/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3387 - accuracy: 0.9114 - val_loss: 2.8086 - val_accuracy: 0.4700\n",
      "Epoch 1543/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3379 - accuracy: 0.9114 - val_loss: 2.8101 - val_accuracy: 0.4700\n",
      "Epoch 1544/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3386 - accuracy: 0.9114 - val_loss: 2.7934 - val_accuracy: 0.4600\n",
      "Epoch 1545/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3377 - accuracy: 0.9129 - val_loss: 2.8114 - val_accuracy: 0.4633\n",
      "Epoch 1546/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3377 - accuracy: 0.9157 - val_loss: 2.8134 - val_accuracy: 0.4667\n",
      "Epoch 1547/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3380 - accuracy: 0.9129 - val_loss: 2.8203 - val_accuracy: 0.4667\n",
      "Epoch 1548/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3386 - accuracy: 0.9157 - val_loss: 2.8085 - val_accuracy: 0.4700\n",
      "Epoch 1549/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3364 - accuracy: 0.9157 - val_loss: 2.8107 - val_accuracy: 0.4633\n",
      "Epoch 1550/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 87us/step - loss: 0.3381 - accuracy: 0.9114 - val_loss: 2.8152 - val_accuracy: 0.4633\n",
      "Epoch 1551/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3372 - accuracy: 0.9129 - val_loss: 2.8215 - val_accuracy: 0.4667\n",
      "Epoch 1552/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3369 - accuracy: 0.9129 - val_loss: 2.8207 - val_accuracy: 0.4667\n",
      "Epoch 1553/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3371 - accuracy: 0.9129 - val_loss: 2.8094 - val_accuracy: 0.4633\n",
      "Epoch 1554/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3372 - accuracy: 0.9143 - val_loss: 2.8276 - val_accuracy: 0.4700\n",
      "Epoch 1555/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3371 - accuracy: 0.9129 - val_loss: 2.8150 - val_accuracy: 0.4633\n",
      "Epoch 1556/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3365 - accuracy: 0.9129 - val_loss: 2.8192 - val_accuracy: 0.4633\n",
      "Epoch 1557/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3349 - accuracy: 0.9143 - val_loss: 2.8138 - val_accuracy: 0.4633\n",
      "Epoch 1558/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3365 - accuracy: 0.9129 - val_loss: 2.8101 - val_accuracy: 0.4600\n",
      "Epoch 1559/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3368 - accuracy: 0.9143 - val_loss: 2.8373 - val_accuracy: 0.4667\n",
      "Epoch 1560/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3354 - accuracy: 0.9143 - val_loss: 2.8404 - val_accuracy: 0.4633\n",
      "Epoch 1561/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3371 - accuracy: 0.9129 - val_loss: 2.8303 - val_accuracy: 0.4667\n",
      "Epoch 1562/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3364 - accuracy: 0.9157 - val_loss: 2.8259 - val_accuracy: 0.4633\n",
      "Epoch 1563/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3357 - accuracy: 0.9143 - val_loss: 2.8186 - val_accuracy: 0.4633\n",
      "Epoch 1564/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3365 - accuracy: 0.9143 - val_loss: 2.8213 - val_accuracy: 0.4633\n",
      "Epoch 1565/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3361 - accuracy: 0.9114 - val_loss: 2.8363 - val_accuracy: 0.4700\n",
      "Epoch 1566/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3354 - accuracy: 0.9114 - val_loss: 2.8343 - val_accuracy: 0.4667\n",
      "Epoch 1567/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3353 - accuracy: 0.9114 - val_loss: 2.8307 - val_accuracy: 0.4667\n",
      "Epoch 1568/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3353 - accuracy: 0.9157 - val_loss: 2.8254 - val_accuracy: 0.4667\n",
      "Epoch 1569/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3347 - accuracy: 0.9143 - val_loss: 2.8358 - val_accuracy: 0.4600\n",
      "Epoch 1570/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3358 - accuracy: 0.9114 - val_loss: 2.8425 - val_accuracy: 0.4667\n",
      "Epoch 1571/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3355 - accuracy: 0.9143 - val_loss: 2.8391 - val_accuracy: 0.4667\n",
      "Epoch 1572/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3356 - accuracy: 0.9143 - val_loss: 2.8417 - val_accuracy: 0.4633\n",
      "Epoch 1573/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3350 - accuracy: 0.9143 - val_loss: 2.8468 - val_accuracy: 0.4633\n",
      "Epoch 1574/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3350 - accuracy: 0.9129 - val_loss: 2.8356 - val_accuracy: 0.4633\n",
      "Epoch 1575/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3343 - accuracy: 0.9114 - val_loss: 2.8294 - val_accuracy: 0.4633\n",
      "Epoch 1576/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3347 - accuracy: 0.9143 - val_loss: 2.8426 - val_accuracy: 0.4667\n",
      "Epoch 1577/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3349 - accuracy: 0.9143 - val_loss: 2.8435 - val_accuracy: 0.4667\n",
      "Epoch 1578/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3345 - accuracy: 0.9129 - val_loss: 2.8555 - val_accuracy: 0.4700\n",
      "Epoch 1579/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3343 - accuracy: 0.9143 - val_loss: 2.8556 - val_accuracy: 0.4633\n",
      "Epoch 1580/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3351 - accuracy: 0.9157 - val_loss: 2.8514 - val_accuracy: 0.4667\n",
      "Epoch 1581/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3338 - accuracy: 0.9143 - val_loss: 2.8462 - val_accuracy: 0.4633\n",
      "Epoch 1582/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3350 - accuracy: 0.9143 - val_loss: 2.8475 - val_accuracy: 0.4633\n",
      "Epoch 1583/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3346 - accuracy: 0.9143 - val_loss: 2.8486 - val_accuracy: 0.4667\n",
      "Epoch 1584/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3339 - accuracy: 0.9129 - val_loss: 2.8501 - val_accuracy: 0.4600\n",
      "Epoch 1585/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3345 - accuracy: 0.9114 - val_loss: 2.8440 - val_accuracy: 0.4700\n",
      "Epoch 1586/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3337 - accuracy: 0.9143 - val_loss: 2.8486 - val_accuracy: 0.4633\n",
      "Epoch 1587/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3337 - accuracy: 0.9143 - val_loss: 2.8555 - val_accuracy: 0.4667\n",
      "Epoch 1588/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3338 - accuracy: 0.9157 - val_loss: 2.8629 - val_accuracy: 0.4633\n",
      "Epoch 1589/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3329 - accuracy: 0.9143 - val_loss: 2.8627 - val_accuracy: 0.4600\n",
      "Epoch 1590/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3335 - accuracy: 0.9129 - val_loss: 2.8617 - val_accuracy: 0.4600\n",
      "Epoch 1591/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3322 - accuracy: 0.9157 - val_loss: 2.8577 - val_accuracy: 0.4600\n",
      "Epoch 1592/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3327 - accuracy: 0.9129 - val_loss: 2.8501 - val_accuracy: 0.4600\n",
      "Epoch 1593/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3327 - accuracy: 0.9143 - val_loss: 2.8619 - val_accuracy: 0.4633\n",
      "Epoch 1594/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3340 - accuracy: 0.9143 - val_loss: 2.8556 - val_accuracy: 0.4633\n",
      "Epoch 1595/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3331 - accuracy: 0.9129 - val_loss: 2.8604 - val_accuracy: 0.4633\n",
      "Epoch 1596/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3338 - accuracy: 0.9129 - val_loss: 2.8588 - val_accuracy: 0.4633\n",
      "Epoch 1597/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3326 - accuracy: 0.9114 - val_loss: 2.8680 - val_accuracy: 0.4700\n",
      "Epoch 1598/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3332 - accuracy: 0.9143 - val_loss: 2.8587 - val_accuracy: 0.4633\n",
      "Epoch 1599/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3314 - accuracy: 0.9129 - val_loss: 2.8628 - val_accuracy: 0.4633\n",
      "Epoch 1600/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3322 - accuracy: 0.9143 - val_loss: 2.8708 - val_accuracy: 0.4667\n",
      "Epoch 1601/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3317 - accuracy: 0.9157 - val_loss: 2.8764 - val_accuracy: 0.4667\n",
      "Epoch 1602/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3322 - accuracy: 0.9143 - val_loss: 2.8735 - val_accuracy: 0.4667\n",
      "Epoch 1603/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3319 - accuracy: 0.9129 - val_loss: 2.8758 - val_accuracy: 0.4700\n",
      "Epoch 1604/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3318 - accuracy: 0.9171 - val_loss: 2.8791 - val_accuracy: 0.4667\n",
      "Epoch 1605/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 0.3312 - accuracy: 0.9143 - val_loss: 2.8723 - val_accuracy: 0.4633\n",
      "Epoch 1606/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3327 - accuracy: 0.9129 - val_loss: 2.8792 - val_accuracy: 0.4667\n",
      "Epoch 1607/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3323 - accuracy: 0.9129 - val_loss: 2.8882 - val_accuracy: 0.4667\n",
      "Epoch 1608/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3320 - accuracy: 0.9114 - val_loss: 2.8853 - val_accuracy: 0.4600\n",
      "Epoch 1609/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3319 - accuracy: 0.9143 - val_loss: 2.8815 - val_accuracy: 0.4633\n",
      "Epoch 1610/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3309 - accuracy: 0.9143 - val_loss: 2.8776 - val_accuracy: 0.4567\n",
      "Epoch 1611/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3324 - accuracy: 0.9143 - val_loss: 2.8870 - val_accuracy: 0.4667\n",
      "Epoch 1612/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3320 - accuracy: 0.9157 - val_loss: 2.8778 - val_accuracy: 0.4633\n",
      "Epoch 1613/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3313 - accuracy: 0.9143 - val_loss: 2.8917 - val_accuracy: 0.4667\n",
      "Epoch 1614/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3307 - accuracy: 0.9143 - val_loss: 2.8915 - val_accuracy: 0.4667\n",
      "Epoch 1615/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3311 - accuracy: 0.9143 - val_loss: 2.8872 - val_accuracy: 0.4667\n",
      "Epoch 1616/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3312 - accuracy: 0.9143 - val_loss: 2.8841 - val_accuracy: 0.4633\n",
      "Epoch 1617/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3315 - accuracy: 0.9129 - val_loss: 2.8980 - val_accuracy: 0.4667\n",
      "Epoch 1618/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3313 - accuracy: 0.9114 - val_loss: 2.8940 - val_accuracy: 0.4700\n",
      "Epoch 1619/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3311 - accuracy: 0.9114 - val_loss: 2.8818 - val_accuracy: 0.4667\n",
      "Epoch 1620/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3300 - accuracy: 0.9143 - val_loss: 2.9063 - val_accuracy: 0.4700\n",
      "Epoch 1621/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3314 - accuracy: 0.9129 - val_loss: 2.9030 - val_accuracy: 0.4567\n",
      "Epoch 1622/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3309 - accuracy: 0.9143 - val_loss: 2.9036 - val_accuracy: 0.4667\n",
      "Epoch 1623/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3307 - accuracy: 0.9143 - val_loss: 2.9011 - val_accuracy: 0.4700\n",
      "Epoch 1624/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3298 - accuracy: 0.9157 - val_loss: 2.9037 - val_accuracy: 0.4633\n",
      "Epoch 1625/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3305 - accuracy: 0.9157 - val_loss: 2.9049 - val_accuracy: 0.4633\n",
      "Epoch 1626/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3298 - accuracy: 0.9157 - val_loss: 2.9107 - val_accuracy: 0.4633\n",
      "Epoch 1627/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3306 - accuracy: 0.9186 - val_loss: 2.9049 - val_accuracy: 0.4667\n",
      "Epoch 1628/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3298 - accuracy: 0.9143 - val_loss: 2.9082 - val_accuracy: 0.4667\n",
      "Epoch 1629/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3295 - accuracy: 0.9114 - val_loss: 2.9157 - val_accuracy: 0.4633\n",
      "Epoch 1630/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3301 - accuracy: 0.9157 - val_loss: 2.9054 - val_accuracy: 0.4633\n",
      "Epoch 1631/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3300 - accuracy: 0.9114 - val_loss: 2.8993 - val_accuracy: 0.4633\n",
      "Epoch 1632/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3293 - accuracy: 0.9171 - val_loss: 2.9175 - val_accuracy: 0.4667\n",
      "Epoch 1633/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3296 - accuracy: 0.9143 - val_loss: 2.9124 - val_accuracy: 0.4667\n",
      "Epoch 1634/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3298 - accuracy: 0.9157 - val_loss: 2.9137 - val_accuracy: 0.4733\n",
      "Epoch 1635/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3289 - accuracy: 0.9143 - val_loss: 2.9170 - val_accuracy: 0.4667\n",
      "Epoch 1636/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3291 - accuracy: 0.9157 - val_loss: 2.9196 - val_accuracy: 0.4700\n",
      "Epoch 1637/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3287 - accuracy: 0.9171 - val_loss: 2.9139 - val_accuracy: 0.4633\n",
      "Epoch 1638/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3288 - accuracy: 0.9143 - val_loss: 2.9194 - val_accuracy: 0.4667\n",
      "Epoch 1639/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3298 - accuracy: 0.9143 - val_loss: 2.9215 - val_accuracy: 0.4700\n",
      "Epoch 1640/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3280 - accuracy: 0.9143 - val_loss: 2.9266 - val_accuracy: 0.4667\n",
      "Epoch 1641/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3276 - accuracy: 0.9200 - val_loss: 2.9311 - val_accuracy: 0.4633\n",
      "Epoch 1642/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3287 - accuracy: 0.9157 - val_loss: 2.9232 - val_accuracy: 0.4667\n",
      "Epoch 1643/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3285 - accuracy: 0.9157 - val_loss: 2.9248 - val_accuracy: 0.4700\n",
      "Epoch 1644/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3282 - accuracy: 0.9171 - val_loss: 2.9249 - val_accuracy: 0.4667\n",
      "Epoch 1645/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3288 - accuracy: 0.9157 - val_loss: 2.9268 - val_accuracy: 0.4633\n",
      "Epoch 1646/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3287 - accuracy: 0.9157 - val_loss: 2.9208 - val_accuracy: 0.4667\n",
      "Epoch 1647/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3280 - accuracy: 0.9186 - val_loss: 2.9299 - val_accuracy: 0.4733\n",
      "Epoch 1648/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3278 - accuracy: 0.9157 - val_loss: 2.9360 - val_accuracy: 0.4633\n",
      "Epoch 1649/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3276 - accuracy: 0.9143 - val_loss: 2.9281 - val_accuracy: 0.4633\n",
      "Epoch 1650/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3277 - accuracy: 0.9143 - val_loss: 2.9286 - val_accuracy: 0.4667\n",
      "Epoch 1651/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3275 - accuracy: 0.9143 - val_loss: 2.9301 - val_accuracy: 0.4667\n",
      "Epoch 1652/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3278 - accuracy: 0.9129 - val_loss: 2.9212 - val_accuracy: 0.4567\n",
      "Epoch 1653/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3277 - accuracy: 0.9186 - val_loss: 2.9166 - val_accuracy: 0.4567\n",
      "Epoch 1654/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3269 - accuracy: 0.9143 - val_loss: 2.9277 - val_accuracy: 0.4633\n",
      "Epoch 1655/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3280 - accuracy: 0.9171 - val_loss: 2.9356 - val_accuracy: 0.4667\n",
      "Epoch 1656/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3263 - accuracy: 0.9171 - val_loss: 2.9307 - val_accuracy: 0.4600\n",
      "Epoch 1657/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3268 - accuracy: 0.9143 - val_loss: 2.9449 - val_accuracy: 0.4733\n",
      "Epoch 1658/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3266 - accuracy: 0.9171 - val_loss: 2.9506 - val_accuracy: 0.4667\n",
      "Epoch 1659/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3270 - accuracy: 0.9143 - val_loss: 2.9478 - val_accuracy: 0.4667\n",
      "Epoch 1660/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.3273 - accuracy: 0.9200 - val_loss: 2.9467 - val_accuracy: 0.4700\n",
      "Epoch 1661/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3267 - accuracy: 0.9157 - val_loss: 2.9405 - val_accuracy: 0.4667\n",
      "Epoch 1662/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3265 - accuracy: 0.9157 - val_loss: 2.9254 - val_accuracy: 0.4633\n",
      "Epoch 1663/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3270 - accuracy: 0.9157 - val_loss: 2.9362 - val_accuracy: 0.4633\n",
      "Epoch 1664/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3273 - accuracy: 0.9143 - val_loss: 2.9409 - val_accuracy: 0.4633\n",
      "Epoch 1665/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3263 - accuracy: 0.9114 - val_loss: 2.9396 - val_accuracy: 0.4633\n",
      "Epoch 1666/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3264 - accuracy: 0.9129 - val_loss: 2.9478 - val_accuracy: 0.4600\n",
      "Epoch 1667/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3259 - accuracy: 0.9157 - val_loss: 2.9421 - val_accuracy: 0.4633\n",
      "Epoch 1668/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3267 - accuracy: 0.9157 - val_loss: 2.9453 - val_accuracy: 0.4633\n",
      "Epoch 1669/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3260 - accuracy: 0.9157 - val_loss: 2.9511 - val_accuracy: 0.4700\n",
      "Epoch 1670/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3262 - accuracy: 0.9143 - val_loss: 2.9607 - val_accuracy: 0.4667\n",
      "Epoch 1671/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3263 - accuracy: 0.9171 - val_loss: 2.9524 - val_accuracy: 0.4667\n",
      "Epoch 1672/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3259 - accuracy: 0.9171 - val_loss: 2.9486 - val_accuracy: 0.4567\n",
      "Epoch 1673/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3265 - accuracy: 0.9143 - val_loss: 2.9526 - val_accuracy: 0.4667\n",
      "Epoch 1674/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3261 - accuracy: 0.9157 - val_loss: 2.9630 - val_accuracy: 0.4633\n",
      "Epoch 1675/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3260 - accuracy: 0.9143 - val_loss: 2.9625 - val_accuracy: 0.4700\n",
      "Epoch 1676/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3257 - accuracy: 0.9171 - val_loss: 2.9520 - val_accuracy: 0.4667\n",
      "Epoch 1677/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3255 - accuracy: 0.9171 - val_loss: 2.9613 - val_accuracy: 0.4733\n",
      "Epoch 1678/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3258 - accuracy: 0.9186 - val_loss: 2.9595 - val_accuracy: 0.4633\n",
      "Epoch 1679/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3256 - accuracy: 0.9157 - val_loss: 2.9629 - val_accuracy: 0.4667\n",
      "Epoch 1680/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3248 - accuracy: 0.9157 - val_loss: 2.9557 - val_accuracy: 0.4633\n",
      "Epoch 1681/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3250 - accuracy: 0.9171 - val_loss: 2.9505 - val_accuracy: 0.4633\n",
      "Epoch 1682/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3252 - accuracy: 0.9171 - val_loss: 2.9626 - val_accuracy: 0.4633\n",
      "Epoch 1683/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3244 - accuracy: 0.9129 - val_loss: 2.9704 - val_accuracy: 0.4733\n",
      "Epoch 1684/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3250 - accuracy: 0.9171 - val_loss: 2.9625 - val_accuracy: 0.4733\n",
      "Epoch 1685/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3245 - accuracy: 0.9171 - val_loss: 2.9657 - val_accuracy: 0.4633\n",
      "Epoch 1686/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3242 - accuracy: 0.9186 - val_loss: 2.9694 - val_accuracy: 0.4633\n",
      "Epoch 1687/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3242 - accuracy: 0.9157 - val_loss: 2.9740 - val_accuracy: 0.4700\n",
      "Epoch 1688/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3231 - accuracy: 0.9186 - val_loss: 2.9600 - val_accuracy: 0.4633\n",
      "Epoch 1689/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3243 - accuracy: 0.9171 - val_loss: 2.9625 - val_accuracy: 0.4667\n",
      "Epoch 1690/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3235 - accuracy: 0.9171 - val_loss: 2.9854 - val_accuracy: 0.4733\n",
      "Epoch 1691/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3240 - accuracy: 0.9186 - val_loss: 2.9772 - val_accuracy: 0.4633\n",
      "Epoch 1692/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3244 - accuracy: 0.9200 - val_loss: 2.9758 - val_accuracy: 0.4700\n",
      "Epoch 1693/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3253 - accuracy: 0.9143 - val_loss: 2.9739 - val_accuracy: 0.4667\n",
      "Epoch 1694/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3237 - accuracy: 0.9157 - val_loss: 2.9732 - val_accuracy: 0.4667\n",
      "Epoch 1695/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3239 - accuracy: 0.9157 - val_loss: 2.9639 - val_accuracy: 0.4700\n",
      "Epoch 1696/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3237 - accuracy: 0.9171 - val_loss: 2.9790 - val_accuracy: 0.4633\n",
      "Epoch 1697/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3246 - accuracy: 0.9143 - val_loss: 2.9790 - val_accuracy: 0.4700\n",
      "Epoch 1698/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3233 - accuracy: 0.9171 - val_loss: 2.9797 - val_accuracy: 0.4633\n",
      "Epoch 1699/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3243 - accuracy: 0.9157 - val_loss: 2.9899 - val_accuracy: 0.4667\n",
      "Epoch 1700/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3231 - accuracy: 0.9171 - val_loss: 2.9949 - val_accuracy: 0.4733\n",
      "Epoch 1701/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3233 - accuracy: 0.9157 - val_loss: 2.9925 - val_accuracy: 0.4700\n",
      "Epoch 1702/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3226 - accuracy: 0.9157 - val_loss: 3.0140 - val_accuracy: 0.4567\n",
      "Epoch 1703/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3246 - accuracy: 0.9171 - val_loss: 2.9728 - val_accuracy: 0.4700\n",
      "Epoch 1704/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3227 - accuracy: 0.9186 - val_loss: 2.9873 - val_accuracy: 0.4667\n",
      "Epoch 1705/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3245 - accuracy: 0.9157 - val_loss: 2.9914 - val_accuracy: 0.4667\n",
      "Epoch 1706/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3228 - accuracy: 0.9200 - val_loss: 2.9928 - val_accuracy: 0.4733\n",
      "Epoch 1707/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3227 - accuracy: 0.9186 - val_loss: 2.9943 - val_accuracy: 0.4733\n",
      "Epoch 1708/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3225 - accuracy: 0.9171 - val_loss: 3.0030 - val_accuracy: 0.4633\n",
      "Epoch 1709/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3224 - accuracy: 0.9186 - val_loss: 2.9987 - val_accuracy: 0.4700\n",
      "Epoch 1710/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3230 - accuracy: 0.9143 - val_loss: 3.0039 - val_accuracy: 0.4667\n",
      "Epoch 1711/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3226 - accuracy: 0.9171 - val_loss: 2.9937 - val_accuracy: 0.4700\n",
      "Epoch 1712/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3220 - accuracy: 0.9171 - val_loss: 2.9964 - val_accuracy: 0.4533\n",
      "Epoch 1713/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3233 - accuracy: 0.9200 - val_loss: 3.0042 - val_accuracy: 0.4733\n",
      "Epoch 1714/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3221 - accuracy: 0.9200 - val_loss: 2.9914 - val_accuracy: 0.4667\n",
      "Epoch 1715/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 0.3221 - accuracy: 0.9143 - val_loss: 2.9888 - val_accuracy: 0.4700\n",
      "Epoch 1716/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3219 - accuracy: 0.9171 - val_loss: 2.9881 - val_accuracy: 0.4667\n",
      "Epoch 1717/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3216 - accuracy: 0.9171 - val_loss: 3.0017 - val_accuracy: 0.4633\n",
      "Epoch 1718/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.3221 - accuracy: 0.9186 - val_loss: 3.0012 - val_accuracy: 0.4700\n",
      "Epoch 1719/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3224 - accuracy: 0.9157 - val_loss: 3.0011 - val_accuracy: 0.4633\n",
      "Epoch 1720/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3213 - accuracy: 0.9171 - val_loss: 2.9980 - val_accuracy: 0.4667\n",
      "Epoch 1721/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3216 - accuracy: 0.9171 - val_loss: 3.0105 - val_accuracy: 0.4667\n",
      "Epoch 1722/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3215 - accuracy: 0.9171 - val_loss: 3.0014 - val_accuracy: 0.4700\n",
      "Epoch 1723/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3218 - accuracy: 0.9186 - val_loss: 3.0031 - val_accuracy: 0.4667\n",
      "Epoch 1724/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3211 - accuracy: 0.9186 - val_loss: 3.0148 - val_accuracy: 0.4667\n",
      "Epoch 1725/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3215 - accuracy: 0.9186 - val_loss: 2.9997 - val_accuracy: 0.4667\n",
      "Epoch 1726/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3207 - accuracy: 0.9171 - val_loss: 3.0179 - val_accuracy: 0.4667\n",
      "Epoch 1727/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3202 - accuracy: 0.9157 - val_loss: 3.0202 - val_accuracy: 0.4733\n",
      "Epoch 1728/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3217 - accuracy: 0.9214 - val_loss: 3.0151 - val_accuracy: 0.4633\n",
      "Epoch 1729/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3207 - accuracy: 0.9186 - val_loss: 3.0292 - val_accuracy: 0.4567\n",
      "Epoch 1730/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3209 - accuracy: 0.9186 - val_loss: 3.0155 - val_accuracy: 0.4667\n",
      "Epoch 1731/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3210 - accuracy: 0.9200 - val_loss: 3.0185 - val_accuracy: 0.4733\n",
      "Epoch 1732/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3212 - accuracy: 0.9186 - val_loss: 3.0131 - val_accuracy: 0.4700\n",
      "Epoch 1733/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3202 - accuracy: 0.9186 - val_loss: 3.0225 - val_accuracy: 0.4700\n",
      "Epoch 1734/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3200 - accuracy: 0.9200 - val_loss: 3.0190 - val_accuracy: 0.4600\n",
      "Epoch 1735/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3200 - accuracy: 0.9171 - val_loss: 3.0218 - val_accuracy: 0.4667\n",
      "Epoch 1736/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3209 - accuracy: 0.9157 - val_loss: 3.0244 - val_accuracy: 0.4700\n",
      "Epoch 1737/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3205 - accuracy: 0.9200 - val_loss: 3.0229 - val_accuracy: 0.4600\n",
      "Epoch 1738/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3199 - accuracy: 0.9143 - val_loss: 3.0247 - val_accuracy: 0.4733\n",
      "Epoch 1739/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3196 - accuracy: 0.9186 - val_loss: 3.0199 - val_accuracy: 0.4633\n",
      "Epoch 1740/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3200 - accuracy: 0.9143 - val_loss: 3.0419 - val_accuracy: 0.4533\n",
      "Epoch 1741/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3198 - accuracy: 0.9171 - val_loss: 3.0324 - val_accuracy: 0.4733\n",
      "Epoch 1742/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3205 - accuracy: 0.9186 - val_loss: 3.0175 - val_accuracy: 0.4600\n",
      "Epoch 1743/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3199 - accuracy: 0.9186 - val_loss: 3.0299 - val_accuracy: 0.4733\n",
      "Epoch 1744/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3194 - accuracy: 0.9186 - val_loss: 3.0408 - val_accuracy: 0.4667\n",
      "Epoch 1745/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3198 - accuracy: 0.9186 - val_loss: 3.0448 - val_accuracy: 0.4700\n",
      "Epoch 1746/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3200 - accuracy: 0.9186 - val_loss: 3.0362 - val_accuracy: 0.4700\n",
      "Epoch 1747/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3193 - accuracy: 0.9157 - val_loss: 3.0505 - val_accuracy: 0.4600\n",
      "Epoch 1748/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3194 - accuracy: 0.9186 - val_loss: 3.0370 - val_accuracy: 0.4667\n",
      "Epoch 1749/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3193 - accuracy: 0.9171 - val_loss: 3.0405 - val_accuracy: 0.4600\n",
      "Epoch 1750/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3195 - accuracy: 0.9200 - val_loss: 3.0305 - val_accuracy: 0.4633\n",
      "Epoch 1751/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3195 - accuracy: 0.9200 - val_loss: 3.0330 - val_accuracy: 0.4700\n",
      "Epoch 1752/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3190 - accuracy: 0.9157 - val_loss: 3.0515 - val_accuracy: 0.4567\n",
      "Epoch 1753/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3198 - accuracy: 0.9171 - val_loss: 3.0483 - val_accuracy: 0.4633\n",
      "Epoch 1754/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3186 - accuracy: 0.9200 - val_loss: 3.0335 - val_accuracy: 0.4700\n",
      "Epoch 1755/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3194 - accuracy: 0.9186 - val_loss: 3.0491 - val_accuracy: 0.4667\n",
      "Epoch 1756/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3184 - accuracy: 0.9200 - val_loss: 3.0489 - val_accuracy: 0.4667\n",
      "Epoch 1757/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3184 - accuracy: 0.9186 - val_loss: 3.0464 - val_accuracy: 0.4633\n",
      "Epoch 1758/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3182 - accuracy: 0.9186 - val_loss: 3.0427 - val_accuracy: 0.4633\n",
      "Epoch 1759/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3182 - accuracy: 0.9186 - val_loss: 3.0456 - val_accuracy: 0.4667\n",
      "Epoch 1760/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3187 - accuracy: 0.9157 - val_loss: 3.0634 - val_accuracy: 0.4633\n",
      "Epoch 1761/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3187 - accuracy: 0.9200 - val_loss: 3.0604 - val_accuracy: 0.4733\n",
      "Epoch 1762/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3191 - accuracy: 0.9171 - val_loss: 3.0492 - val_accuracy: 0.4667\n",
      "Epoch 1763/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3186 - accuracy: 0.9186 - val_loss: 3.0616 - val_accuracy: 0.4633\n",
      "Epoch 1764/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3184 - accuracy: 0.9186 - val_loss: 3.0489 - val_accuracy: 0.4633\n",
      "Epoch 1765/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3182 - accuracy: 0.9171 - val_loss: 3.0509 - val_accuracy: 0.4633\n",
      "Epoch 1766/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3182 - accuracy: 0.9186 - val_loss: 3.0459 - val_accuracy: 0.4567\n",
      "Epoch 1767/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3175 - accuracy: 0.9186 - val_loss: 3.0517 - val_accuracy: 0.4667\n",
      "Epoch 1768/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3170 - accuracy: 0.9171 - val_loss: 3.0551 - val_accuracy: 0.4767\n",
      "Epoch 1769/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3171 - accuracy: 0.9186 - val_loss: 3.0607 - val_accuracy: 0.4767\n",
      "Epoch 1770/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 0.3182 - accuracy: 0.9157 - val_loss: 3.0539 - val_accuracy: 0.4733\n",
      "Epoch 1771/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3175 - accuracy: 0.9214 - val_loss: 3.0640 - val_accuracy: 0.4633\n",
      "Epoch 1772/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3171 - accuracy: 0.9186 - val_loss: 3.0641 - val_accuracy: 0.4700\n",
      "Epoch 1773/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3174 - accuracy: 0.9171 - val_loss: 3.0790 - val_accuracy: 0.4600\n",
      "Epoch 1774/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3171 - accuracy: 0.9200 - val_loss: 3.0807 - val_accuracy: 0.4633\n",
      "Epoch 1775/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3180 - accuracy: 0.9200 - val_loss: 3.0615 - val_accuracy: 0.4700\n",
      "Epoch 1776/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3172 - accuracy: 0.9200 - val_loss: 3.0675 - val_accuracy: 0.4667\n",
      "Epoch 1777/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3167 - accuracy: 0.9200 - val_loss: 3.0848 - val_accuracy: 0.4567\n",
      "Epoch 1778/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3171 - accuracy: 0.9186 - val_loss: 3.0745 - val_accuracy: 0.4667\n",
      "Epoch 1779/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3168 - accuracy: 0.9200 - val_loss: 3.0811 - val_accuracy: 0.4733\n",
      "Epoch 1780/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3163 - accuracy: 0.9186 - val_loss: 3.0557 - val_accuracy: 0.4700\n",
      "Epoch 1781/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3165 - accuracy: 0.9157 - val_loss: 3.0710 - val_accuracy: 0.4667\n",
      "Epoch 1782/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3159 - accuracy: 0.9214 - val_loss: 3.0665 - val_accuracy: 0.4700\n",
      "Epoch 1783/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3168 - accuracy: 0.9171 - val_loss: 3.0707 - val_accuracy: 0.4667\n",
      "Epoch 1784/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3164 - accuracy: 0.9200 - val_loss: 3.0646 - val_accuracy: 0.4667\n",
      "Epoch 1785/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3165 - accuracy: 0.9186 - val_loss: 3.0830 - val_accuracy: 0.4600\n",
      "Epoch 1786/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3157 - accuracy: 0.9200 - val_loss: 3.0765 - val_accuracy: 0.4533\n",
      "Epoch 1787/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3169 - accuracy: 0.9229 - val_loss: 3.0732 - val_accuracy: 0.4533\n",
      "Epoch 1788/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3164 - accuracy: 0.9214 - val_loss: 3.0884 - val_accuracy: 0.4600\n",
      "Epoch 1789/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3163 - accuracy: 0.9186 - val_loss: 3.0862 - val_accuracy: 0.4667\n",
      "Epoch 1790/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3162 - accuracy: 0.9186 - val_loss: 3.0759 - val_accuracy: 0.4667\n",
      "Epoch 1791/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3159 - accuracy: 0.9157 - val_loss: 3.0875 - val_accuracy: 0.4567\n",
      "Epoch 1792/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3158 - accuracy: 0.9200 - val_loss: 3.0754 - val_accuracy: 0.4667\n",
      "Epoch 1793/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3155 - accuracy: 0.9186 - val_loss: 3.0884 - val_accuracy: 0.4733\n",
      "Epoch 1794/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3162 - accuracy: 0.9200 - val_loss: 3.0920 - val_accuracy: 0.4600\n",
      "Epoch 1795/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3157 - accuracy: 0.9200 - val_loss: 3.0761 - val_accuracy: 0.4633\n",
      "Epoch 1796/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3152 - accuracy: 0.9200 - val_loss: 3.0864 - val_accuracy: 0.4700\n",
      "Epoch 1797/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3146 - accuracy: 0.9214 - val_loss: 3.0885 - val_accuracy: 0.4633\n",
      "Epoch 1798/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3156 - accuracy: 0.9214 - val_loss: 3.0843 - val_accuracy: 0.4667\n",
      "Epoch 1799/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3153 - accuracy: 0.9200 - val_loss: 3.0903 - val_accuracy: 0.4567\n",
      "Epoch 1800/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3139 - accuracy: 0.9214 - val_loss: 3.0977 - val_accuracy: 0.4700\n",
      "Epoch 1801/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3154 - accuracy: 0.9214 - val_loss: 3.0886 - val_accuracy: 0.4667\n",
      "Epoch 1802/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3158 - accuracy: 0.9186 - val_loss: 3.0867 - val_accuracy: 0.4567\n",
      "Epoch 1803/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3147 - accuracy: 0.9200 - val_loss: 3.1045 - val_accuracy: 0.4600\n",
      "Epoch 1804/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3150 - accuracy: 0.9186 - val_loss: 3.0992 - val_accuracy: 0.4567\n",
      "Epoch 1805/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.3146 - accuracy: 0.9200 - val_loss: 3.1002 - val_accuracy: 0.4700\n",
      "Epoch 1806/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3156 - accuracy: 0.9200 - val_loss: 3.1056 - val_accuracy: 0.4633\n",
      "Epoch 1807/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3138 - accuracy: 0.9200 - val_loss: 3.0998 - val_accuracy: 0.4700\n",
      "Epoch 1808/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3150 - accuracy: 0.9200 - val_loss: 3.1129 - val_accuracy: 0.4567\n",
      "Epoch 1809/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3150 - accuracy: 0.9214 - val_loss: 3.0924 - val_accuracy: 0.4600\n",
      "Epoch 1810/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3145 - accuracy: 0.9200 - val_loss: 3.1011 - val_accuracy: 0.4533\n",
      "Epoch 1811/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3149 - accuracy: 0.9186 - val_loss: 3.0896 - val_accuracy: 0.4567\n",
      "Epoch 1812/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3145 - accuracy: 0.9214 - val_loss: 3.1084 - val_accuracy: 0.4533\n",
      "Epoch 1813/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3136 - accuracy: 0.9200 - val_loss: 3.1113 - val_accuracy: 0.4633\n",
      "Epoch 1814/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3143 - accuracy: 0.9214 - val_loss: 3.1022 - val_accuracy: 0.4533\n",
      "Epoch 1815/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3139 - accuracy: 0.9214 - val_loss: 3.1171 - val_accuracy: 0.4667\n",
      "Epoch 1816/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3136 - accuracy: 0.9200 - val_loss: 3.1065 - val_accuracy: 0.4567\n",
      "Epoch 1817/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3146 - accuracy: 0.9200 - val_loss: 3.1166 - val_accuracy: 0.4700\n",
      "Epoch 1818/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3142 - accuracy: 0.9200 - val_loss: 3.1013 - val_accuracy: 0.4700\n",
      "Epoch 1819/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3141 - accuracy: 0.9200 - val_loss: 3.1053 - val_accuracy: 0.4567\n",
      "Epoch 1820/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3149 - accuracy: 0.9186 - val_loss: 3.1071 - val_accuracy: 0.4633\n",
      "Epoch 1821/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3137 - accuracy: 0.9214 - val_loss: 3.1168 - val_accuracy: 0.4667\n",
      "Epoch 1822/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3126 - accuracy: 0.9200 - val_loss: 3.1105 - val_accuracy: 0.4667\n",
      "Epoch 1823/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3136 - accuracy: 0.9186 - val_loss: 3.1206 - val_accuracy: 0.4700\n",
      "Epoch 1824/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3132 - accuracy: 0.9186 - val_loss: 3.0998 - val_accuracy: 0.4600\n",
      "Epoch 1825/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 110us/step - loss: 0.3138 - accuracy: 0.9186 - val_loss: 3.1006 - val_accuracy: 0.4600\n",
      "Epoch 1826/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3134 - accuracy: 0.9229 - val_loss: 3.1292 - val_accuracy: 0.4567\n",
      "Epoch 1827/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3136 - accuracy: 0.9214 - val_loss: 3.1130 - val_accuracy: 0.4700\n",
      "Epoch 1828/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3132 - accuracy: 0.9214 - val_loss: 3.1287 - val_accuracy: 0.4700\n",
      "Epoch 1829/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3137 - accuracy: 0.9200 - val_loss: 3.1197 - val_accuracy: 0.4667\n",
      "Epoch 1830/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3123 - accuracy: 0.9243 - val_loss: 3.1406 - val_accuracy: 0.4567\n",
      "Epoch 1831/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3130 - accuracy: 0.9200 - val_loss: 3.1248 - val_accuracy: 0.4667\n",
      "Epoch 1832/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3133 - accuracy: 0.9200 - val_loss: 3.1343 - val_accuracy: 0.4567\n",
      "Epoch 1833/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3130 - accuracy: 0.9229 - val_loss: 3.1205 - val_accuracy: 0.4600\n",
      "Epoch 1834/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3124 - accuracy: 0.9200 - val_loss: 3.1146 - val_accuracy: 0.4567\n",
      "Epoch 1835/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3135 - accuracy: 0.9214 - val_loss: 3.1352 - val_accuracy: 0.4667\n",
      "Epoch 1836/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3126 - accuracy: 0.9200 - val_loss: 3.1410 - val_accuracy: 0.4600\n",
      "Epoch 1837/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3124 - accuracy: 0.9229 - val_loss: 3.1337 - val_accuracy: 0.4633\n",
      "Epoch 1838/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3127 - accuracy: 0.9200 - val_loss: 3.1375 - val_accuracy: 0.4667\n",
      "Epoch 1839/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3123 - accuracy: 0.9214 - val_loss: 3.1372 - val_accuracy: 0.4600\n",
      "Epoch 1840/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3124 - accuracy: 0.9229 - val_loss: 3.1346 - val_accuracy: 0.4633\n",
      "Epoch 1841/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3130 - accuracy: 0.9214 - val_loss: 3.1316 - val_accuracy: 0.4633\n",
      "Epoch 1842/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3126 - accuracy: 0.9214 - val_loss: 3.1340 - val_accuracy: 0.4600\n",
      "Epoch 1843/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3114 - accuracy: 0.9214 - val_loss: 3.1351 - val_accuracy: 0.4633\n",
      "Epoch 1844/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3119 - accuracy: 0.9229 - val_loss: 3.1381 - val_accuracy: 0.4700\n",
      "Epoch 1845/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3128 - accuracy: 0.9229 - val_loss: 3.1414 - val_accuracy: 0.4633\n",
      "Epoch 1846/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3126 - accuracy: 0.9214 - val_loss: 3.1367 - val_accuracy: 0.4667\n",
      "Epoch 1847/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3118 - accuracy: 0.9214 - val_loss: 3.1411 - val_accuracy: 0.4633\n",
      "Epoch 1848/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3113 - accuracy: 0.9229 - val_loss: 3.1423 - val_accuracy: 0.4633\n",
      "Epoch 1849/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3115 - accuracy: 0.9200 - val_loss: 3.1510 - val_accuracy: 0.4667\n",
      "Epoch 1850/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3115 - accuracy: 0.9214 - val_loss: 3.1589 - val_accuracy: 0.4567\n",
      "Epoch 1851/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3117 - accuracy: 0.9214 - val_loss: 3.1505 - val_accuracy: 0.4667\n",
      "Epoch 1852/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3116 - accuracy: 0.9214 - val_loss: 3.1429 - val_accuracy: 0.4700\n",
      "Epoch 1853/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3113 - accuracy: 0.9214 - val_loss: 3.1574 - val_accuracy: 0.4667\n",
      "Epoch 1854/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3112 - accuracy: 0.9214 - val_loss: 3.1656 - val_accuracy: 0.4533\n",
      "Epoch 1855/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3118 - accuracy: 0.9214 - val_loss: 3.1472 - val_accuracy: 0.4667\n",
      "Epoch 1856/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3121 - accuracy: 0.9229 - val_loss: 3.1597 - val_accuracy: 0.4600\n",
      "Epoch 1857/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3108 - accuracy: 0.9200 - val_loss: 3.1570 - val_accuracy: 0.4667\n",
      "Epoch 1858/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3112 - accuracy: 0.9186 - val_loss: 3.1481 - val_accuracy: 0.4667\n",
      "Epoch 1859/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3114 - accuracy: 0.9214 - val_loss: 3.1638 - val_accuracy: 0.4733\n",
      "Epoch 1860/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3105 - accuracy: 0.9214 - val_loss: 3.1385 - val_accuracy: 0.4600\n",
      "Epoch 1861/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3106 - accuracy: 0.9200 - val_loss: 3.1611 - val_accuracy: 0.4600\n",
      "Epoch 1862/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3115 - accuracy: 0.9214 - val_loss: 3.1479 - val_accuracy: 0.4600\n",
      "Epoch 1863/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3112 - accuracy: 0.9214 - val_loss: 3.1559 - val_accuracy: 0.4633\n",
      "Epoch 1864/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3098 - accuracy: 0.9186 - val_loss: 3.1693 - val_accuracy: 0.4667\n",
      "Epoch 1865/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3104 - accuracy: 0.9200 - val_loss: 3.1525 - val_accuracy: 0.4633\n",
      "Epoch 1866/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3106 - accuracy: 0.9186 - val_loss: 3.1715 - val_accuracy: 0.4567\n",
      "Epoch 1867/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3105 - accuracy: 0.9214 - val_loss: 3.1670 - val_accuracy: 0.4667\n",
      "Epoch 1868/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3096 - accuracy: 0.9214 - val_loss: 3.1678 - val_accuracy: 0.4633\n",
      "Epoch 1869/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3108 - accuracy: 0.9214 - val_loss: 3.1661 - val_accuracy: 0.4633\n",
      "Epoch 1870/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3103 - accuracy: 0.9200 - val_loss: 3.1658 - val_accuracy: 0.4700\n",
      "Epoch 1871/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3104 - accuracy: 0.9214 - val_loss: 3.1707 - val_accuracy: 0.4633\n",
      "Epoch 1872/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3098 - accuracy: 0.9214 - val_loss: 3.1651 - val_accuracy: 0.4633\n",
      "Epoch 1873/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3098 - accuracy: 0.9214 - val_loss: 3.1466 - val_accuracy: 0.4600\n",
      "Epoch 1874/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3100 - accuracy: 0.9214 - val_loss: 3.1648 - val_accuracy: 0.4667\n",
      "Epoch 1875/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3094 - accuracy: 0.9214 - val_loss: 3.1731 - val_accuracy: 0.4633\n",
      "Epoch 1876/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3101 - accuracy: 0.9214 - val_loss: 3.1794 - val_accuracy: 0.4633\n",
      "Epoch 1877/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3098 - accuracy: 0.9214 - val_loss: 3.1684 - val_accuracy: 0.4600\n",
      "Epoch 1878/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3099 - accuracy: 0.9214 - val_loss: 3.1691 - val_accuracy: 0.4667\n",
      "Epoch 1879/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3095 - accuracy: 0.9214 - val_loss: 3.1788 - val_accuracy: 0.4567\n",
      "Epoch 1880/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 0.3099 - accuracy: 0.9186 - val_loss: 3.1632 - val_accuracy: 0.4600\n",
      "Epoch 1881/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3093 - accuracy: 0.9214 - val_loss: 3.1677 - val_accuracy: 0.4600\n",
      "Epoch 1882/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3090 - accuracy: 0.9229 - val_loss: 3.1867 - val_accuracy: 0.4600\n",
      "Epoch 1883/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3099 - accuracy: 0.9214 - val_loss: 3.1772 - val_accuracy: 0.4633\n",
      "Epoch 1884/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3096 - accuracy: 0.9214 - val_loss: 3.1783 - val_accuracy: 0.4567\n",
      "Epoch 1885/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3089 - accuracy: 0.9200 - val_loss: 3.1804 - val_accuracy: 0.4600\n",
      "Epoch 1886/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3095 - accuracy: 0.9200 - val_loss: 3.1759 - val_accuracy: 0.4700\n",
      "Epoch 1887/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3084 - accuracy: 0.9214 - val_loss: 3.1656 - val_accuracy: 0.4667\n",
      "Epoch 1888/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3093 - accuracy: 0.9200 - val_loss: 3.1839 - val_accuracy: 0.4600\n",
      "Epoch 1889/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3089 - accuracy: 0.9229 - val_loss: 3.1805 - val_accuracy: 0.4633\n",
      "Epoch 1890/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3090 - accuracy: 0.9229 - val_loss: 3.1912 - val_accuracy: 0.4600\n",
      "Epoch 1891/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3086 - accuracy: 0.9186 - val_loss: 3.1917 - val_accuracy: 0.4600\n",
      "Epoch 1892/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3083 - accuracy: 0.9214 - val_loss: 3.1804 - val_accuracy: 0.4600\n",
      "Epoch 1893/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3085 - accuracy: 0.9214 - val_loss: 3.1878 - val_accuracy: 0.4600\n",
      "Epoch 1894/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3091 - accuracy: 0.9200 - val_loss: 3.1880 - val_accuracy: 0.4600\n",
      "Epoch 1895/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3090 - accuracy: 0.9214 - val_loss: 3.1934 - val_accuracy: 0.4533\n",
      "Epoch 1896/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3080 - accuracy: 0.9243 - val_loss: 3.1998 - val_accuracy: 0.4667\n",
      "Epoch 1897/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3085 - accuracy: 0.9214 - val_loss: 3.2075 - val_accuracy: 0.4700\n",
      "Epoch 1898/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3089 - accuracy: 0.9186 - val_loss: 3.2010 - val_accuracy: 0.4667\n",
      "Epoch 1899/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3082 - accuracy: 0.9214 - val_loss: 3.1860 - val_accuracy: 0.4633\n",
      "Epoch 1900/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3071 - accuracy: 0.9214 - val_loss: 3.1993 - val_accuracy: 0.4667\n",
      "Epoch 1901/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3088 - accuracy: 0.9200 - val_loss: 3.1891 - val_accuracy: 0.4567\n",
      "Epoch 1902/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3080 - accuracy: 0.9214 - val_loss: 3.2021 - val_accuracy: 0.4633\n",
      "Epoch 1903/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3078 - accuracy: 0.9214 - val_loss: 3.1816 - val_accuracy: 0.4567\n",
      "Epoch 1904/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3074 - accuracy: 0.9229 - val_loss: 3.1977 - val_accuracy: 0.4633\n",
      "Epoch 1905/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3087 - accuracy: 0.9214 - val_loss: 3.1966 - val_accuracy: 0.4700\n",
      "Epoch 1906/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3077 - accuracy: 0.9200 - val_loss: 3.2046 - val_accuracy: 0.4633\n",
      "Epoch 1907/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3080 - accuracy: 0.9229 - val_loss: 3.1847 - val_accuracy: 0.4700\n",
      "Epoch 1908/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3069 - accuracy: 0.9229 - val_loss: 3.1837 - val_accuracy: 0.4567\n",
      "Epoch 1909/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3081 - accuracy: 0.9229 - val_loss: 3.2066 - val_accuracy: 0.4667\n",
      "Epoch 1910/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3081 - accuracy: 0.9214 - val_loss: 3.1922 - val_accuracy: 0.4633\n",
      "Epoch 1911/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3072 - accuracy: 0.9214 - val_loss: 3.1881 - val_accuracy: 0.4567\n",
      "Epoch 1912/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3074 - accuracy: 0.9214 - val_loss: 3.2057 - val_accuracy: 0.4633\n",
      "Epoch 1913/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3063 - accuracy: 0.9229 - val_loss: 3.1961 - val_accuracy: 0.4600\n",
      "Epoch 1914/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3079 - accuracy: 0.9229 - val_loss: 3.2112 - val_accuracy: 0.4600\n",
      "Epoch 1915/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3071 - accuracy: 0.9200 - val_loss: 3.2016 - val_accuracy: 0.4667\n",
      "Epoch 1916/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3070 - accuracy: 0.9214 - val_loss: 3.2163 - val_accuracy: 0.4633\n",
      "Epoch 1917/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3063 - accuracy: 0.9229 - val_loss: 3.1966 - val_accuracy: 0.4567\n",
      "Epoch 1918/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3075 - accuracy: 0.9200 - val_loss: 3.2160 - val_accuracy: 0.4667\n",
      "Epoch 1919/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3074 - accuracy: 0.9214 - val_loss: 3.2113 - val_accuracy: 0.4667\n",
      "Epoch 1920/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3070 - accuracy: 0.9214 - val_loss: 3.2096 - val_accuracy: 0.4600\n",
      "Epoch 1921/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.3068 - accuracy: 0.9243 - val_loss: 3.2146 - val_accuracy: 0.4600\n",
      "Epoch 1922/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.3064 - accuracy: 0.9229 - val_loss: 3.2289 - val_accuracy: 0.4633\n",
      "Epoch 1923/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3062 - accuracy: 0.9214 - val_loss: 3.2245 - val_accuracy: 0.4533\n",
      "Epoch 1924/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3058 - accuracy: 0.9200 - val_loss: 3.2340 - val_accuracy: 0.4600\n",
      "Epoch 1925/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3069 - accuracy: 0.9229 - val_loss: 3.2137 - val_accuracy: 0.4633\n",
      "Epoch 1926/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 0.3078 - accuracy: 0.9229 - val_loss: 3.2053 - val_accuracy: 0.4667\n",
      "Epoch 1927/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3065 - accuracy: 0.9214 - val_loss: 3.2267 - val_accuracy: 0.4600\n",
      "Epoch 1928/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3068 - accuracy: 0.9214 - val_loss: 3.2245 - val_accuracy: 0.4667\n",
      "Epoch 1929/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3067 - accuracy: 0.9229 - val_loss: 3.2192 - val_accuracy: 0.4600\n",
      "Epoch 1930/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3059 - accuracy: 0.9243 - val_loss: 3.2341 - val_accuracy: 0.4667\n",
      "Epoch 1931/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3062 - accuracy: 0.9214 - val_loss: 3.2382 - val_accuracy: 0.4600\n",
      "Epoch 1932/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3056 - accuracy: 0.9229 - val_loss: 3.2285 - val_accuracy: 0.4600\n",
      "Epoch 1933/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.3060 - accuracy: 0.9214 - val_loss: 3.2241 - val_accuracy: 0.4600\n",
      "Epoch 1934/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3064 - accuracy: 0.9229 - val_loss: 3.2344 - val_accuracy: 0.4600\n",
      "Epoch 1935/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 0.3054 - accuracy: 0.9229 - val_loss: 3.2399 - val_accuracy: 0.4567\n",
      "Epoch 1936/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3061 - accuracy: 0.9229 - val_loss: 3.2280 - val_accuracy: 0.4633\n",
      "Epoch 1937/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3051 - accuracy: 0.9214 - val_loss: 3.2101 - val_accuracy: 0.4533\n",
      "Epoch 1938/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3062 - accuracy: 0.9214 - val_loss: 3.2353 - val_accuracy: 0.4633\n",
      "Epoch 1939/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3056 - accuracy: 0.9229 - val_loss: 3.2370 - val_accuracy: 0.4633\n",
      "Epoch 1940/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3056 - accuracy: 0.9214 - val_loss: 3.2285 - val_accuracy: 0.4600\n",
      "Epoch 1941/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3062 - accuracy: 0.9229 - val_loss: 3.2285 - val_accuracy: 0.4600\n",
      "Epoch 1942/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.3048 - accuracy: 0.9214 - val_loss: 3.2162 - val_accuracy: 0.4567\n",
      "Epoch 1943/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3048 - accuracy: 0.9257 - val_loss: 3.2372 - val_accuracy: 0.4667\n",
      "Epoch 1944/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3060 - accuracy: 0.9243 - val_loss: 3.2386 - val_accuracy: 0.4633\n",
      "Epoch 1945/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.3053 - accuracy: 0.9229 - val_loss: 3.2245 - val_accuracy: 0.4567\n",
      "Epoch 1946/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3057 - accuracy: 0.9214 - val_loss: 3.2345 - val_accuracy: 0.4633\n",
      "Epoch 1947/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3052 - accuracy: 0.9243 - val_loss: 3.2298 - val_accuracy: 0.4600\n",
      "Epoch 1948/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3055 - accuracy: 0.9243 - val_loss: 3.2373 - val_accuracy: 0.4633\n",
      "Epoch 1949/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3053 - accuracy: 0.9229 - val_loss: 3.2287 - val_accuracy: 0.4533\n",
      "Epoch 1950/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3056 - accuracy: 0.9214 - val_loss: 3.2427 - val_accuracy: 0.4633\n",
      "Epoch 1951/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.3050 - accuracy: 0.9243 - val_loss: 3.2340 - val_accuracy: 0.4600\n",
      "Epoch 1952/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3046 - accuracy: 0.9229 - val_loss: 3.2369 - val_accuracy: 0.4600\n",
      "Epoch 1953/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3055 - accuracy: 0.9214 - val_loss: 3.2576 - val_accuracy: 0.4600\n",
      "Epoch 1954/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3045 - accuracy: 0.9229 - val_loss: 3.2515 - val_accuracy: 0.4633\n",
      "Epoch 1955/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3048 - accuracy: 0.9229 - val_loss: 3.2596 - val_accuracy: 0.4600\n",
      "Epoch 1956/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3047 - accuracy: 0.9214 - val_loss: 3.2556 - val_accuracy: 0.4667\n",
      "Epoch 1957/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3041 - accuracy: 0.9257 - val_loss: 3.2496 - val_accuracy: 0.4633\n",
      "Epoch 1958/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3047 - accuracy: 0.9243 - val_loss: 3.2541 - val_accuracy: 0.4600\n",
      "Epoch 1959/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.3040 - accuracy: 0.9229 - val_loss: 3.2422 - val_accuracy: 0.4600\n",
      "Epoch 1960/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3049 - accuracy: 0.9214 - val_loss: 3.2656 - val_accuracy: 0.4633\n",
      "Epoch 1961/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3039 - accuracy: 0.9229 - val_loss: 3.2579 - val_accuracy: 0.4600\n",
      "Epoch 1962/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3053 - accuracy: 0.9229 - val_loss: 3.2455 - val_accuracy: 0.4633\n",
      "Epoch 1963/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3042 - accuracy: 0.9214 - val_loss: 3.2539 - val_accuracy: 0.4533\n",
      "Epoch 1964/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.3039 - accuracy: 0.9214 - val_loss: 3.2361 - val_accuracy: 0.4533\n",
      "Epoch 1965/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3046 - accuracy: 0.9214 - val_loss: 3.2485 - val_accuracy: 0.4633\n",
      "Epoch 1966/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3038 - accuracy: 0.9229 - val_loss: 3.2512 - val_accuracy: 0.4567\n",
      "Epoch 1967/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3035 - accuracy: 0.9243 - val_loss: 3.2682 - val_accuracy: 0.4600\n",
      "Epoch 1968/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3033 - accuracy: 0.9229 - val_loss: 3.2626 - val_accuracy: 0.4633\n",
      "Epoch 1969/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3046 - accuracy: 0.9214 - val_loss: 3.2542 - val_accuracy: 0.4567\n",
      "Epoch 1970/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3036 - accuracy: 0.9243 - val_loss: 3.2495 - val_accuracy: 0.4633\n",
      "Epoch 1971/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.3030 - accuracy: 0.9243 - val_loss: 3.2590 - val_accuracy: 0.4633\n",
      "Epoch 1972/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3035 - accuracy: 0.9229 - val_loss: 3.2555 - val_accuracy: 0.4567\n",
      "Epoch 1973/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3040 - accuracy: 0.9243 - val_loss: 3.2707 - val_accuracy: 0.4633\n",
      "Epoch 1974/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.3030 - accuracy: 0.9229 - val_loss: 3.2678 - val_accuracy: 0.4667\n",
      "Epoch 1975/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3025 - accuracy: 0.9257 - val_loss: 3.2527 - val_accuracy: 0.4533\n",
      "Epoch 1976/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3036 - accuracy: 0.9229 - val_loss: 3.2695 - val_accuracy: 0.4667\n",
      "Epoch 1977/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3038 - accuracy: 0.9243 - val_loss: 3.2717 - val_accuracy: 0.4633\n",
      "Epoch 1978/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3031 - accuracy: 0.9243 - val_loss: 3.2794 - val_accuracy: 0.4600\n",
      "Epoch 1979/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3035 - accuracy: 0.9214 - val_loss: 3.2720 - val_accuracy: 0.4667\n",
      "Epoch 1980/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3027 - accuracy: 0.9243 - val_loss: 3.2736 - val_accuracy: 0.4600\n",
      "Epoch 1981/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3030 - accuracy: 0.9214 - val_loss: 3.2811 - val_accuracy: 0.4533\n",
      "Epoch 1982/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3030 - accuracy: 0.9243 - val_loss: 3.2782 - val_accuracy: 0.4667\n",
      "Epoch 1983/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3030 - accuracy: 0.9257 - val_loss: 3.2786 - val_accuracy: 0.4633\n",
      "Epoch 1984/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.3030 - accuracy: 0.9200 - val_loss: 3.2800 - val_accuracy: 0.4667\n",
      "Epoch 1985/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3025 - accuracy: 0.9229 - val_loss: 3.2623 - val_accuracy: 0.4633\n",
      "Epoch 1986/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3025 - accuracy: 0.9214 - val_loss: 3.2954 - val_accuracy: 0.4633\n",
      "Epoch 1987/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3019 - accuracy: 0.9243 - val_loss: 3.2968 - val_accuracy: 0.4567\n",
      "Epoch 1988/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3031 - accuracy: 0.9229 - val_loss: 3.2970 - val_accuracy: 0.4600\n",
      "Epoch 1989/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.3025 - accuracy: 0.9243 - val_loss: 3.2838 - val_accuracy: 0.4600\n",
      "Epoch 1990/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 0.3030 - accuracy: 0.9229 - val_loss: 3.2916 - val_accuracy: 0.4700\n",
      "Epoch 1991/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3025 - accuracy: 0.9243 - val_loss: 3.2795 - val_accuracy: 0.4667\n",
      "Epoch 1992/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3018 - accuracy: 0.9229 - val_loss: 3.2864 - val_accuracy: 0.4567\n",
      "Epoch 1993/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3023 - accuracy: 0.9257 - val_loss: 3.2892 - val_accuracy: 0.4633\n",
      "Epoch 1994/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3019 - accuracy: 0.9257 - val_loss: 3.2931 - val_accuracy: 0.4600\n",
      "Epoch 1995/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3018 - accuracy: 0.9229 - val_loss: 3.2912 - val_accuracy: 0.4467\n",
      "Epoch 1996/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3024 - accuracy: 0.9243 - val_loss: 3.2933 - val_accuracy: 0.4633\n",
      "Epoch 1997/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3022 - accuracy: 0.9229 - val_loss: 3.2822 - val_accuracy: 0.4567\n",
      "Epoch 1998/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3015 - accuracy: 0.9257 - val_loss: 3.2876 - val_accuracy: 0.4600\n",
      "Epoch 1999/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3019 - accuracy: 0.9229 - val_loss: 3.2891 - val_accuracy: 0.4633\n",
      "Epoch 2000/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3018 - accuracy: 0.9229 - val_loss: 3.2988 - val_accuracy: 0.4633\n",
      "Epoch 2001/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3018 - accuracy: 0.9214 - val_loss: 3.2882 - val_accuracy: 0.4600\n",
      "Epoch 2002/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3017 - accuracy: 0.9229 - val_loss: 3.2956 - val_accuracy: 0.4567\n",
      "Epoch 2003/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.3016 - accuracy: 0.9243 - val_loss: 3.2999 - val_accuracy: 0.4533\n",
      "Epoch 2004/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3022 - accuracy: 0.9243 - val_loss: 3.2952 - val_accuracy: 0.4667\n",
      "Epoch 2005/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3015 - accuracy: 0.9229 - val_loss: 3.3047 - val_accuracy: 0.4633\n",
      "Epoch 2006/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3020 - accuracy: 0.9229 - val_loss: 3.2935 - val_accuracy: 0.4600\n",
      "Epoch 2007/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3013 - accuracy: 0.9257 - val_loss: 3.3096 - val_accuracy: 0.4633\n",
      "Epoch 2008/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3012 - accuracy: 0.9243 - val_loss: 3.2899 - val_accuracy: 0.4600\n",
      "Epoch 2009/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3013 - accuracy: 0.9214 - val_loss: 3.3096 - val_accuracy: 0.4633\n",
      "Epoch 2010/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.3009 - accuracy: 0.9243 - val_loss: 3.3007 - val_accuracy: 0.4567\n",
      "Epoch 2011/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3014 - accuracy: 0.9229 - val_loss: 3.3073 - val_accuracy: 0.4600\n",
      "Epoch 2012/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3010 - accuracy: 0.9257 - val_loss: 3.3002 - val_accuracy: 0.4667\n",
      "Epoch 2013/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3012 - accuracy: 0.9243 - val_loss: 3.3026 - val_accuracy: 0.4633\n",
      "Epoch 2014/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3011 - accuracy: 0.9229 - val_loss: 3.3017 - val_accuracy: 0.4667\n",
      "Epoch 2015/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3009 - accuracy: 0.9257 - val_loss: 3.3077 - val_accuracy: 0.4600\n",
      "Epoch 2016/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.3011 - accuracy: 0.9229 - val_loss: 3.3058 - val_accuracy: 0.4600\n",
      "Epoch 2017/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.3005 - accuracy: 0.9229 - val_loss: 3.3100 - val_accuracy: 0.4667\n",
      "Epoch 2018/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.3011 - accuracy: 0.9257 - val_loss: 3.3145 - val_accuracy: 0.4600\n",
      "Epoch 2019/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.3003 - accuracy: 0.9229 - val_loss: 3.3222 - val_accuracy: 0.4567\n",
      "Epoch 2020/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3001 - accuracy: 0.9243 - val_loss: 3.3284 - val_accuracy: 0.4600\n",
      "Epoch 2021/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3005 - accuracy: 0.9214 - val_loss: 3.3105 - val_accuracy: 0.4633\n",
      "Epoch 2022/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2997 - accuracy: 0.9271 - val_loss: 3.3075 - val_accuracy: 0.4600\n",
      "Epoch 2023/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.3005 - accuracy: 0.9214 - val_loss: 3.3061 - val_accuracy: 0.4633\n",
      "Epoch 2024/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.3005 - accuracy: 0.9257 - val_loss: 3.3238 - val_accuracy: 0.4633\n",
      "Epoch 2025/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3006 - accuracy: 0.9243 - val_loss: 3.3244 - val_accuracy: 0.4600\n",
      "Epoch 2026/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.3008 - accuracy: 0.9229 - val_loss: 3.3114 - val_accuracy: 0.4600\n",
      "Epoch 2027/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.3003 - accuracy: 0.9229 - val_loss: 3.3175 - val_accuracy: 0.4633\n",
      "Epoch 2028/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2999 - accuracy: 0.9257 - val_loss: 3.3198 - val_accuracy: 0.4600\n",
      "Epoch 2029/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.3002 - accuracy: 0.9257 - val_loss: 3.3079 - val_accuracy: 0.4600\n",
      "Epoch 2030/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3000 - accuracy: 0.9257 - val_loss: 3.3177 - val_accuracy: 0.4600\n",
      "Epoch 2031/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.3001 - accuracy: 0.9229 - val_loss: 3.3026 - val_accuracy: 0.4467\n",
      "Epoch 2032/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.3000 - accuracy: 0.9229 - val_loss: 3.3305 - val_accuracy: 0.4567\n",
      "Epoch 2033/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.3002 - accuracy: 0.9229 - val_loss: 3.3189 - val_accuracy: 0.4633\n",
      "Epoch 2034/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2999 - accuracy: 0.9257 - val_loss: 3.3433 - val_accuracy: 0.4567\n",
      "Epoch 2035/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.3002 - accuracy: 0.9243 - val_loss: 3.3220 - val_accuracy: 0.4600\n",
      "Epoch 2036/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2998 - accuracy: 0.9243 - val_loss: 3.3247 - val_accuracy: 0.4600\n",
      "Epoch 2037/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2994 - accuracy: 0.9243 - val_loss: 3.3206 - val_accuracy: 0.4600\n",
      "Epoch 2038/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2992 - accuracy: 0.9243 - val_loss: 3.3225 - val_accuracy: 0.4567\n",
      "Epoch 2039/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2993 - accuracy: 0.9243 - val_loss: 3.3256 - val_accuracy: 0.4633\n",
      "Epoch 2040/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2996 - accuracy: 0.9229 - val_loss: 3.3454 - val_accuracy: 0.4567\n",
      "Epoch 2041/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2996 - accuracy: 0.9243 - val_loss: 3.3391 - val_accuracy: 0.4533\n",
      "Epoch 2042/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2994 - accuracy: 0.9229 - val_loss: 3.3140 - val_accuracy: 0.4500\n",
      "Epoch 2043/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2994 - accuracy: 0.9257 - val_loss: 3.3389 - val_accuracy: 0.4500\n",
      "Epoch 2044/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2993 - accuracy: 0.9243 - val_loss: 3.3287 - val_accuracy: 0.4600\n",
      "Epoch 2045/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/step - loss: 0.2988 - accuracy: 0.9257 - val_loss: 3.3254 - val_accuracy: 0.4400\n",
      "Epoch 2046/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2997 - accuracy: 0.9257 - val_loss: 3.3260 - val_accuracy: 0.4633\n",
      "Epoch 2047/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2987 - accuracy: 0.9257 - val_loss: 3.3603 - val_accuracy: 0.4533\n",
      "Epoch 2048/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2991 - accuracy: 0.9257 - val_loss: 3.3547 - val_accuracy: 0.4600\n",
      "Epoch 2049/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2994 - accuracy: 0.9229 - val_loss: 3.3223 - val_accuracy: 0.4567\n",
      "Epoch 2050/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2987 - accuracy: 0.9257 - val_loss: 3.3567 - val_accuracy: 0.4600\n",
      "Epoch 2051/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2994 - accuracy: 0.9257 - val_loss: 3.3363 - val_accuracy: 0.4567\n",
      "Epoch 2052/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2986 - accuracy: 0.9257 - val_loss: 3.3400 - val_accuracy: 0.4600\n",
      "Epoch 2053/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2989 - accuracy: 0.9243 - val_loss: 3.3357 - val_accuracy: 0.4600\n",
      "Epoch 2054/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2986 - accuracy: 0.9257 - val_loss: 3.3397 - val_accuracy: 0.4533\n",
      "Epoch 2055/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2992 - accuracy: 0.9257 - val_loss: 3.3344 - val_accuracy: 0.4567\n",
      "Epoch 2056/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2986 - accuracy: 0.9229 - val_loss: 3.3628 - val_accuracy: 0.4600\n",
      "Epoch 2057/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2985 - accuracy: 0.9229 - val_loss: 3.3565 - val_accuracy: 0.4567\n",
      "Epoch 2058/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2983 - accuracy: 0.9243 - val_loss: 3.3395 - val_accuracy: 0.4567\n",
      "Epoch 2059/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2979 - accuracy: 0.9243 - val_loss: 3.3317 - val_accuracy: 0.4500\n",
      "Epoch 2060/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2990 - accuracy: 0.9243 - val_loss: 3.3578 - val_accuracy: 0.4633\n",
      "Epoch 2061/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2981 - accuracy: 0.9257 - val_loss: 3.3464 - val_accuracy: 0.4600\n",
      "Epoch 2062/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2987 - accuracy: 0.9214 - val_loss: 3.3577 - val_accuracy: 0.4600\n",
      "Epoch 2063/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2984 - accuracy: 0.9243 - val_loss: 3.3579 - val_accuracy: 0.4567\n",
      "Epoch 2064/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2981 - accuracy: 0.9243 - val_loss: 3.3426 - val_accuracy: 0.4433\n",
      "Epoch 2065/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2980 - accuracy: 0.9271 - val_loss: 3.3418 - val_accuracy: 0.4567\n",
      "Epoch 2066/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2978 - accuracy: 0.9271 - val_loss: 3.3450 - val_accuracy: 0.4433\n",
      "Epoch 2067/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2980 - accuracy: 0.9257 - val_loss: 3.3685 - val_accuracy: 0.4500\n",
      "Epoch 2068/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2975 - accuracy: 0.9243 - val_loss: 3.3498 - val_accuracy: 0.4533\n",
      "Epoch 2069/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2981 - accuracy: 0.9271 - val_loss: 3.3511 - val_accuracy: 0.4500\n",
      "Epoch 2070/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2987 - accuracy: 0.9243 - val_loss: 3.3527 - val_accuracy: 0.4533\n",
      "Epoch 2071/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2981 - accuracy: 0.9257 - val_loss: 3.3726 - val_accuracy: 0.4567\n",
      "Epoch 2072/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2968 - accuracy: 0.9257 - val_loss: 3.3662 - val_accuracy: 0.4567\n",
      "Epoch 2073/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2981 - accuracy: 0.9243 - val_loss: 3.3636 - val_accuracy: 0.4633\n",
      "Epoch 2074/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2983 - accuracy: 0.9243 - val_loss: 3.3629 - val_accuracy: 0.4600\n",
      "Epoch 2075/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2975 - accuracy: 0.9229 - val_loss: 3.3629 - val_accuracy: 0.4633\n",
      "Epoch 2076/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2975 - accuracy: 0.9243 - val_loss: 3.3691 - val_accuracy: 0.4533\n",
      "Epoch 2077/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2980 - accuracy: 0.9257 - val_loss: 3.3696 - val_accuracy: 0.4567\n",
      "Epoch 2078/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2973 - accuracy: 0.9243 - val_loss: 3.3862 - val_accuracy: 0.4567\n",
      "Epoch 2079/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2970 - accuracy: 0.9257 - val_loss: 3.3723 - val_accuracy: 0.4500\n",
      "Epoch 2080/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2974 - accuracy: 0.9257 - val_loss: 3.3662 - val_accuracy: 0.4500\n",
      "Epoch 2081/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2969 - accuracy: 0.9229 - val_loss: 3.3638 - val_accuracy: 0.4533\n",
      "Epoch 2082/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2972 - accuracy: 0.9286 - val_loss: 3.3556 - val_accuracy: 0.4400\n",
      "Epoch 2083/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2971 - accuracy: 0.9271 - val_loss: 3.3608 - val_accuracy: 0.4533\n",
      "Epoch 2084/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2968 - accuracy: 0.9271 - val_loss: 3.3723 - val_accuracy: 0.4567\n",
      "Epoch 2085/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2968 - accuracy: 0.9243 - val_loss: 3.3736 - val_accuracy: 0.4567\n",
      "Epoch 2086/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2971 - accuracy: 0.9271 - val_loss: 3.3813 - val_accuracy: 0.4600\n",
      "Epoch 2087/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2970 - accuracy: 0.9243 - val_loss: 3.3800 - val_accuracy: 0.4600\n",
      "Epoch 2088/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2968 - accuracy: 0.9271 - val_loss: 3.3713 - val_accuracy: 0.4567\n",
      "Epoch 2089/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2966 - accuracy: 0.9257 - val_loss: 3.3813 - val_accuracy: 0.4533\n",
      "Epoch 2090/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2970 - accuracy: 0.9257 - val_loss: 3.3899 - val_accuracy: 0.4533\n",
      "Epoch 2091/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2963 - accuracy: 0.9257 - val_loss: 3.3897 - val_accuracy: 0.4600\n",
      "Epoch 2092/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2964 - accuracy: 0.9257 - val_loss: 3.3727 - val_accuracy: 0.4533\n",
      "Epoch 2093/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2962 - accuracy: 0.9257 - val_loss: 3.4038 - val_accuracy: 0.4467\n",
      "Epoch 2094/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2970 - accuracy: 0.9243 - val_loss: 3.3732 - val_accuracy: 0.4533\n",
      "Epoch 2095/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2966 - accuracy: 0.9257 - val_loss: 3.3765 - val_accuracy: 0.4433\n",
      "Epoch 2096/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2964 - accuracy: 0.9243 - val_loss: 3.3876 - val_accuracy: 0.4567\n",
      "Epoch 2097/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2962 - accuracy: 0.9257 - val_loss: 3.3767 - val_accuracy: 0.4567\n",
      "Epoch 2098/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2966 - accuracy: 0.9257 - val_loss: 3.3825 - val_accuracy: 0.4467\n",
      "Epoch 2099/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2966 - accuracy: 0.9257 - val_loss: 3.3747 - val_accuracy: 0.4533\n",
      "Epoch 2100/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 0.2963 - accuracy: 0.9271 - val_loss: 3.3908 - val_accuracy: 0.4567\n",
      "Epoch 2101/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2961 - accuracy: 0.9271 - val_loss: 3.4003 - val_accuracy: 0.4467\n",
      "Epoch 2102/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2956 - accuracy: 0.9286 - val_loss: 3.3867 - val_accuracy: 0.4500\n",
      "Epoch 2103/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2959 - accuracy: 0.9286 - val_loss: 3.3874 - val_accuracy: 0.4600\n",
      "Epoch 2104/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2959 - accuracy: 0.9257 - val_loss: 3.3876 - val_accuracy: 0.4467\n",
      "Epoch 2105/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2963 - accuracy: 0.9286 - val_loss: 3.4085 - val_accuracy: 0.4567\n",
      "Epoch 2106/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.2959 - accuracy: 0.9257 - val_loss: 3.3926 - val_accuracy: 0.4500\n",
      "Epoch 2107/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2960 - accuracy: 0.9257 - val_loss: 3.3899 - val_accuracy: 0.4533\n",
      "Epoch 2108/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2956 - accuracy: 0.9257 - val_loss: 3.3806 - val_accuracy: 0.4567\n",
      "Epoch 2109/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2956 - accuracy: 0.9271 - val_loss: 3.3991 - val_accuracy: 0.4500\n",
      "Epoch 2110/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2955 - accuracy: 0.9257 - val_loss: 3.4010 - val_accuracy: 0.4533\n",
      "Epoch 2111/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2956 - accuracy: 0.9271 - val_loss: 3.3902 - val_accuracy: 0.4567\n",
      "Epoch 2112/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2958 - accuracy: 0.9257 - val_loss: 3.4082 - val_accuracy: 0.4533\n",
      "Epoch 2113/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2953 - accuracy: 0.9271 - val_loss: 3.3907 - val_accuracy: 0.4600\n",
      "Epoch 2114/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2951 - accuracy: 0.9257 - val_loss: 3.4066 - val_accuracy: 0.4533\n",
      "Epoch 2115/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2951 - accuracy: 0.9271 - val_loss: 3.3978 - val_accuracy: 0.4533\n",
      "Epoch 2116/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2956 - accuracy: 0.9286 - val_loss: 3.3847 - val_accuracy: 0.4567\n",
      "Epoch 2117/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2946 - accuracy: 0.9271 - val_loss: 3.3952 - val_accuracy: 0.4533\n",
      "Epoch 2118/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2953 - accuracy: 0.9271 - val_loss: 3.4078 - val_accuracy: 0.4467\n",
      "Epoch 2119/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2954 - accuracy: 0.9286 - val_loss: 3.4063 - val_accuracy: 0.4533\n",
      "Epoch 2120/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2953 - accuracy: 0.9271 - val_loss: 3.4048 - val_accuracy: 0.4567\n",
      "Epoch 2121/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2948 - accuracy: 0.9286 - val_loss: 3.4044 - val_accuracy: 0.4433\n",
      "Epoch 2122/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2949 - accuracy: 0.9271 - val_loss: 3.4139 - val_accuracy: 0.4500\n",
      "Epoch 2123/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2953 - accuracy: 0.9271 - val_loss: 3.4080 - val_accuracy: 0.4500\n",
      "Epoch 2124/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2949 - accuracy: 0.9271 - val_loss: 3.4140 - val_accuracy: 0.4600\n",
      "Epoch 2125/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2946 - accuracy: 0.9243 - val_loss: 3.3900 - val_accuracy: 0.4533\n",
      "Epoch 2126/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2947 - accuracy: 0.9257 - val_loss: 3.4117 - val_accuracy: 0.4533\n",
      "Epoch 2127/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2944 - accuracy: 0.9257 - val_loss: 3.4258 - val_accuracy: 0.4533\n",
      "Epoch 2128/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2946 - accuracy: 0.9257 - val_loss: 3.4114 - val_accuracy: 0.4500\n",
      "Epoch 2129/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2939 - accuracy: 0.9257 - val_loss: 3.3847 - val_accuracy: 0.4500\n",
      "Epoch 2130/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2957 - accuracy: 0.9243 - val_loss: 3.4091 - val_accuracy: 0.4567\n",
      "Epoch 2131/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2948 - accuracy: 0.9257 - val_loss: 3.4178 - val_accuracy: 0.4533\n",
      "Epoch 2132/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2943 - accuracy: 0.9257 - val_loss: 3.4061 - val_accuracy: 0.4567\n",
      "Epoch 2133/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2943 - accuracy: 0.9271 - val_loss: 3.4018 - val_accuracy: 0.4567\n",
      "Epoch 2134/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2944 - accuracy: 0.9271 - val_loss: 3.4269 - val_accuracy: 0.4567\n",
      "Epoch 2135/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2944 - accuracy: 0.9257 - val_loss: 3.4068 - val_accuracy: 0.4533\n",
      "Epoch 2136/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2943 - accuracy: 0.9257 - val_loss: 3.4198 - val_accuracy: 0.4500\n",
      "Epoch 2137/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2944 - accuracy: 0.9243 - val_loss: 3.4090 - val_accuracy: 0.4500\n",
      "Epoch 2138/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2940 - accuracy: 0.9243 - val_loss: 3.4163 - val_accuracy: 0.4500\n",
      "Epoch 2139/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2942 - accuracy: 0.9257 - val_loss: 3.4017 - val_accuracy: 0.4433\n",
      "Epoch 2140/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2944 - accuracy: 0.9257 - val_loss: 3.4247 - val_accuracy: 0.4500\n",
      "Epoch 2141/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2942 - accuracy: 0.9271 - val_loss: 3.4266 - val_accuracy: 0.4533\n",
      "Epoch 2142/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2936 - accuracy: 0.9286 - val_loss: 3.4177 - val_accuracy: 0.4500\n",
      "Epoch 2143/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2939 - accuracy: 0.9257 - val_loss: 3.4295 - val_accuracy: 0.4533\n",
      "Epoch 2144/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2934 - accuracy: 0.9257 - val_loss: 3.4268 - val_accuracy: 0.4567\n",
      "Epoch 2145/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2934 - accuracy: 0.9271 - val_loss: 3.4355 - val_accuracy: 0.4533\n",
      "Epoch 2146/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2934 - accuracy: 0.9271 - val_loss: 3.4292 - val_accuracy: 0.4567\n",
      "Epoch 2147/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2939 - accuracy: 0.9286 - val_loss: 3.4115 - val_accuracy: 0.4433\n",
      "Epoch 2148/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2933 - accuracy: 0.9286 - val_loss: 3.4096 - val_accuracy: 0.4467\n",
      "Epoch 2149/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2937 - accuracy: 0.9271 - val_loss: 3.4502 - val_accuracy: 0.4533\n",
      "Epoch 2150/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2933 - accuracy: 0.9271 - val_loss: 3.4142 - val_accuracy: 0.4500\n",
      "Epoch 2151/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2932 - accuracy: 0.9271 - val_loss: 3.4147 - val_accuracy: 0.4533\n",
      "Epoch 2152/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2937 - accuracy: 0.9257 - val_loss: 3.4350 - val_accuracy: 0.4567\n",
      "Epoch 2153/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2931 - accuracy: 0.9286 - val_loss: 3.4303 - val_accuracy: 0.4500\n",
      "Epoch 2154/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2927 - accuracy: 0.9271 - val_loss: 3.4269 - val_accuracy: 0.4467\n",
      "Epoch 2155/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 0.2935 - accuracy: 0.9271 - val_loss: 3.4313 - val_accuracy: 0.4567\n",
      "Epoch 2156/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2923 - accuracy: 0.9286 - val_loss: 3.4585 - val_accuracy: 0.4533\n",
      "Epoch 2157/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2934 - accuracy: 0.9271 - val_loss: 3.4422 - val_accuracy: 0.4500\n",
      "Epoch 2158/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2927 - accuracy: 0.9257 - val_loss: 3.4266 - val_accuracy: 0.4500\n",
      "Epoch 2159/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2924 - accuracy: 0.9286 - val_loss: 3.4567 - val_accuracy: 0.4533\n",
      "Epoch 2160/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2928 - accuracy: 0.9271 - val_loss: 3.4427 - val_accuracy: 0.4533\n",
      "Epoch 2161/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2929 - accuracy: 0.9271 - val_loss: 3.4488 - val_accuracy: 0.4533\n",
      "Epoch 2162/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2934 - accuracy: 0.9257 - val_loss: 3.4234 - val_accuracy: 0.4500\n",
      "Epoch 2163/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2929 - accuracy: 0.9271 - val_loss: 3.4298 - val_accuracy: 0.4500\n",
      "Epoch 2164/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2930 - accuracy: 0.9286 - val_loss: 3.4350 - val_accuracy: 0.4500\n",
      "Epoch 2165/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2924 - accuracy: 0.9257 - val_loss: 3.4301 - val_accuracy: 0.4467\n",
      "Epoch 2166/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2922 - accuracy: 0.9271 - val_loss: 3.4316 - val_accuracy: 0.4533\n",
      "Epoch 2167/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2928 - accuracy: 0.9286 - val_loss: 3.4142 - val_accuracy: 0.4433\n",
      "Epoch 2168/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2927 - accuracy: 0.9286 - val_loss: 3.4484 - val_accuracy: 0.4533\n",
      "Epoch 2169/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2921 - accuracy: 0.9271 - val_loss: 3.4500 - val_accuracy: 0.4600\n",
      "Epoch 2170/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2925 - accuracy: 0.9271 - val_loss: 3.4523 - val_accuracy: 0.4533\n",
      "Epoch 2171/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2928 - accuracy: 0.9271 - val_loss: 3.4528 - val_accuracy: 0.4533\n",
      "Epoch 2172/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2921 - accuracy: 0.9286 - val_loss: 3.4503 - val_accuracy: 0.4500\n",
      "Epoch 2173/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2921 - accuracy: 0.9257 - val_loss: 3.4546 - val_accuracy: 0.4433\n",
      "Epoch 2174/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2924 - accuracy: 0.9271 - val_loss: 3.4544 - val_accuracy: 0.4500\n",
      "Epoch 2175/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2924 - accuracy: 0.9271 - val_loss: 3.4541 - val_accuracy: 0.4567\n",
      "Epoch 2176/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2917 - accuracy: 0.9271 - val_loss: 3.4456 - val_accuracy: 0.4500\n",
      "Epoch 2177/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2925 - accuracy: 0.9286 - val_loss: 3.4509 - val_accuracy: 0.4533\n",
      "Epoch 2178/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2923 - accuracy: 0.9271 - val_loss: 3.4511 - val_accuracy: 0.4533\n",
      "Epoch 2179/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2923 - accuracy: 0.9286 - val_loss: 3.4505 - val_accuracy: 0.4467\n",
      "Epoch 2180/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2925 - accuracy: 0.9271 - val_loss: 3.4547 - val_accuracy: 0.4500\n",
      "Epoch 2181/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2917 - accuracy: 0.9271 - val_loss: 3.4615 - val_accuracy: 0.4467\n",
      "Epoch 2182/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2914 - accuracy: 0.9271 - val_loss: 3.4499 - val_accuracy: 0.4500\n",
      "Epoch 2183/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2919 - accuracy: 0.9257 - val_loss: 3.4599 - val_accuracy: 0.4500\n",
      "Epoch 2184/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2919 - accuracy: 0.9286 - val_loss: 3.4703 - val_accuracy: 0.4533\n",
      "Epoch 2185/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2911 - accuracy: 0.9271 - val_loss: 3.4547 - val_accuracy: 0.4467\n",
      "Epoch 2186/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2919 - accuracy: 0.9257 - val_loss: 3.4553 - val_accuracy: 0.4500\n",
      "Epoch 2187/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2921 - accuracy: 0.9271 - val_loss: 3.4666 - val_accuracy: 0.4500\n",
      "Epoch 2188/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2917 - accuracy: 0.9286 - val_loss: 3.4715 - val_accuracy: 0.4567\n",
      "Epoch 2189/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2911 - accuracy: 0.9286 - val_loss: 3.4657 - val_accuracy: 0.4500\n",
      "Epoch 2190/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 0.2915 - accuracy: 0.9286 - val_loss: 3.4569 - val_accuracy: 0.4500\n",
      "Epoch 2191/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2917 - accuracy: 0.9271 - val_loss: 3.4814 - val_accuracy: 0.4533\n",
      "Epoch 2192/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2919 - accuracy: 0.9271 - val_loss: 3.4722 - val_accuracy: 0.4533\n",
      "Epoch 2193/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2916 - accuracy: 0.9271 - val_loss: 3.4872 - val_accuracy: 0.4500\n",
      "Epoch 2194/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2912 - accuracy: 0.9257 - val_loss: 3.4717 - val_accuracy: 0.4467\n",
      "Epoch 2195/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2917 - accuracy: 0.9286 - val_loss: 3.4714 - val_accuracy: 0.4467\n",
      "Epoch 2196/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2915 - accuracy: 0.9286 - val_loss: 3.4806 - val_accuracy: 0.4533\n",
      "Epoch 2197/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2913 - accuracy: 0.9286 - val_loss: 3.4722 - val_accuracy: 0.4467\n",
      "Epoch 2198/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2913 - accuracy: 0.9271 - val_loss: 3.4757 - val_accuracy: 0.4533\n",
      "Epoch 2199/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2907 - accuracy: 0.9257 - val_loss: 3.4792 - val_accuracy: 0.4467\n",
      "Epoch 2200/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2910 - accuracy: 0.9257 - val_loss: 3.4679 - val_accuracy: 0.4467\n",
      "Epoch 2201/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2908 - accuracy: 0.9271 - val_loss: 3.4736 - val_accuracy: 0.4467\n",
      "Epoch 2202/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2904 - accuracy: 0.9286 - val_loss: 3.4814 - val_accuracy: 0.4400\n",
      "Epoch 2203/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2907 - accuracy: 0.9286 - val_loss: 3.4814 - val_accuracy: 0.4467\n",
      "Epoch 2204/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2910 - accuracy: 0.9271 - val_loss: 3.4900 - val_accuracy: 0.4533\n",
      "Epoch 2205/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2914 - accuracy: 0.9286 - val_loss: 3.4794 - val_accuracy: 0.4500\n",
      "Epoch 2206/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2906 - accuracy: 0.9271 - val_loss: 3.4922 - val_accuracy: 0.4467\n",
      "Epoch 2207/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2910 - accuracy: 0.9271 - val_loss: 3.4932 - val_accuracy: 0.4533\n",
      "Epoch 2208/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2906 - accuracy: 0.9271 - val_loss: 3.4632 - val_accuracy: 0.4433\n",
      "Epoch 2209/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2908 - accuracy: 0.9271 - val_loss: 3.4712 - val_accuracy: 0.4400\n",
      "Epoch 2210/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 0.2902 - accuracy: 0.9286 - val_loss: 3.4799 - val_accuracy: 0.4467\n",
      "Epoch 2211/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2905 - accuracy: 0.9286 - val_loss: 3.4684 - val_accuracy: 0.4433\n",
      "Epoch 2212/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2906 - accuracy: 0.9257 - val_loss: 3.4795 - val_accuracy: 0.4500\n",
      "Epoch 2213/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2906 - accuracy: 0.9271 - val_loss: 3.4691 - val_accuracy: 0.4433\n",
      "Epoch 2214/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2904 - accuracy: 0.9286 - val_loss: 3.4872 - val_accuracy: 0.4567\n",
      "Epoch 2215/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2902 - accuracy: 0.9286 - val_loss: 3.4786 - val_accuracy: 0.4433\n",
      "Epoch 2216/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2907 - accuracy: 0.9271 - val_loss: 3.4900 - val_accuracy: 0.4500\n",
      "Epoch 2217/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2903 - accuracy: 0.9286 - val_loss: 3.4963 - val_accuracy: 0.4533\n",
      "Epoch 2218/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2893 - accuracy: 0.9286 - val_loss: 3.4732 - val_accuracy: 0.4433\n",
      "Epoch 2219/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2897 - accuracy: 0.9286 - val_loss: 3.4979 - val_accuracy: 0.4533\n",
      "Epoch 2220/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2898 - accuracy: 0.9271 - val_loss: 3.5001 - val_accuracy: 0.4467\n",
      "Epoch 2221/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2899 - accuracy: 0.9286 - val_loss: 3.5071 - val_accuracy: 0.4433\n",
      "Epoch 2222/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2898 - accuracy: 0.9286 - val_loss: 3.4709 - val_accuracy: 0.4400\n",
      "Epoch 2223/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2899 - accuracy: 0.9286 - val_loss: 3.4967 - val_accuracy: 0.4500\n",
      "Epoch 2224/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2899 - accuracy: 0.9286 - val_loss: 3.4998 - val_accuracy: 0.4500\n",
      "Epoch 2225/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2897 - accuracy: 0.9286 - val_loss: 3.5134 - val_accuracy: 0.4500\n",
      "Epoch 2226/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2896 - accuracy: 0.9271 - val_loss: 3.5120 - val_accuracy: 0.4500\n",
      "Epoch 2227/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2901 - accuracy: 0.9286 - val_loss: 3.4800 - val_accuracy: 0.4467\n",
      "Epoch 2228/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2897 - accuracy: 0.9271 - val_loss: 3.4944 - val_accuracy: 0.4467\n",
      "Epoch 2229/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2904 - accuracy: 0.9286 - val_loss: 3.4905 - val_accuracy: 0.4500\n",
      "Epoch 2230/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2890 - accuracy: 0.9286 - val_loss: 3.4807 - val_accuracy: 0.4400\n",
      "Epoch 2231/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2906 - accuracy: 0.9286 - val_loss: 3.4945 - val_accuracy: 0.4400\n",
      "Epoch 2232/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2893 - accuracy: 0.9286 - val_loss: 3.4955 - val_accuracy: 0.4467\n",
      "Epoch 2233/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2894 - accuracy: 0.9271 - val_loss: 3.4942 - val_accuracy: 0.4467\n",
      "Epoch 2234/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2890 - accuracy: 0.9286 - val_loss: 3.5093 - val_accuracy: 0.4500\n",
      "Epoch 2235/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2889 - accuracy: 0.9271 - val_loss: 3.4972 - val_accuracy: 0.4367\n",
      "Epoch 2236/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2894 - accuracy: 0.9286 - val_loss: 3.5144 - val_accuracy: 0.4500\n",
      "Epoch 2237/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2893 - accuracy: 0.9286 - val_loss: 3.5137 - val_accuracy: 0.4500\n",
      "Epoch 2238/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2889 - accuracy: 0.9286 - val_loss: 3.4827 - val_accuracy: 0.4400\n",
      "Epoch 2239/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.2894 - accuracy: 0.9257 - val_loss: 3.5073 - val_accuracy: 0.4500\n",
      "Epoch 2240/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2892 - accuracy: 0.9271 - val_loss: 3.4959 - val_accuracy: 0.4467\n",
      "Epoch 2241/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2893 - accuracy: 0.9271 - val_loss: 3.5228 - val_accuracy: 0.4533\n",
      "Epoch 2242/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2887 - accuracy: 0.9257 - val_loss: 3.5069 - val_accuracy: 0.4500\n",
      "Epoch 2243/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2899 - accuracy: 0.9286 - val_loss: 3.5086 - val_accuracy: 0.4500\n",
      "Epoch 2244/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2890 - accuracy: 0.9257 - val_loss: 3.5120 - val_accuracy: 0.4433\n",
      "Epoch 2245/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2891 - accuracy: 0.9286 - val_loss: 3.5140 - val_accuracy: 0.4467\n",
      "Epoch 2246/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2887 - accuracy: 0.9271 - val_loss: 3.5181 - val_accuracy: 0.4467\n",
      "Epoch 2247/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2885 - accuracy: 0.9286 - val_loss: 3.5344 - val_accuracy: 0.4500\n",
      "Epoch 2248/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2882 - accuracy: 0.9286 - val_loss: 3.4916 - val_accuracy: 0.4400\n",
      "Epoch 2249/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2895 - accuracy: 0.9286 - val_loss: 3.5177 - val_accuracy: 0.4467\n",
      "Epoch 2250/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2872 - accuracy: 0.9286 - val_loss: 3.4882 - val_accuracy: 0.4400\n",
      "Epoch 2251/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2888 - accuracy: 0.9271 - val_loss: 3.5148 - val_accuracy: 0.4433\n",
      "Epoch 2252/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2892 - accuracy: 0.9286 - val_loss: 3.5177 - val_accuracy: 0.4500\n",
      "Epoch 2253/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2886 - accuracy: 0.9286 - val_loss: 3.5309 - val_accuracy: 0.4533\n",
      "Epoch 2254/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2886 - accuracy: 0.9286 - val_loss: 3.5357 - val_accuracy: 0.4533\n",
      "Epoch 2255/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.2883 - accuracy: 0.9286 - val_loss: 3.5180 - val_accuracy: 0.4500\n",
      "Epoch 2256/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2882 - accuracy: 0.9271 - val_loss: 3.5163 - val_accuracy: 0.4433\n",
      "Epoch 2257/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2891 - accuracy: 0.9271 - val_loss: 3.5369 - val_accuracy: 0.4500\n",
      "Epoch 2258/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2886 - accuracy: 0.9286 - val_loss: 3.5315 - val_accuracy: 0.4500\n",
      "Epoch 2259/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2879 - accuracy: 0.9286 - val_loss: 3.5303 - val_accuracy: 0.4467\n",
      "Epoch 2260/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2884 - accuracy: 0.9286 - val_loss: 3.5376 - val_accuracy: 0.4500\n",
      "Epoch 2261/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2886 - accuracy: 0.9271 - val_loss: 3.5315 - val_accuracy: 0.4467\n",
      "Epoch 2262/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2885 - accuracy: 0.9286 - val_loss: 3.5268 - val_accuracy: 0.4467\n",
      "Epoch 2263/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2889 - accuracy: 0.9286 - val_loss: 3.5242 - val_accuracy: 0.4500\n",
      "Epoch 2264/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2879 - accuracy: 0.9271 - val_loss: 3.5431 - val_accuracy: 0.4467\n",
      "Epoch 2265/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.2880 - accuracy: 0.9271 - val_loss: 3.5298 - val_accuracy: 0.4433\n",
      "Epoch 2266/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2878 - accuracy: 0.9286 - val_loss: 3.5266 - val_accuracy: 0.4500\n",
      "Epoch 2267/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2882 - accuracy: 0.9257 - val_loss: 3.5298 - val_accuracy: 0.4433\n",
      "Epoch 2268/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2878 - accuracy: 0.9286 - val_loss: 3.5073 - val_accuracy: 0.4400\n",
      "Epoch 2269/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2879 - accuracy: 0.9286 - val_loss: 3.5100 - val_accuracy: 0.4400\n",
      "Epoch 2270/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2876 - accuracy: 0.9286 - val_loss: 3.5345 - val_accuracy: 0.4467\n",
      "Epoch 2271/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2875 - accuracy: 0.9271 - val_loss: 3.5405 - val_accuracy: 0.4467\n",
      "Epoch 2272/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2880 - accuracy: 0.9286 - val_loss: 3.5536 - val_accuracy: 0.4500\n",
      "Epoch 2273/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2876 - accuracy: 0.9257 - val_loss: 3.5271 - val_accuracy: 0.4400\n",
      "Epoch 2274/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2878 - accuracy: 0.9286 - val_loss: 3.5504 - val_accuracy: 0.4500\n",
      "Epoch 2275/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2873 - accuracy: 0.9286 - val_loss: 3.5372 - val_accuracy: 0.4533\n",
      "Epoch 2276/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2871 - accuracy: 0.9271 - val_loss: 3.5261 - val_accuracy: 0.4400\n",
      "Epoch 2277/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2871 - accuracy: 0.9286 - val_loss: 3.5470 - val_accuracy: 0.4500\n",
      "Epoch 2278/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2875 - accuracy: 0.9286 - val_loss: 3.5423 - val_accuracy: 0.4500\n",
      "Epoch 2279/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2871 - accuracy: 0.9286 - val_loss: 3.5612 - val_accuracy: 0.4433\n",
      "Epoch 2280/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2880 - accuracy: 0.9271 - val_loss: 3.5523 - val_accuracy: 0.4500\n",
      "Epoch 2281/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2872 - accuracy: 0.9300 - val_loss: 3.5404 - val_accuracy: 0.4433\n",
      "Epoch 2282/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2866 - accuracy: 0.9286 - val_loss: 3.5552 - val_accuracy: 0.4467\n",
      "Epoch 2283/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2873 - accuracy: 0.9286 - val_loss: 3.5594 - val_accuracy: 0.4467\n",
      "Epoch 2284/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2863 - accuracy: 0.9286 - val_loss: 3.5414 - val_accuracy: 0.4467\n",
      "Epoch 2285/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2869 - accuracy: 0.9286 - val_loss: 3.5384 - val_accuracy: 0.4433\n",
      "Epoch 2286/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2867 - accuracy: 0.9286 - val_loss: 3.5480 - val_accuracy: 0.4467\n",
      "Epoch 2287/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2867 - accuracy: 0.9300 - val_loss: 3.5575 - val_accuracy: 0.4467\n",
      "Epoch 2288/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2866 - accuracy: 0.9286 - val_loss: 3.5396 - val_accuracy: 0.4400\n",
      "Epoch 2289/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2871 - accuracy: 0.9286 - val_loss: 3.5551 - val_accuracy: 0.4367\n",
      "Epoch 2290/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2870 - accuracy: 0.9286 - val_loss: 3.5404 - val_accuracy: 0.4433\n",
      "Epoch 2291/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2864 - accuracy: 0.9300 - val_loss: 3.5423 - val_accuracy: 0.4467\n",
      "Epoch 2292/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2876 - accuracy: 0.9286 - val_loss: 3.5481 - val_accuracy: 0.4400\n",
      "Epoch 2293/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2861 - accuracy: 0.9286 - val_loss: 3.5572 - val_accuracy: 0.4500\n",
      "Epoch 2294/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2870 - accuracy: 0.9286 - val_loss: 3.5692 - val_accuracy: 0.4467\n",
      "Epoch 2295/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2865 - accuracy: 0.9271 - val_loss: 3.5641 - val_accuracy: 0.4467\n",
      "Epoch 2296/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2865 - accuracy: 0.9286 - val_loss: 3.5555 - val_accuracy: 0.4467\n",
      "Epoch 2297/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2868 - accuracy: 0.9286 - val_loss: 3.5505 - val_accuracy: 0.4433\n",
      "Epoch 2298/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2863 - accuracy: 0.9286 - val_loss: 3.5483 - val_accuracy: 0.4467\n",
      "Epoch 2299/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2868 - accuracy: 0.9286 - val_loss: 3.5570 - val_accuracy: 0.4433\n",
      "Epoch 2300/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2865 - accuracy: 0.9300 - val_loss: 3.5817 - val_accuracy: 0.4467\n",
      "Epoch 2301/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2866 - accuracy: 0.9286 - val_loss: 3.5705 - val_accuracy: 0.4500\n",
      "Epoch 2302/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2858 - accuracy: 0.9286 - val_loss: 3.5522 - val_accuracy: 0.4400\n",
      "Epoch 2303/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2866 - accuracy: 0.9271 - val_loss: 3.5738 - val_accuracy: 0.4467\n",
      "Epoch 2304/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2862 - accuracy: 0.9286 - val_loss: 3.5809 - val_accuracy: 0.4500\n",
      "Epoch 2305/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2859 - accuracy: 0.9286 - val_loss: 3.5584 - val_accuracy: 0.4467\n",
      "Epoch 2306/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2863 - accuracy: 0.9286 - val_loss: 3.5699 - val_accuracy: 0.4467\n",
      "Epoch 2307/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2859 - accuracy: 0.9286 - val_loss: 3.5573 - val_accuracy: 0.4400\n",
      "Epoch 2308/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2867 - accuracy: 0.9286 - val_loss: 3.5665 - val_accuracy: 0.4400\n",
      "Epoch 2309/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2856 - accuracy: 0.9286 - val_loss: 3.5605 - val_accuracy: 0.4367\n",
      "Epoch 2310/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2861 - accuracy: 0.9286 - val_loss: 3.5774 - val_accuracy: 0.4467\n",
      "Epoch 2311/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2859 - accuracy: 0.9271 - val_loss: 3.5903 - val_accuracy: 0.4467\n",
      "Epoch 2312/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2866 - accuracy: 0.9286 - val_loss: 3.5971 - val_accuracy: 0.4467\n",
      "Epoch 2313/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2863 - accuracy: 0.9286 - val_loss: 3.5872 - val_accuracy: 0.4467\n",
      "Epoch 2314/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2856 - accuracy: 0.9286 - val_loss: 3.5718 - val_accuracy: 0.4433\n",
      "Epoch 2315/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2857 - accuracy: 0.9286 - val_loss: 3.5896 - val_accuracy: 0.4467\n",
      "Epoch 2316/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2859 - accuracy: 0.9300 - val_loss: 3.5885 - val_accuracy: 0.4467\n",
      "Epoch 2317/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2855 - accuracy: 0.9286 - val_loss: 3.5769 - val_accuracy: 0.4467\n",
      "Epoch 2318/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2854 - accuracy: 0.9286 - val_loss: 3.5834 - val_accuracy: 0.4467\n",
      "Epoch 2319/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2854 - accuracy: 0.9286 - val_loss: 3.5674 - val_accuracy: 0.4467\n",
      "Epoch 2320/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.2858 - accuracy: 0.9271 - val_loss: 3.5824 - val_accuracy: 0.4467\n",
      "Epoch 2321/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2858 - accuracy: 0.9286 - val_loss: 3.5709 - val_accuracy: 0.4467\n",
      "Epoch 2322/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2855 - accuracy: 0.9286 - val_loss: 3.5917 - val_accuracy: 0.4433\n",
      "Epoch 2323/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2851 - accuracy: 0.9271 - val_loss: 3.5753 - val_accuracy: 0.4367\n",
      "Epoch 2324/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2852 - accuracy: 0.9286 - val_loss: 3.5597 - val_accuracy: 0.4367\n",
      "Epoch 2325/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2850 - accuracy: 0.9286 - val_loss: 3.5840 - val_accuracy: 0.4433\n",
      "Epoch 2326/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2842 - accuracy: 0.9286 - val_loss: 3.6071 - val_accuracy: 0.4467\n",
      "Epoch 2327/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2858 - accuracy: 0.9286 - val_loss: 3.6137 - val_accuracy: 0.4500\n",
      "Epoch 2328/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2853 - accuracy: 0.9300 - val_loss: 3.5924 - val_accuracy: 0.4467\n",
      "Epoch 2329/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2850 - accuracy: 0.9286 - val_loss: 3.5808 - val_accuracy: 0.4367\n",
      "Epoch 2330/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2851 - accuracy: 0.9286 - val_loss: 3.5841 - val_accuracy: 0.4367\n",
      "Epoch 2331/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2849 - accuracy: 0.9286 - val_loss: 3.5851 - val_accuracy: 0.4400\n",
      "Epoch 2332/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2850 - accuracy: 0.9286 - val_loss: 3.5933 - val_accuracy: 0.4467\n",
      "Epoch 2333/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2849 - accuracy: 0.9286 - val_loss: 3.5903 - val_accuracy: 0.4367\n",
      "Epoch 2334/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2848 - accuracy: 0.9300 - val_loss: 3.5848 - val_accuracy: 0.4367\n",
      "Epoch 2335/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2847 - accuracy: 0.9286 - val_loss: 3.5812 - val_accuracy: 0.4367\n",
      "Epoch 2336/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2851 - accuracy: 0.9286 - val_loss: 3.6017 - val_accuracy: 0.4433\n",
      "Epoch 2337/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2850 - accuracy: 0.9300 - val_loss: 3.5889 - val_accuracy: 0.4400\n",
      "Epoch 2338/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2847 - accuracy: 0.9300 - val_loss: 3.6016 - val_accuracy: 0.4433\n",
      "Epoch 2339/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2847 - accuracy: 0.9271 - val_loss: 3.5975 - val_accuracy: 0.4433\n",
      "Epoch 2340/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2850 - accuracy: 0.9271 - val_loss: 3.5710 - val_accuracy: 0.4400\n",
      "Epoch 2341/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2849 - accuracy: 0.9286 - val_loss: 3.6007 - val_accuracy: 0.4500\n",
      "Epoch 2342/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2848 - accuracy: 0.9286 - val_loss: 3.5807 - val_accuracy: 0.4400\n",
      "Epoch 2343/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2845 - accuracy: 0.9286 - val_loss: 3.6038 - val_accuracy: 0.4433\n",
      "Epoch 2344/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2847 - accuracy: 0.9286 - val_loss: 3.6061 - val_accuracy: 0.4467\n",
      "Epoch 2345/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 0.2847 - accuracy: 0.9286 - val_loss: 3.5955 - val_accuracy: 0.4467\n",
      "Epoch 2346/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2843 - accuracy: 0.9286 - val_loss: 3.5870 - val_accuracy: 0.4400\n",
      "Epoch 2347/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2842 - accuracy: 0.9300 - val_loss: 3.6009 - val_accuracy: 0.4467\n",
      "Epoch 2348/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2847 - accuracy: 0.9286 - val_loss: 3.5717 - val_accuracy: 0.4400\n",
      "Epoch 2349/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2847 - accuracy: 0.9286 - val_loss: 3.5929 - val_accuracy: 0.4433\n",
      "Epoch 2350/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2842 - accuracy: 0.9271 - val_loss: 3.6014 - val_accuracy: 0.4433\n",
      "Epoch 2351/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2843 - accuracy: 0.9286 - val_loss: 3.6147 - val_accuracy: 0.4467\n",
      "Epoch 2352/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2843 - accuracy: 0.9286 - val_loss: 3.6209 - val_accuracy: 0.4467\n",
      "Epoch 2353/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2848 - accuracy: 0.9286 - val_loss: 3.6111 - val_accuracy: 0.4433\n",
      "Epoch 2354/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2839 - accuracy: 0.9300 - val_loss: 3.5901 - val_accuracy: 0.4367\n",
      "Epoch 2355/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2844 - accuracy: 0.9300 - val_loss: 3.6289 - val_accuracy: 0.4467\n",
      "Epoch 2356/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2841 - accuracy: 0.9286 - val_loss: 3.6150 - val_accuracy: 0.4367\n",
      "Epoch 2357/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2842 - accuracy: 0.9286 - val_loss: 3.6279 - val_accuracy: 0.4433\n",
      "Epoch 2358/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2838 - accuracy: 0.9300 - val_loss: 3.6212 - val_accuracy: 0.4433\n",
      "Epoch 2359/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2841 - accuracy: 0.9300 - val_loss: 3.6024 - val_accuracy: 0.4433\n",
      "Epoch 2360/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2837 - accuracy: 0.9286 - val_loss: 3.6170 - val_accuracy: 0.4467\n",
      "Epoch 2361/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2843 - accuracy: 0.9286 - val_loss: 3.6059 - val_accuracy: 0.4367\n",
      "Epoch 2362/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2836 - accuracy: 0.9286 - val_loss: 3.6134 - val_accuracy: 0.4400\n",
      "Epoch 2363/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2840 - accuracy: 0.9286 - val_loss: 3.5960 - val_accuracy: 0.4400\n",
      "Epoch 2364/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2837 - accuracy: 0.9286 - val_loss: 3.6152 - val_accuracy: 0.4400\n",
      "Epoch 2365/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.2837 - accuracy: 0.9286 - val_loss: 3.6395 - val_accuracy: 0.4433\n",
      "Epoch 2366/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2840 - accuracy: 0.9300 - val_loss: 3.6113 - val_accuracy: 0.4400\n",
      "Epoch 2367/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2834 - accuracy: 0.9286 - val_loss: 3.6384 - val_accuracy: 0.4467\n",
      "Epoch 2368/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2836 - accuracy: 0.9286 - val_loss: 3.6345 - val_accuracy: 0.4467\n",
      "Epoch 2369/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2834 - accuracy: 0.9286 - val_loss: 3.6125 - val_accuracy: 0.4433\n",
      "Epoch 2370/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2835 - accuracy: 0.9286 - val_loss: 3.6319 - val_accuracy: 0.4433\n",
      "Epoch 2371/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2834 - accuracy: 0.9286 - val_loss: 3.6321 - val_accuracy: 0.4467\n",
      "Epoch 2372/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2833 - accuracy: 0.9286 - val_loss: 3.6186 - val_accuracy: 0.4400\n",
      "Epoch 2373/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2836 - accuracy: 0.9300 - val_loss: 3.6198 - val_accuracy: 0.4467\n",
      "Epoch 2374/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2830 - accuracy: 0.9271 - val_loss: 3.6306 - val_accuracy: 0.4467\n",
      "Epoch 2375/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 109us/step - loss: 0.2834 - accuracy: 0.9286 - val_loss: 3.5926 - val_accuracy: 0.4367\n",
      "Epoch 2376/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2832 - accuracy: 0.9286 - val_loss: 3.6294 - val_accuracy: 0.4433\n",
      "Epoch 2377/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2833 - accuracy: 0.9300 - val_loss: 3.6187 - val_accuracy: 0.4367\n",
      "Epoch 2378/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2832 - accuracy: 0.9286 - val_loss: 3.6264 - val_accuracy: 0.4433\n",
      "Epoch 2379/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2833 - accuracy: 0.9286 - val_loss: 3.6375 - val_accuracy: 0.4500\n",
      "Epoch 2380/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2832 - accuracy: 0.9286 - val_loss: 3.6199 - val_accuracy: 0.4367\n",
      "Epoch 2381/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2834 - accuracy: 0.9271 - val_loss: 3.6400 - val_accuracy: 0.4433\n",
      "Epoch 2382/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2832 - accuracy: 0.9286 - val_loss: 3.6323 - val_accuracy: 0.4400\n",
      "Epoch 2383/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2834 - accuracy: 0.9286 - val_loss: 3.6285 - val_accuracy: 0.4433\n",
      "Epoch 2384/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2826 - accuracy: 0.9286 - val_loss: 3.6207 - val_accuracy: 0.4367\n",
      "Epoch 2385/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2833 - accuracy: 0.9300 - val_loss: 3.6371 - val_accuracy: 0.4500\n",
      "Epoch 2386/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2827 - accuracy: 0.9286 - val_loss: 3.6450 - val_accuracy: 0.4433\n",
      "Epoch 2387/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2827 - accuracy: 0.9286 - val_loss: 3.6407 - val_accuracy: 0.4433\n",
      "Epoch 2388/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2825 - accuracy: 0.9286 - val_loss: 3.6376 - val_accuracy: 0.4433\n",
      "Epoch 2389/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2828 - accuracy: 0.9286 - val_loss: 3.6184 - val_accuracy: 0.4367\n",
      "Epoch 2390/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2825 - accuracy: 0.9300 - val_loss: 3.6468 - val_accuracy: 0.4433\n",
      "Epoch 2391/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2826 - accuracy: 0.9286 - val_loss: 3.6214 - val_accuracy: 0.4367\n",
      "Epoch 2392/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2826 - accuracy: 0.9300 - val_loss: 3.6340 - val_accuracy: 0.4400\n",
      "Epoch 2393/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2825 - accuracy: 0.9286 - val_loss: 3.6296 - val_accuracy: 0.4433\n",
      "Epoch 2394/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2824 - accuracy: 0.9286 - val_loss: 3.6372 - val_accuracy: 0.4400\n",
      "Epoch 2395/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2826 - accuracy: 0.9286 - val_loss: 3.6461 - val_accuracy: 0.4433\n",
      "Epoch 2396/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2819 - accuracy: 0.9286 - val_loss: 3.6478 - val_accuracy: 0.4500\n",
      "Epoch 2397/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2823 - accuracy: 0.9300 - val_loss: 3.6511 - val_accuracy: 0.4500\n",
      "Epoch 2398/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2823 - accuracy: 0.9300 - val_loss: 3.6380 - val_accuracy: 0.4400\n",
      "Epoch 2399/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2822 - accuracy: 0.9286 - val_loss: 3.6340 - val_accuracy: 0.4400\n",
      "Epoch 2400/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2818 - accuracy: 0.9300 - val_loss: 3.6606 - val_accuracy: 0.4467\n",
      "Epoch 2401/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2824 - accuracy: 0.9286 - val_loss: 3.6409 - val_accuracy: 0.4400\n",
      "Epoch 2402/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2821 - accuracy: 0.9300 - val_loss: 3.6504 - val_accuracy: 0.4433\n",
      "Epoch 2403/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2824 - accuracy: 0.9300 - val_loss: 3.6524 - val_accuracy: 0.4400\n",
      "Epoch 2404/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2824 - accuracy: 0.9286 - val_loss: 3.6527 - val_accuracy: 0.4400\n",
      "Epoch 2405/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2822 - accuracy: 0.9286 - val_loss: 3.6473 - val_accuracy: 0.4433\n",
      "Epoch 2406/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2825 - accuracy: 0.9300 - val_loss: 3.6456 - val_accuracy: 0.4400\n",
      "Epoch 2407/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2813 - accuracy: 0.9286 - val_loss: 3.6285 - val_accuracy: 0.4367\n",
      "Epoch 2408/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.2821 - accuracy: 0.9300 - val_loss: 3.6729 - val_accuracy: 0.4467\n",
      "Epoch 2409/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.2816 - accuracy: 0.9286 - val_loss: 3.6562 - val_accuracy: 0.4400\n",
      "Epoch 2410/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2827 - accuracy: 0.9286 - val_loss: 3.6545 - val_accuracy: 0.4400\n",
      "Epoch 2411/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2817 - accuracy: 0.9286 - val_loss: 3.6492 - val_accuracy: 0.4400\n",
      "Epoch 2412/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2816 - accuracy: 0.9286 - val_loss: 3.6315 - val_accuracy: 0.4400\n",
      "Epoch 2413/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2820 - accuracy: 0.9286 - val_loss: 3.6489 - val_accuracy: 0.4400\n",
      "Epoch 2414/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2816 - accuracy: 0.9286 - val_loss: 3.6688 - val_accuracy: 0.4467\n",
      "Epoch 2415/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 0.2812 - accuracy: 0.9286 - val_loss: 3.6577 - val_accuracy: 0.4400\n",
      "Epoch 2416/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2820 - accuracy: 0.9286 - val_loss: 3.6705 - val_accuracy: 0.4433\n",
      "Epoch 2417/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2821 - accuracy: 0.9286 - val_loss: 3.6596 - val_accuracy: 0.4400\n",
      "Epoch 2418/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2814 - accuracy: 0.9286 - val_loss: 3.6498 - val_accuracy: 0.4367\n",
      "Epoch 2419/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2820 - accuracy: 0.9300 - val_loss: 3.6509 - val_accuracy: 0.4400\n",
      "Epoch 2420/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2816 - accuracy: 0.9286 - val_loss: 3.6621 - val_accuracy: 0.4400\n",
      "Epoch 2421/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2814 - accuracy: 0.9300 - val_loss: 3.6624 - val_accuracy: 0.4433\n",
      "Epoch 2422/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2814 - accuracy: 0.9286 - val_loss: 3.6728 - val_accuracy: 0.4433\n",
      "Epoch 2423/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2816 - accuracy: 0.9286 - val_loss: 3.6538 - val_accuracy: 0.4367\n",
      "Epoch 2424/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2812 - accuracy: 0.9286 - val_loss: 3.6811 - val_accuracy: 0.4467\n",
      "Epoch 2425/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2811 - accuracy: 0.9286 - val_loss: 3.6667 - val_accuracy: 0.4400\n",
      "Epoch 2426/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2808 - accuracy: 0.9286 - val_loss: 3.6644 - val_accuracy: 0.4400\n",
      "Epoch 2427/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2816 - accuracy: 0.9300 - val_loss: 3.6695 - val_accuracy: 0.4400\n",
      "Epoch 2428/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2810 - accuracy: 0.9286 - val_loss: 3.6682 - val_accuracy: 0.4400\n",
      "Epoch 2429/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2812 - accuracy: 0.9286 - val_loss: 3.6533 - val_accuracy: 0.4333\n",
      "Epoch 2430/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.2808 - accuracy: 0.9300 - val_loss: 3.6621 - val_accuracy: 0.4367\n",
      "Epoch 2431/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2812 - accuracy: 0.9300 - val_loss: 3.6821 - val_accuracy: 0.4467\n",
      "Epoch 2432/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2810 - accuracy: 0.9286 - val_loss: 3.6856 - val_accuracy: 0.4400\n",
      "Epoch 2433/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2809 - accuracy: 0.9300 - val_loss: 3.6422 - val_accuracy: 0.4333\n",
      "Epoch 2434/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2811 - accuracy: 0.9300 - val_loss: 3.6609 - val_accuracy: 0.4367\n",
      "Epoch 2435/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2807 - accuracy: 0.9286 - val_loss: 3.6876 - val_accuracy: 0.4433\n",
      "Epoch 2436/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2811 - accuracy: 0.9286 - val_loss: 3.6656 - val_accuracy: 0.4367\n",
      "Epoch 2437/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2809 - accuracy: 0.9286 - val_loss: 3.6819 - val_accuracy: 0.4400\n",
      "Epoch 2438/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2804 - accuracy: 0.9300 - val_loss: 3.6864 - val_accuracy: 0.4400\n",
      "Epoch 2439/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2807 - accuracy: 0.9300 - val_loss: 3.6881 - val_accuracy: 0.4467\n",
      "Epoch 2440/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2807 - accuracy: 0.9286 - val_loss: 3.7018 - val_accuracy: 0.4400\n",
      "Epoch 2441/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2809 - accuracy: 0.9286 - val_loss: 3.6680 - val_accuracy: 0.4367\n",
      "Epoch 2442/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2803 - accuracy: 0.9286 - val_loss: 3.6555 - val_accuracy: 0.4400\n",
      "Epoch 2443/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2801 - accuracy: 0.9286 - val_loss: 3.6677 - val_accuracy: 0.4467\n",
      "Epoch 2444/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2803 - accuracy: 0.9286 - val_loss: 3.6623 - val_accuracy: 0.4400\n",
      "Epoch 2445/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2805 - accuracy: 0.9286 - val_loss: 3.6750 - val_accuracy: 0.4433\n",
      "Epoch 2446/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2807 - accuracy: 0.9300 - val_loss: 3.6834 - val_accuracy: 0.4433\n",
      "Epoch 2447/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2804 - accuracy: 0.9300 - val_loss: 3.6671 - val_accuracy: 0.4400\n",
      "Epoch 2448/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2807 - accuracy: 0.9286 - val_loss: 3.6903 - val_accuracy: 0.4433\n",
      "Epoch 2449/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2803 - accuracy: 0.9286 - val_loss: 3.6829 - val_accuracy: 0.4367\n",
      "Epoch 2450/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2803 - accuracy: 0.9300 - val_loss: 3.6873 - val_accuracy: 0.4367\n",
      "Epoch 2451/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2800 - accuracy: 0.9286 - val_loss: 3.7094 - val_accuracy: 0.4400\n",
      "Epoch 2452/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2808 - accuracy: 0.9286 - val_loss: 3.6771 - val_accuracy: 0.4367\n",
      "Epoch 2453/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2802 - accuracy: 0.9286 - val_loss: 3.7044 - val_accuracy: 0.4400\n",
      "Epoch 2454/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2804 - accuracy: 0.9286 - val_loss: 3.6895 - val_accuracy: 0.4400\n",
      "Epoch 2455/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2799 - accuracy: 0.9300 - val_loss: 3.6841 - val_accuracy: 0.4367\n",
      "Epoch 2456/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2802 - accuracy: 0.9300 - val_loss: 3.6835 - val_accuracy: 0.4333\n",
      "Epoch 2457/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2801 - accuracy: 0.9300 - val_loss: 3.6985 - val_accuracy: 0.4433\n",
      "Epoch 2458/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2807 - accuracy: 0.9286 - val_loss: 3.6923 - val_accuracy: 0.4400\n",
      "Epoch 2459/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2797 - accuracy: 0.9286 - val_loss: 3.7041 - val_accuracy: 0.4400\n",
      "Epoch 2460/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2797 - accuracy: 0.9286 - val_loss: 3.6723 - val_accuracy: 0.4333\n",
      "Epoch 2461/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2802 - accuracy: 0.9300 - val_loss: 3.7025 - val_accuracy: 0.4467\n",
      "Epoch 2462/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2801 - accuracy: 0.9300 - val_loss: 3.6773 - val_accuracy: 0.4333\n",
      "Epoch 2463/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2798 - accuracy: 0.9300 - val_loss: 3.6895 - val_accuracy: 0.4433\n",
      "Epoch 2464/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2789 - accuracy: 0.9300 - val_loss: 3.6770 - val_accuracy: 0.4400\n",
      "Epoch 2465/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2800 - accuracy: 0.9286 - val_loss: 3.7082 - val_accuracy: 0.4467\n",
      "Epoch 2466/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2798 - accuracy: 0.9300 - val_loss: 3.6819 - val_accuracy: 0.4400\n",
      "Epoch 2467/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2796 - accuracy: 0.9286 - val_loss: 3.6965 - val_accuracy: 0.4367\n",
      "Epoch 2468/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2797 - accuracy: 0.9286 - val_loss: 3.6845 - val_accuracy: 0.4400\n",
      "Epoch 2469/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2793 - accuracy: 0.9300 - val_loss: 3.7022 - val_accuracy: 0.4367\n",
      "Epoch 2470/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2797 - accuracy: 0.9300 - val_loss: 3.6918 - val_accuracy: 0.4367\n",
      "Epoch 2471/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2793 - accuracy: 0.9286 - val_loss: 3.7092 - val_accuracy: 0.4400\n",
      "Epoch 2472/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2799 - accuracy: 0.9300 - val_loss: 3.7107 - val_accuracy: 0.4433\n",
      "Epoch 2473/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2794 - accuracy: 0.9286 - val_loss: 3.7045 - val_accuracy: 0.4400\n",
      "Epoch 2474/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2791 - accuracy: 0.9300 - val_loss: 3.7189 - val_accuracy: 0.4400\n",
      "Epoch 2475/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2798 - accuracy: 0.9271 - val_loss: 3.7120 - val_accuracy: 0.4433\n",
      "Epoch 2476/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2791 - accuracy: 0.9300 - val_loss: 3.7197 - val_accuracy: 0.4433\n",
      "Epoch 2477/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2792 - accuracy: 0.9300 - val_loss: 3.7129 - val_accuracy: 0.4467\n",
      "Epoch 2478/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2790 - accuracy: 0.9286 - val_loss: 3.7257 - val_accuracy: 0.4433\n",
      "Epoch 2479/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2793 - accuracy: 0.9286 - val_loss: 3.7123 - val_accuracy: 0.4433\n",
      "Epoch 2480/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2792 - accuracy: 0.9286 - val_loss: 3.7042 - val_accuracy: 0.4433\n",
      "Epoch 2481/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2793 - accuracy: 0.9300 - val_loss: 3.7101 - val_accuracy: 0.4400\n",
      "Epoch 2482/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2794 - accuracy: 0.9300 - val_loss: 3.7118 - val_accuracy: 0.4400\n",
      "Epoch 2483/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2794 - accuracy: 0.9286 - val_loss: 3.7076 - val_accuracy: 0.4367\n",
      "Epoch 2484/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2783 - accuracy: 0.9300 - val_loss: 3.7299 - val_accuracy: 0.4433\n",
      "Epoch 2485/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 86us/step - loss: 0.2790 - accuracy: 0.9286 - val_loss: 3.7292 - val_accuracy: 0.4433\n",
      "Epoch 2486/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2798 - accuracy: 0.9300 - val_loss: 3.7231 - val_accuracy: 0.4433\n",
      "Epoch 2487/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2795 - accuracy: 0.9286 - val_loss: 3.7018 - val_accuracy: 0.4333\n",
      "Epoch 2488/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2786 - accuracy: 0.9300 - val_loss: 3.7092 - val_accuracy: 0.4367\n",
      "Epoch 2489/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2792 - accuracy: 0.9286 - val_loss: 3.7101 - val_accuracy: 0.4367\n",
      "Epoch 2490/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2790 - accuracy: 0.9286 - val_loss: 3.7264 - val_accuracy: 0.4433\n",
      "Epoch 2491/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2785 - accuracy: 0.9286 - val_loss: 3.6940 - val_accuracy: 0.4433\n",
      "Epoch 2492/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2786 - accuracy: 0.9300 - val_loss: 3.7178 - val_accuracy: 0.4400\n",
      "Epoch 2493/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2782 - accuracy: 0.9286 - val_loss: 3.7200 - val_accuracy: 0.4367\n",
      "Epoch 2494/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2786 - accuracy: 0.9286 - val_loss: 3.7116 - val_accuracy: 0.4367\n",
      "Epoch 2495/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2788 - accuracy: 0.9300 - val_loss: 3.7340 - val_accuracy: 0.4400\n",
      "Epoch 2496/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.2786 - accuracy: 0.9300 - val_loss: 3.7118 - val_accuracy: 0.4333\n",
      "Epoch 2497/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2785 - accuracy: 0.9300 - val_loss: 3.7245 - val_accuracy: 0.4400\n",
      "Epoch 2498/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2786 - accuracy: 0.9286 - val_loss: 3.6888 - val_accuracy: 0.4400\n",
      "Epoch 2499/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2788 - accuracy: 0.9286 - val_loss: 3.7165 - val_accuracy: 0.4333\n",
      "Epoch 2500/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2788 - accuracy: 0.9300 - val_loss: 3.7154 - val_accuracy: 0.4367\n",
      "Epoch 2501/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2784 - accuracy: 0.9286 - val_loss: 3.7177 - val_accuracy: 0.4400\n",
      "Epoch 2502/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2780 - accuracy: 0.9286 - val_loss: 3.7384 - val_accuracy: 0.4433\n",
      "Epoch 2503/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2782 - accuracy: 0.9286 - val_loss: 3.7167 - val_accuracy: 0.4367\n",
      "Epoch 2504/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2780 - accuracy: 0.9300 - val_loss: 3.7289 - val_accuracy: 0.4333\n",
      "Epoch 2505/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2786 - accuracy: 0.9286 - val_loss: 3.7109 - val_accuracy: 0.4367\n",
      "Epoch 2506/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2791 - accuracy: 0.9286 - val_loss: 3.7424 - val_accuracy: 0.4467\n",
      "Epoch 2507/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2785 - accuracy: 0.9300 - val_loss: 3.7299 - val_accuracy: 0.4367\n",
      "Epoch 2508/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2779 - accuracy: 0.9286 - val_loss: 3.7376 - val_accuracy: 0.4400\n",
      "Epoch 2509/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2783 - accuracy: 0.9286 - val_loss: 3.7373 - val_accuracy: 0.4400\n",
      "Epoch 2510/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2783 - accuracy: 0.9286 - val_loss: 3.7500 - val_accuracy: 0.4400\n",
      "Epoch 2511/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2780 - accuracy: 0.9300 - val_loss: 3.7123 - val_accuracy: 0.4333\n",
      "Epoch 2512/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2779 - accuracy: 0.9300 - val_loss: 3.7544 - val_accuracy: 0.4367\n",
      "Epoch 2513/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2781 - accuracy: 0.9300 - val_loss: 3.7346 - val_accuracy: 0.4367\n",
      "Epoch 2514/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2781 - accuracy: 0.9286 - val_loss: 3.7435 - val_accuracy: 0.4433\n",
      "Epoch 2515/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2781 - accuracy: 0.9300 - val_loss: 3.7278 - val_accuracy: 0.4367\n",
      "Epoch 2516/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2781 - accuracy: 0.9300 - val_loss: 3.7308 - val_accuracy: 0.4367\n",
      "Epoch 2517/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2778 - accuracy: 0.9286 - val_loss: 3.7468 - val_accuracy: 0.4367\n",
      "Epoch 2518/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2781 - accuracy: 0.9286 - val_loss: 3.7287 - val_accuracy: 0.4333\n",
      "Epoch 2519/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2781 - accuracy: 0.9300 - val_loss: 3.7432 - val_accuracy: 0.4367\n",
      "Epoch 2520/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2781 - accuracy: 0.9286 - val_loss: 3.7441 - val_accuracy: 0.4400\n",
      "Epoch 2521/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2778 - accuracy: 0.9300 - val_loss: 3.7589 - val_accuracy: 0.4400\n",
      "Epoch 2522/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2776 - accuracy: 0.9286 - val_loss: 3.7447 - val_accuracy: 0.4367\n",
      "Epoch 2523/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2780 - accuracy: 0.9300 - val_loss: 3.7592 - val_accuracy: 0.4400\n",
      "Epoch 2524/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2775 - accuracy: 0.9286 - val_loss: 3.7442 - val_accuracy: 0.4367\n",
      "Epoch 2525/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2780 - accuracy: 0.9286 - val_loss: 3.7627 - val_accuracy: 0.4400\n",
      "Epoch 2526/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2774 - accuracy: 0.9300 - val_loss: 3.7188 - val_accuracy: 0.4400\n",
      "Epoch 2527/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2780 - accuracy: 0.9286 - val_loss: 3.7361 - val_accuracy: 0.4333\n",
      "Epoch 2528/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2775 - accuracy: 0.9300 - val_loss: 3.7657 - val_accuracy: 0.4400\n",
      "Epoch 2529/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2777 - accuracy: 0.9286 - val_loss: 3.7437 - val_accuracy: 0.4400\n",
      "Epoch 2530/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2774 - accuracy: 0.9300 - val_loss: 3.7651 - val_accuracy: 0.4400\n",
      "Epoch 2531/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2776 - accuracy: 0.9286 - val_loss: 3.7244 - val_accuracy: 0.4367\n",
      "Epoch 2532/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2776 - accuracy: 0.9286 - val_loss: 3.7690 - val_accuracy: 0.4367\n",
      "Epoch 2533/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2776 - accuracy: 0.9286 - val_loss: 3.7543 - val_accuracy: 0.4367\n",
      "Epoch 2534/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2772 - accuracy: 0.9300 - val_loss: 3.7550 - val_accuracy: 0.4367\n",
      "Epoch 2535/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2773 - accuracy: 0.9300 - val_loss: 3.7468 - val_accuracy: 0.4367\n",
      "Epoch 2536/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2770 - accuracy: 0.9300 - val_loss: 3.7582 - val_accuracy: 0.4400\n",
      "Epoch 2537/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2773 - accuracy: 0.9300 - val_loss: 3.7268 - val_accuracy: 0.4333\n",
      "Epoch 2538/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2778 - accuracy: 0.9286 - val_loss: 3.7352 - val_accuracy: 0.4367\n",
      "Epoch 2539/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2768 - accuracy: 0.9300 - val_loss: 3.7671 - val_accuracy: 0.4400\n",
      "Epoch 2540/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 114us/step - loss: 0.2771 - accuracy: 0.9286 - val_loss: 3.7490 - val_accuracy: 0.4333\n",
      "Epoch 2541/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2772 - accuracy: 0.9300 - val_loss: 3.7560 - val_accuracy: 0.4367\n",
      "Epoch 2542/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2771 - accuracy: 0.9300 - val_loss: 3.7744 - val_accuracy: 0.4467\n",
      "Epoch 2543/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2766 - accuracy: 0.9286 - val_loss: 3.7697 - val_accuracy: 0.4400\n",
      "Epoch 2544/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2773 - accuracy: 0.9300 - val_loss: 3.7645 - val_accuracy: 0.4367\n",
      "Epoch 2545/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2769 - accuracy: 0.9300 - val_loss: 3.7736 - val_accuracy: 0.4400\n",
      "Epoch 2546/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2766 - accuracy: 0.9286 - val_loss: 3.7661 - val_accuracy: 0.4367\n",
      "Epoch 2547/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2764 - accuracy: 0.9286 - val_loss: 3.7715 - val_accuracy: 0.4400\n",
      "Epoch 2548/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2766 - accuracy: 0.9300 - val_loss: 3.7605 - val_accuracy: 0.4367\n",
      "Epoch 2549/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2773 - accuracy: 0.9286 - val_loss: 3.7690 - val_accuracy: 0.4367\n",
      "Epoch 2550/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2766 - accuracy: 0.9286 - val_loss: 3.7739 - val_accuracy: 0.4367\n",
      "Epoch 2551/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2766 - accuracy: 0.9286 - val_loss: 3.7594 - val_accuracy: 0.4400\n",
      "Epoch 2552/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2766 - accuracy: 0.9300 - val_loss: 3.7584 - val_accuracy: 0.4333\n",
      "Epoch 2553/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2770 - accuracy: 0.9300 - val_loss: 3.7780 - val_accuracy: 0.4400\n",
      "Epoch 2554/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2767 - accuracy: 0.9286 - val_loss: 3.7607 - val_accuracy: 0.4333\n",
      "Epoch 2555/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2764 - accuracy: 0.9286 - val_loss: 3.7577 - val_accuracy: 0.4367\n",
      "Epoch 2556/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2764 - accuracy: 0.9300 - val_loss: 3.7412 - val_accuracy: 0.4333\n",
      "Epoch 2557/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2763 - accuracy: 0.9286 - val_loss: 3.7648 - val_accuracy: 0.4367\n",
      "Epoch 2558/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2765 - accuracy: 0.9286 - val_loss: 3.7652 - val_accuracy: 0.4367\n",
      "Epoch 2559/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2768 - accuracy: 0.9300 - val_loss: 3.7797 - val_accuracy: 0.4433\n",
      "Epoch 2560/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2763 - accuracy: 0.9300 - val_loss: 3.7627 - val_accuracy: 0.4333\n",
      "Epoch 2561/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2760 - accuracy: 0.9286 - val_loss: 3.7934 - val_accuracy: 0.4400\n",
      "Epoch 2562/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2762 - accuracy: 0.9300 - val_loss: 3.7701 - val_accuracy: 0.4367\n",
      "Epoch 2563/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2765 - accuracy: 0.9300 - val_loss: 3.7760 - val_accuracy: 0.4367\n",
      "Epoch 2564/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2763 - accuracy: 0.9300 - val_loss: 3.7816 - val_accuracy: 0.4367\n",
      "Epoch 2565/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2760 - accuracy: 0.9300 - val_loss: 3.7687 - val_accuracy: 0.4367\n",
      "Epoch 2566/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2766 - accuracy: 0.9300 - val_loss: 3.7671 - val_accuracy: 0.4367\n",
      "Epoch 2567/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2760 - accuracy: 0.9300 - val_loss: 3.7689 - val_accuracy: 0.4367\n",
      "Epoch 2568/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2758 - accuracy: 0.9300 - val_loss: 3.7751 - val_accuracy: 0.4367\n",
      "Epoch 2569/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2761 - accuracy: 0.9300 - val_loss: 3.7841 - val_accuracy: 0.4400\n",
      "Epoch 2570/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2759 - accuracy: 0.9300 - val_loss: 3.7602 - val_accuracy: 0.4333\n",
      "Epoch 2571/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2758 - accuracy: 0.9286 - val_loss: 3.7753 - val_accuracy: 0.4367\n",
      "Epoch 2572/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2760 - accuracy: 0.9300 - val_loss: 3.7829 - val_accuracy: 0.4367\n",
      "Epoch 2573/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2759 - accuracy: 0.9300 - val_loss: 3.7738 - val_accuracy: 0.4333\n",
      "Epoch 2574/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2758 - accuracy: 0.9300 - val_loss: 3.7801 - val_accuracy: 0.4367\n",
      "Epoch 2575/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2759 - accuracy: 0.9300 - val_loss: 3.8043 - val_accuracy: 0.4400\n",
      "Epoch 2576/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2759 - accuracy: 0.9300 - val_loss: 3.7982 - val_accuracy: 0.4367\n",
      "Epoch 2577/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2756 - accuracy: 0.9300 - val_loss: 3.7972 - val_accuracy: 0.4400\n",
      "Epoch 2578/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2756 - accuracy: 0.9300 - val_loss: 3.7670 - val_accuracy: 0.4367\n",
      "Epoch 2579/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2756 - accuracy: 0.9300 - val_loss: 3.7707 - val_accuracy: 0.4333\n",
      "Epoch 2580/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2757 - accuracy: 0.9300 - val_loss: 3.7929 - val_accuracy: 0.4367\n",
      "Epoch 2581/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2759 - accuracy: 0.9300 - val_loss: 3.7843 - val_accuracy: 0.4400\n",
      "Epoch 2582/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2754 - accuracy: 0.9300 - val_loss: 3.7969 - val_accuracy: 0.4400\n",
      "Epoch 2583/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2757 - accuracy: 0.9286 - val_loss: 3.7950 - val_accuracy: 0.4400\n",
      "Epoch 2584/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2756 - accuracy: 0.9300 - val_loss: 3.7800 - val_accuracy: 0.4333\n",
      "Epoch 2585/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2758 - accuracy: 0.9300 - val_loss: 3.7966 - val_accuracy: 0.4433\n",
      "Epoch 2586/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2754 - accuracy: 0.9300 - val_loss: 3.7985 - val_accuracy: 0.4333\n",
      "Epoch 2587/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2750 - accuracy: 0.9300 - val_loss: 3.8029 - val_accuracy: 0.4333\n",
      "Epoch 2588/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2751 - accuracy: 0.9300 - val_loss: 3.7639 - val_accuracy: 0.4400\n",
      "Epoch 2589/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2759 - accuracy: 0.9300 - val_loss: 3.7886 - val_accuracy: 0.4333\n",
      "Epoch 2590/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2752 - accuracy: 0.9286 - val_loss: 3.8029 - val_accuracy: 0.4333\n",
      "Epoch 2591/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2755 - accuracy: 0.9286 - val_loss: 3.7871 - val_accuracy: 0.4367\n",
      "Epoch 2592/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 0.2752 - accuracy: 0.9300 - val_loss: 3.7880 - val_accuracy: 0.4367\n",
      "Epoch 2593/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2755 - accuracy: 0.9300 - val_loss: 3.7823 - val_accuracy: 0.4333\n",
      "Epoch 2594/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2752 - accuracy: 0.9300 - val_loss: 3.8165 - val_accuracy: 0.4400\n",
      "Epoch 2595/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 0.2754 - accuracy: 0.9286 - val_loss: 3.7818 - val_accuracy: 0.4367\n",
      "Epoch 2596/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2754 - accuracy: 0.9300 - val_loss: 3.8090 - val_accuracy: 0.4433\n",
      "Epoch 2597/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2751 - accuracy: 0.9300 - val_loss: 3.7756 - val_accuracy: 0.4333\n",
      "Epoch 2598/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2750 - accuracy: 0.9300 - val_loss: 3.8043 - val_accuracy: 0.4400\n",
      "Epoch 2599/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2751 - accuracy: 0.9300 - val_loss: 3.8032 - val_accuracy: 0.4367\n",
      "Epoch 2600/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2746 - accuracy: 0.9286 - val_loss: 3.8260 - val_accuracy: 0.4400\n",
      "Epoch 2601/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2749 - accuracy: 0.9300 - val_loss: 3.8225 - val_accuracy: 0.4400\n",
      "Epoch 2602/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2754 - accuracy: 0.9286 - val_loss: 3.8005 - val_accuracy: 0.4333\n",
      "Epoch 2603/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2746 - accuracy: 0.9300 - val_loss: 3.7930 - val_accuracy: 0.4367\n",
      "Epoch 2604/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2745 - accuracy: 0.9286 - val_loss: 3.7670 - val_accuracy: 0.4367\n",
      "Epoch 2605/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2749 - accuracy: 0.9300 - val_loss: 3.8012 - val_accuracy: 0.4400\n",
      "Epoch 2606/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2747 - accuracy: 0.9300 - val_loss: 3.7817 - val_accuracy: 0.4333\n",
      "Epoch 2607/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2747 - accuracy: 0.9300 - val_loss: 3.7899 - val_accuracy: 0.4333\n",
      "Epoch 2608/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2744 - accuracy: 0.9300 - val_loss: 3.7903 - val_accuracy: 0.4333\n",
      "Epoch 2609/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2747 - accuracy: 0.9300 - val_loss: 3.8312 - val_accuracy: 0.4400\n",
      "Epoch 2610/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2748 - accuracy: 0.9300 - val_loss: 3.8016 - val_accuracy: 0.4367\n",
      "Epoch 2611/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2751 - accuracy: 0.9286 - val_loss: 3.8006 - val_accuracy: 0.4333\n",
      "Epoch 2612/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2745 - accuracy: 0.9300 - val_loss: 3.8167 - val_accuracy: 0.4333\n",
      "Epoch 2613/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2743 - accuracy: 0.9300 - val_loss: 3.8042 - val_accuracy: 0.4367\n",
      "Epoch 2614/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2750 - accuracy: 0.9300 - val_loss: 3.8181 - val_accuracy: 0.4333\n",
      "Epoch 2615/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2743 - accuracy: 0.9300 - val_loss: 3.8254 - val_accuracy: 0.4333\n",
      "Epoch 2616/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2746 - accuracy: 0.9300 - val_loss: 3.8025 - val_accuracy: 0.4367\n",
      "Epoch 2617/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2743 - accuracy: 0.9300 - val_loss: 3.8235 - val_accuracy: 0.4367\n",
      "Epoch 2618/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2745 - accuracy: 0.9300 - val_loss: 3.8146 - val_accuracy: 0.4367\n",
      "Epoch 2619/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2744 - accuracy: 0.9286 - val_loss: 3.8213 - val_accuracy: 0.4400\n",
      "Epoch 2620/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2745 - accuracy: 0.9300 - val_loss: 3.8218 - val_accuracy: 0.4400\n",
      "Epoch 2621/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2744 - accuracy: 0.9300 - val_loss: 3.8296 - val_accuracy: 0.4400\n",
      "Epoch 2622/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2737 - accuracy: 0.9300 - val_loss: 3.8294 - val_accuracy: 0.4367\n",
      "Epoch 2623/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2750 - accuracy: 0.9300 - val_loss: 3.8084 - val_accuracy: 0.4333\n",
      "Epoch 2624/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2745 - accuracy: 0.9300 - val_loss: 3.8152 - val_accuracy: 0.4367\n",
      "Epoch 2625/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2740 - accuracy: 0.9286 - val_loss: 3.8075 - val_accuracy: 0.4333\n",
      "Epoch 2626/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2743 - accuracy: 0.9300 - val_loss: 3.8282 - val_accuracy: 0.4367\n",
      "Epoch 2627/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2740 - accuracy: 0.9286 - val_loss: 3.8257 - val_accuracy: 0.4400\n",
      "Epoch 2628/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.2743 - accuracy: 0.9300 - val_loss: 3.8210 - val_accuracy: 0.4367\n",
      "Epoch 2629/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2739 - accuracy: 0.9300 - val_loss: 3.8176 - val_accuracy: 0.4333\n",
      "Epoch 2630/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2736 - accuracy: 0.9300 - val_loss: 3.8236 - val_accuracy: 0.4333\n",
      "Epoch 2631/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2740 - accuracy: 0.9300 - val_loss: 3.8249 - val_accuracy: 0.4333\n",
      "Epoch 2632/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2741 - accuracy: 0.9300 - val_loss: 3.8211 - val_accuracy: 0.4367\n",
      "Epoch 2633/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2738 - accuracy: 0.9286 - val_loss: 3.8279 - val_accuracy: 0.4367\n",
      "Epoch 2634/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2737 - accuracy: 0.9300 - val_loss: 3.8335 - val_accuracy: 0.4367\n",
      "Epoch 2635/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2738 - accuracy: 0.9300 - val_loss: 3.8233 - val_accuracy: 0.4333\n",
      "Epoch 2636/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2743 - accuracy: 0.9300 - val_loss: 3.8383 - val_accuracy: 0.4400\n",
      "Epoch 2637/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2742 - accuracy: 0.9300 - val_loss: 3.8386 - val_accuracy: 0.4333\n",
      "Epoch 2638/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2735 - accuracy: 0.9300 - val_loss: 3.8388 - val_accuracy: 0.4367\n",
      "Epoch 2639/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2742 - accuracy: 0.9300 - val_loss: 3.8313 - val_accuracy: 0.4333\n",
      "Epoch 2640/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2735 - accuracy: 0.9300 - val_loss: 3.8156 - val_accuracy: 0.4333\n",
      "Epoch 2641/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2737 - accuracy: 0.9300 - val_loss: 3.8301 - val_accuracy: 0.4367\n",
      "Epoch 2642/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2737 - accuracy: 0.9286 - val_loss: 3.8152 - val_accuracy: 0.4333\n",
      "Epoch 2643/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2735 - accuracy: 0.9300 - val_loss: 3.8151 - val_accuracy: 0.4333\n",
      "Epoch 2644/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2738 - accuracy: 0.9286 - val_loss: 3.8255 - val_accuracy: 0.4333\n",
      "Epoch 2645/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2734 - accuracy: 0.9300 - val_loss: 3.8409 - val_accuracy: 0.4333\n",
      "Epoch 2646/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2736 - accuracy: 0.9286 - val_loss: 3.8260 - val_accuracy: 0.4333\n",
      "Epoch 2647/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2734 - accuracy: 0.9300 - val_loss: 3.8464 - val_accuracy: 0.4400\n",
      "Epoch 2648/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2737 - accuracy: 0.9300 - val_loss: 3.8376 - val_accuracy: 0.4400\n",
      "Epoch 2649/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2737 - accuracy: 0.9300 - val_loss: 3.8466 - val_accuracy: 0.4300\n",
      "Epoch 2650/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.2737 - accuracy: 0.9286 - val_loss: 3.8512 - val_accuracy: 0.4333\n",
      "Epoch 2651/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2734 - accuracy: 0.9286 - val_loss: 3.8265 - val_accuracy: 0.4333\n",
      "Epoch 2652/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2732 - accuracy: 0.9300 - val_loss: 3.8544 - val_accuracy: 0.4333\n",
      "Epoch 2653/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2736 - accuracy: 0.9286 - val_loss: 3.8447 - val_accuracy: 0.4333\n",
      "Epoch 2654/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2733 - accuracy: 0.9300 - val_loss: 3.8311 - val_accuracy: 0.4333\n",
      "Epoch 2655/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2736 - accuracy: 0.9300 - val_loss: 3.8446 - val_accuracy: 0.4367\n",
      "Epoch 2656/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2733 - accuracy: 0.9286 - val_loss: 3.8515 - val_accuracy: 0.4333\n",
      "Epoch 2657/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2727 - accuracy: 0.9300 - val_loss: 3.8397 - val_accuracy: 0.4333\n",
      "Epoch 2658/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2735 - accuracy: 0.9300 - val_loss: 3.8324 - val_accuracy: 0.4300\n",
      "Epoch 2659/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2731 - accuracy: 0.9300 - val_loss: 3.8517 - val_accuracy: 0.4333\n",
      "Epoch 2660/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2731 - accuracy: 0.9300 - val_loss: 3.8716 - val_accuracy: 0.4367\n",
      "Epoch 2661/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2733 - accuracy: 0.9286 - val_loss: 3.8555 - val_accuracy: 0.4300\n",
      "Epoch 2662/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2731 - accuracy: 0.9300 - val_loss: 3.8532 - val_accuracy: 0.4333\n",
      "Epoch 2663/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2729 - accuracy: 0.9300 - val_loss: 3.8587 - val_accuracy: 0.4367\n",
      "Epoch 2664/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2735 - accuracy: 0.9300 - val_loss: 3.8629 - val_accuracy: 0.4333\n",
      "Epoch 2665/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2731 - accuracy: 0.9300 - val_loss: 3.8435 - val_accuracy: 0.4367\n",
      "Epoch 2666/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2729 - accuracy: 0.9300 - val_loss: 3.8413 - val_accuracy: 0.4333\n",
      "Epoch 2667/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2729 - accuracy: 0.9300 - val_loss: 3.8589 - val_accuracy: 0.4300\n",
      "Epoch 2668/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2730 - accuracy: 0.9300 - val_loss: 3.8573 - val_accuracy: 0.4300\n",
      "Epoch 2669/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2727 - accuracy: 0.9300 - val_loss: 3.8484 - val_accuracy: 0.4333\n",
      "Epoch 2670/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2725 - accuracy: 0.9300 - val_loss: 3.8471 - val_accuracy: 0.4367\n",
      "Epoch 2671/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2725 - accuracy: 0.9286 - val_loss: 3.8467 - val_accuracy: 0.4333\n",
      "Epoch 2672/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2730 - accuracy: 0.9300 - val_loss: 3.8622 - val_accuracy: 0.4333\n",
      "Epoch 2673/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2727 - accuracy: 0.9286 - val_loss: 3.8683 - val_accuracy: 0.4367\n",
      "Epoch 2674/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2727 - accuracy: 0.9300 - val_loss: 3.8652 - val_accuracy: 0.4367\n",
      "Epoch 2675/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2727 - accuracy: 0.9300 - val_loss: 3.8642 - val_accuracy: 0.4400\n",
      "Epoch 2676/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2726 - accuracy: 0.9300 - val_loss: 3.8813 - val_accuracy: 0.4400\n",
      "Epoch 2677/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2729 - accuracy: 0.9300 - val_loss: 3.8470 - val_accuracy: 0.4300\n",
      "Epoch 2678/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2725 - accuracy: 0.9300 - val_loss: 3.8640 - val_accuracy: 0.4333\n",
      "Epoch 2679/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2726 - accuracy: 0.9300 - val_loss: 3.8460 - val_accuracy: 0.4333\n",
      "Epoch 2680/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2722 - accuracy: 0.9286 - val_loss: 3.8283 - val_accuracy: 0.4333\n",
      "Epoch 2681/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2725 - accuracy: 0.9300 - val_loss: 3.8503 - val_accuracy: 0.4333\n",
      "Epoch 2682/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2725 - accuracy: 0.9300 - val_loss: 3.8441 - val_accuracy: 0.4333\n",
      "Epoch 2683/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2721 - accuracy: 0.9300 - val_loss: 3.8562 - val_accuracy: 0.4333\n",
      "Epoch 2684/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2724 - accuracy: 0.9300 - val_loss: 3.8543 - val_accuracy: 0.4367\n",
      "Epoch 2685/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2720 - accuracy: 0.9300 - val_loss: 3.8490 - val_accuracy: 0.4333\n",
      "Epoch 2686/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2728 - accuracy: 0.9300 - val_loss: 3.8503 - val_accuracy: 0.4333\n",
      "Epoch 2687/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2719 - accuracy: 0.9300 - val_loss: 3.8605 - val_accuracy: 0.4367\n",
      "Epoch 2688/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2721 - accuracy: 0.9300 - val_loss: 3.8771 - val_accuracy: 0.4367\n",
      "Epoch 2689/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2722 - accuracy: 0.9300 - val_loss: 3.8718 - val_accuracy: 0.4367\n",
      "Epoch 2690/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2722 - accuracy: 0.9300 - val_loss: 3.8764 - val_accuracy: 0.4400\n",
      "Epoch 2691/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2722 - accuracy: 0.9300 - val_loss: 3.8624 - val_accuracy: 0.4333\n",
      "Epoch 2692/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2718 - accuracy: 0.9286 - val_loss: 3.8440 - val_accuracy: 0.4333\n",
      "Epoch 2693/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2716 - accuracy: 0.9300 - val_loss: 3.8637 - val_accuracy: 0.4333\n",
      "Epoch 2694/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2718 - accuracy: 0.9300 - val_loss: 3.8657 - val_accuracy: 0.4300\n",
      "Epoch 2695/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2722 - accuracy: 0.9300 - val_loss: 3.8643 - val_accuracy: 0.4333\n",
      "Epoch 2696/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2721 - accuracy: 0.9300 - val_loss: 3.8676 - val_accuracy: 0.4333\n",
      "Epoch 2697/3000\n",
      "700/700 [==============================] - 0s 84us/step - loss: 0.2722 - accuracy: 0.9300 - val_loss: 3.8896 - val_accuracy: 0.4333\n",
      "Epoch 2698/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2718 - accuracy: 0.9300 - val_loss: 3.8615 - val_accuracy: 0.4300\n",
      "Epoch 2699/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2718 - accuracy: 0.9300 - val_loss: 3.8802 - val_accuracy: 0.4333\n",
      "Epoch 2700/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2714 - accuracy: 0.9300 - val_loss: 3.8671 - val_accuracy: 0.4367\n",
      "Epoch 2701/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2717 - accuracy: 0.9300 - val_loss: 3.8580 - val_accuracy: 0.4267\n",
      "Epoch 2702/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2721 - accuracy: 0.9300 - val_loss: 3.8899 - val_accuracy: 0.4367\n",
      "Epoch 2703/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2720 - accuracy: 0.9300 - val_loss: 3.8793 - val_accuracy: 0.4300\n",
      "Epoch 2704/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2717 - accuracy: 0.9300 - val_loss: 3.8750 - val_accuracy: 0.4333\n",
      "Epoch 2705/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.2718 - accuracy: 0.9300 - val_loss: 3.8846 - val_accuracy: 0.4333\n",
      "Epoch 2706/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2714 - accuracy: 0.9300 - val_loss: 3.8832 - val_accuracy: 0.4333\n",
      "Epoch 2707/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2715 - accuracy: 0.9300 - val_loss: 3.8678 - val_accuracy: 0.4300\n",
      "Epoch 2708/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2717 - accuracy: 0.9300 - val_loss: 3.8895 - val_accuracy: 0.4333\n",
      "Epoch 2709/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2719 - accuracy: 0.9300 - val_loss: 3.8842 - val_accuracy: 0.4333\n",
      "Epoch 2710/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2713 - accuracy: 0.9300 - val_loss: 3.8746 - val_accuracy: 0.4333\n",
      "Epoch 2711/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2716 - accuracy: 0.9286 - val_loss: 3.8541 - val_accuracy: 0.4300\n",
      "Epoch 2712/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2719 - accuracy: 0.9300 - val_loss: 3.8810 - val_accuracy: 0.4333\n",
      "Epoch 2713/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2715 - accuracy: 0.9300 - val_loss: 3.8782 - val_accuracy: 0.4300\n",
      "Epoch 2714/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2715 - accuracy: 0.9300 - val_loss: 3.8824 - val_accuracy: 0.4333\n",
      "Epoch 2715/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2716 - accuracy: 0.9300 - val_loss: 3.8845 - val_accuracy: 0.4333\n",
      "Epoch 2716/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2714 - accuracy: 0.9300 - val_loss: 3.8962 - val_accuracy: 0.4300\n",
      "Epoch 2717/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2708 - accuracy: 0.9300 - val_loss: 3.8984 - val_accuracy: 0.4300\n",
      "Epoch 2718/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2712 - accuracy: 0.9300 - val_loss: 3.8847 - val_accuracy: 0.4333\n",
      "Epoch 2719/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2716 - accuracy: 0.9300 - val_loss: 3.8914 - val_accuracy: 0.4333\n",
      "Epoch 2720/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2714 - accuracy: 0.9300 - val_loss: 3.8755 - val_accuracy: 0.4300\n",
      "Epoch 2721/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2713 - accuracy: 0.9300 - val_loss: 3.8835 - val_accuracy: 0.4300\n",
      "Epoch 2722/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2711 - accuracy: 0.9300 - val_loss: 3.8983 - val_accuracy: 0.4333\n",
      "Epoch 2723/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2713 - accuracy: 0.9300 - val_loss: 3.8668 - val_accuracy: 0.4333\n",
      "Epoch 2724/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2712 - accuracy: 0.9300 - val_loss: 3.8961 - val_accuracy: 0.4333\n",
      "Epoch 2725/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2710 - accuracy: 0.9300 - val_loss: 3.8880 - val_accuracy: 0.4367\n",
      "Epoch 2726/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2710 - accuracy: 0.9300 - val_loss: 3.8981 - val_accuracy: 0.4367\n",
      "Epoch 2727/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2711 - accuracy: 0.9300 - val_loss: 3.8972 - val_accuracy: 0.4300\n",
      "Epoch 2728/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2710 - accuracy: 0.9300 - val_loss: 3.8957 - val_accuracy: 0.4333\n",
      "Epoch 2729/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2714 - accuracy: 0.9300 - val_loss: 3.8857 - val_accuracy: 0.4300\n",
      "Epoch 2730/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2711 - accuracy: 0.9300 - val_loss: 3.9090 - val_accuracy: 0.4333\n",
      "Epoch 2731/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2708 - accuracy: 0.9300 - val_loss: 3.8887 - val_accuracy: 0.4300\n",
      "Epoch 2732/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2713 - accuracy: 0.9300 - val_loss: 3.9074 - val_accuracy: 0.4333\n",
      "Epoch 2733/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2709 - accuracy: 0.9300 - val_loss: 3.9125 - val_accuracy: 0.4300\n",
      "Epoch 2734/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2708 - accuracy: 0.9300 - val_loss: 3.8963 - val_accuracy: 0.4300\n",
      "Epoch 2735/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2707 - accuracy: 0.9300 - val_loss: 3.9098 - val_accuracy: 0.4267\n",
      "Epoch 2736/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2710 - accuracy: 0.9300 - val_loss: 3.9169 - val_accuracy: 0.4333\n",
      "Epoch 2737/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2709 - accuracy: 0.9300 - val_loss: 3.9019 - val_accuracy: 0.4300\n",
      "Epoch 2738/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2706 - accuracy: 0.9300 - val_loss: 3.9101 - val_accuracy: 0.4267\n",
      "Epoch 2739/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2706 - accuracy: 0.9300 - val_loss: 3.9072 - val_accuracy: 0.4333\n",
      "Epoch 2740/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2704 - accuracy: 0.9300 - val_loss: 3.9038 - val_accuracy: 0.4333\n",
      "Epoch 2741/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2705 - accuracy: 0.9300 - val_loss: 3.8956 - val_accuracy: 0.4300\n",
      "Epoch 2742/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2703 - accuracy: 0.9300 - val_loss: 3.8989 - val_accuracy: 0.4333\n",
      "Epoch 2743/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2705 - accuracy: 0.9300 - val_loss: 3.9023 - val_accuracy: 0.4300\n",
      "Epoch 2744/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2705 - accuracy: 0.9300 - val_loss: 3.8943 - val_accuracy: 0.4300\n",
      "Epoch 2745/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2707 - accuracy: 0.9300 - val_loss: 3.9225 - val_accuracy: 0.4367\n",
      "Epoch 2746/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2709 - accuracy: 0.9300 - val_loss: 3.9153 - val_accuracy: 0.4333\n",
      "Epoch 2747/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2707 - accuracy: 0.9300 - val_loss: 3.9180 - val_accuracy: 0.4333\n",
      "Epoch 2748/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2704 - accuracy: 0.9300 - val_loss: 3.9083 - val_accuracy: 0.4333\n",
      "Epoch 2749/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2702 - accuracy: 0.9300 - val_loss: 3.9117 - val_accuracy: 0.4333\n",
      "Epoch 2750/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2706 - accuracy: 0.9300 - val_loss: 3.9116 - val_accuracy: 0.4333\n",
      "Epoch 2751/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2706 - accuracy: 0.9300 - val_loss: 3.9184 - val_accuracy: 0.4333\n",
      "Epoch 2752/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2707 - accuracy: 0.9300 - val_loss: 3.9202 - val_accuracy: 0.4300\n",
      "Epoch 2753/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2703 - accuracy: 0.9300 - val_loss: 3.8881 - val_accuracy: 0.4300\n",
      "Epoch 2754/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2699 - accuracy: 0.9300 - val_loss: 3.9057 - val_accuracy: 0.4300\n",
      "Epoch 2755/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2702 - accuracy: 0.9300 - val_loss: 3.9353 - val_accuracy: 0.4333\n",
      "Epoch 2756/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2704 - accuracy: 0.9300 - val_loss: 3.8934 - val_accuracy: 0.4400\n",
      "Epoch 2757/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2703 - accuracy: 0.9286 - val_loss: 3.9149 - val_accuracy: 0.4300\n",
      "Epoch 2758/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2702 - accuracy: 0.9300 - val_loss: 3.9253 - val_accuracy: 0.4333\n",
      "Epoch 2759/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.2701 - accuracy: 0.9300 - val_loss: 3.9271 - val_accuracy: 0.4267\n",
      "Epoch 2760/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 94us/step - loss: 0.2703 - accuracy: 0.9300 - val_loss: 3.9116 - val_accuracy: 0.4267\n",
      "Epoch 2761/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2698 - accuracy: 0.9300 - val_loss: 3.9068 - val_accuracy: 0.4300\n",
      "Epoch 2762/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2702 - accuracy: 0.9300 - val_loss: 3.9145 - val_accuracy: 0.4300\n",
      "Epoch 2763/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2699 - accuracy: 0.9300 - val_loss: 3.9267 - val_accuracy: 0.4300\n",
      "Epoch 2764/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2699 - accuracy: 0.9300 - val_loss: 3.9241 - val_accuracy: 0.4333\n",
      "Epoch 2765/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2703 - accuracy: 0.9300 - val_loss: 3.9048 - val_accuracy: 0.4300\n",
      "Epoch 2766/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2698 - accuracy: 0.9300 - val_loss: 3.9208 - val_accuracy: 0.4300\n",
      "Epoch 2767/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2696 - accuracy: 0.9300 - val_loss: 3.9423 - val_accuracy: 0.4367\n",
      "Epoch 2768/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2699 - accuracy: 0.9300 - val_loss: 3.9251 - val_accuracy: 0.4333\n",
      "Epoch 2769/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2695 - accuracy: 0.9300 - val_loss: 3.9019 - val_accuracy: 0.4333\n",
      "Epoch 2770/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2698 - accuracy: 0.9300 - val_loss: 3.9148 - val_accuracy: 0.4300\n",
      "Epoch 2771/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2704 - accuracy: 0.9300 - val_loss: 3.9249 - val_accuracy: 0.4333\n",
      "Epoch 2772/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2696 - accuracy: 0.9300 - val_loss: 3.9222 - val_accuracy: 0.4300\n",
      "Epoch 2773/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2695 - accuracy: 0.9300 - val_loss: 3.9399 - val_accuracy: 0.4300\n",
      "Epoch 2774/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2694 - accuracy: 0.9300 - val_loss: 3.9347 - val_accuracy: 0.4333\n",
      "Epoch 2775/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2697 - accuracy: 0.9300 - val_loss: 3.9185 - val_accuracy: 0.4300\n",
      "Epoch 2776/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2698 - accuracy: 0.9300 - val_loss: 3.9409 - val_accuracy: 0.4333\n",
      "Epoch 2777/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2695 - accuracy: 0.9300 - val_loss: 3.9239 - val_accuracy: 0.4300\n",
      "Epoch 2778/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2694 - accuracy: 0.9300 - val_loss: 3.9507 - val_accuracy: 0.4367\n",
      "Epoch 2779/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2694 - accuracy: 0.9300 - val_loss: 3.9302 - val_accuracy: 0.4267\n",
      "Epoch 2780/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2697 - accuracy: 0.9300 - val_loss: 3.9109 - val_accuracy: 0.4267\n",
      "Epoch 2781/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2691 - accuracy: 0.9300 - val_loss: 3.9355 - val_accuracy: 0.4333\n",
      "Epoch 2782/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2692 - accuracy: 0.9300 - val_loss: 3.9540 - val_accuracy: 0.4333\n",
      "Epoch 2783/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2698 - accuracy: 0.9300 - val_loss: 3.9502 - val_accuracy: 0.4333\n",
      "Epoch 2784/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2695 - accuracy: 0.9300 - val_loss: 3.9358 - val_accuracy: 0.4267\n",
      "Epoch 2785/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2693 - accuracy: 0.9300 - val_loss: 3.9447 - val_accuracy: 0.4333\n",
      "Epoch 2786/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2691 - accuracy: 0.9300 - val_loss: 3.9456 - val_accuracy: 0.4300\n",
      "Epoch 2787/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2694 - accuracy: 0.9300 - val_loss: 3.9351 - val_accuracy: 0.4267\n",
      "Epoch 2788/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2690 - accuracy: 0.9300 - val_loss: 3.9501 - val_accuracy: 0.4333\n",
      "Epoch 2789/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2690 - accuracy: 0.9300 - val_loss: 3.9378 - val_accuracy: 0.4267\n",
      "Epoch 2790/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2691 - accuracy: 0.9300 - val_loss: 3.9577 - val_accuracy: 0.4333\n",
      "Epoch 2791/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2689 - accuracy: 0.9300 - val_loss: 3.9653 - val_accuracy: 0.4367\n",
      "Epoch 2792/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2694 - accuracy: 0.9300 - val_loss: 3.9367 - val_accuracy: 0.4267\n",
      "Epoch 2793/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2690 - accuracy: 0.9300 - val_loss: 3.9389 - val_accuracy: 0.4333\n",
      "Epoch 2794/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2686 - accuracy: 0.9300 - val_loss: 3.9352 - val_accuracy: 0.4300\n",
      "Epoch 2795/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2696 - accuracy: 0.9300 - val_loss: 3.9439 - val_accuracy: 0.4333\n",
      "Epoch 2796/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2692 - accuracy: 0.9300 - val_loss: 3.9485 - val_accuracy: 0.4300\n",
      "Epoch 2797/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2691 - accuracy: 0.9300 - val_loss: 3.9342 - val_accuracy: 0.4300\n",
      "Epoch 2798/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2690 - accuracy: 0.9300 - val_loss: 3.9457 - val_accuracy: 0.4267\n",
      "Epoch 2799/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2688 - accuracy: 0.9300 - val_loss: 3.9600 - val_accuracy: 0.4267\n",
      "Epoch 2800/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2691 - accuracy: 0.9300 - val_loss: 3.9412 - val_accuracy: 0.4300\n",
      "Epoch 2801/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2687 - accuracy: 0.9300 - val_loss: 3.9495 - val_accuracy: 0.4267\n",
      "Epoch 2802/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2691 - accuracy: 0.9300 - val_loss: 3.9507 - val_accuracy: 0.4300\n",
      "Epoch 2803/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2687 - accuracy: 0.9300 - val_loss: 3.9399 - val_accuracy: 0.4267\n",
      "Epoch 2804/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2687 - accuracy: 0.9300 - val_loss: 3.9597 - val_accuracy: 0.4333\n",
      "Epoch 2805/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2684 - accuracy: 0.9300 - val_loss: 3.9327 - val_accuracy: 0.4267\n",
      "Epoch 2806/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2686 - accuracy: 0.9300 - val_loss: 3.9595 - val_accuracy: 0.4300\n",
      "Epoch 2807/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2689 - accuracy: 0.9300 - val_loss: 3.9461 - val_accuracy: 0.4300\n",
      "Epoch 2808/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2685 - accuracy: 0.9300 - val_loss: 3.9615 - val_accuracy: 0.4333\n",
      "Epoch 2809/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2687 - accuracy: 0.9300 - val_loss: 3.9527 - val_accuracy: 0.4267\n",
      "Epoch 2810/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2684 - accuracy: 0.9300 - val_loss: 3.9767 - val_accuracy: 0.4367\n",
      "Epoch 2811/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2687 - accuracy: 0.9300 - val_loss: 3.9696 - val_accuracy: 0.4333\n",
      "Epoch 2812/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2686 - accuracy: 0.9300 - val_loss: 3.9330 - val_accuracy: 0.4300\n",
      "Epoch 2813/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2686 - accuracy: 0.9300 - val_loss: 3.9630 - val_accuracy: 0.4300\n",
      "Epoch 2814/3000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 0.2683 - accuracy: 0.9300 - val_loss: 3.9282 - val_accuracy: 0.4367\n",
      "Epoch 2815/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 96us/step - loss: 0.2685 - accuracy: 0.9300 - val_loss: 3.9722 - val_accuracy: 0.4333\n",
      "Epoch 2816/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2684 - accuracy: 0.9300 - val_loss: 3.9328 - val_accuracy: 0.4300\n",
      "Epoch 2817/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2686 - accuracy: 0.9300 - val_loss: 3.9567 - val_accuracy: 0.4333\n",
      "Epoch 2818/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2683 - accuracy: 0.9300 - val_loss: 3.9389 - val_accuracy: 0.4267\n",
      "Epoch 2819/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2685 - accuracy: 0.9300 - val_loss: 3.9568 - val_accuracy: 0.4333\n",
      "Epoch 2820/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2684 - accuracy: 0.9300 - val_loss: 3.9665 - val_accuracy: 0.4333\n",
      "Epoch 2821/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2683 - accuracy: 0.9300 - val_loss: 3.9482 - val_accuracy: 0.4267\n",
      "Epoch 2822/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2684 - accuracy: 0.9300 - val_loss: 3.9565 - val_accuracy: 0.4267\n",
      "Epoch 2823/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2684 - accuracy: 0.9300 - val_loss: 3.9498 - val_accuracy: 0.4267\n",
      "Epoch 2824/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2684 - accuracy: 0.9300 - val_loss: 3.9566 - val_accuracy: 0.4267\n",
      "Epoch 2825/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2681 - accuracy: 0.9300 - val_loss: 3.9691 - val_accuracy: 0.4267\n",
      "Epoch 2826/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2681 - accuracy: 0.9300 - val_loss: 3.9682 - val_accuracy: 0.4267\n",
      "Epoch 2827/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2686 - accuracy: 0.9300 - val_loss: 3.9754 - val_accuracy: 0.4367\n",
      "Epoch 2828/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2683 - accuracy: 0.9300 - val_loss: 3.9557 - val_accuracy: 0.4267\n",
      "Epoch 2829/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2683 - accuracy: 0.9300 - val_loss: 3.9752 - val_accuracy: 0.4333\n",
      "Epoch 2830/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2682 - accuracy: 0.9300 - val_loss: 3.9638 - val_accuracy: 0.4300\n",
      "Epoch 2831/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2683 - accuracy: 0.9300 - val_loss: 3.9654 - val_accuracy: 0.4267\n",
      "Epoch 2832/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2682 - accuracy: 0.9300 - val_loss: 3.9664 - val_accuracy: 0.4267\n",
      "Epoch 2833/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2677 - accuracy: 0.9300 - val_loss: 3.9771 - val_accuracy: 0.4267\n",
      "Epoch 2834/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2680 - accuracy: 0.9300 - val_loss: 3.9690 - val_accuracy: 0.4267\n",
      "Epoch 2835/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2680 - accuracy: 0.9300 - val_loss: 3.9775 - val_accuracy: 0.4300\n",
      "Epoch 2836/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2680 - accuracy: 0.9300 - val_loss: 3.9875 - val_accuracy: 0.4333\n",
      "Epoch 2837/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2684 - accuracy: 0.9300 - val_loss: 4.0060 - val_accuracy: 0.4400\n",
      "Epoch 2838/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2679 - accuracy: 0.9300 - val_loss: 3.9625 - val_accuracy: 0.4267\n",
      "Epoch 2839/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2676 - accuracy: 0.9300 - val_loss: 3.9387 - val_accuracy: 0.4333\n",
      "Epoch 2840/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2678 - accuracy: 0.9300 - val_loss: 3.9612 - val_accuracy: 0.4333\n",
      "Epoch 2841/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2680 - accuracy: 0.9300 - val_loss: 3.9742 - val_accuracy: 0.4300\n",
      "Epoch 2842/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2675 - accuracy: 0.9300 - val_loss: 3.9535 - val_accuracy: 0.4333\n",
      "Epoch 2843/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2677 - accuracy: 0.9300 - val_loss: 3.9667 - val_accuracy: 0.4233\n",
      "Epoch 2844/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2679 - accuracy: 0.9300 - val_loss: 3.9686 - val_accuracy: 0.4267\n",
      "Epoch 2845/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2676 - accuracy: 0.9300 - val_loss: 3.9667 - val_accuracy: 0.4300\n",
      "Epoch 2846/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.2675 - accuracy: 0.9300 - val_loss: 3.9722 - val_accuracy: 0.4233\n",
      "Epoch 2847/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2674 - accuracy: 0.9300 - val_loss: 3.9832 - val_accuracy: 0.4267\n",
      "Epoch 2848/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2677 - accuracy: 0.9300 - val_loss: 3.9845 - val_accuracy: 0.4300\n",
      "Epoch 2849/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2676 - accuracy: 0.9300 - val_loss: 3.9716 - val_accuracy: 0.4267\n",
      "Epoch 2850/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2675 - accuracy: 0.9300 - val_loss: 3.9784 - val_accuracy: 0.4267\n",
      "Epoch 2851/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2676 - accuracy: 0.9300 - val_loss: 3.9622 - val_accuracy: 0.4267\n",
      "Epoch 2852/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2676 - accuracy: 0.9300 - val_loss: 3.9798 - val_accuracy: 0.4300\n",
      "Epoch 2853/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2671 - accuracy: 0.9300 - val_loss: 3.9541 - val_accuracy: 0.4333\n",
      "Epoch 2854/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2674 - accuracy: 0.9300 - val_loss: 3.9780 - val_accuracy: 0.4233\n",
      "Epoch 2855/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2672 - accuracy: 0.9300 - val_loss: 3.9764 - val_accuracy: 0.4267\n",
      "Epoch 2856/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2674 - accuracy: 0.9300 - val_loss: 3.9814 - val_accuracy: 0.4267\n",
      "Epoch 2857/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2674 - accuracy: 0.9300 - val_loss: 4.0016 - val_accuracy: 0.4300\n",
      "Epoch 2858/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2674 - accuracy: 0.9300 - val_loss: 3.9876 - val_accuracy: 0.4267\n",
      "Epoch 2859/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2670 - accuracy: 0.9300 - val_loss: 3.9960 - val_accuracy: 0.4300\n",
      "Epoch 2860/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2673 - accuracy: 0.9300 - val_loss: 3.9851 - val_accuracy: 0.4300\n",
      "Epoch 2861/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2672 - accuracy: 0.9300 - val_loss: 4.0154 - val_accuracy: 0.4333\n",
      "Epoch 2862/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2671 - accuracy: 0.9300 - val_loss: 3.9763 - val_accuracy: 0.4267\n",
      "Epoch 2863/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2671 - accuracy: 0.9300 - val_loss: 4.0001 - val_accuracy: 0.4267\n",
      "Epoch 2864/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2669 - accuracy: 0.9300 - val_loss: 3.9801 - val_accuracy: 0.4267\n",
      "Epoch 2865/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2675 - accuracy: 0.9300 - val_loss: 3.9708 - val_accuracy: 0.4267\n",
      "Epoch 2866/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2672 - accuracy: 0.9300 - val_loss: 3.9687 - val_accuracy: 0.4267\n",
      "Epoch 2867/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2673 - accuracy: 0.9300 - val_loss: 3.9927 - val_accuracy: 0.4300\n",
      "Epoch 2868/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2666 - accuracy: 0.9300 - val_loss: 3.9897 - val_accuracy: 0.4300\n",
      "Epoch 2869/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2670 - accuracy: 0.9300 - val_loss: 3.9991 - val_accuracy: 0.4300\n",
      "Epoch 2870/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 90us/step - loss: 0.2667 - accuracy: 0.9300 - val_loss: 3.9873 - val_accuracy: 0.4267\n",
      "Epoch 2871/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2674 - accuracy: 0.9300 - val_loss: 4.0033 - val_accuracy: 0.4300\n",
      "Epoch 2872/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2667 - accuracy: 0.9300 - val_loss: 3.9853 - val_accuracy: 0.4233\n",
      "Epoch 2873/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2669 - accuracy: 0.9300 - val_loss: 4.0147 - val_accuracy: 0.4333\n",
      "Epoch 2874/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2672 - accuracy: 0.9300 - val_loss: 4.0059 - val_accuracy: 0.4300\n",
      "Epoch 2875/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2671 - accuracy: 0.9300 - val_loss: 3.9903 - val_accuracy: 0.4267\n",
      "Epoch 2876/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2666 - accuracy: 0.9300 - val_loss: 3.9920 - val_accuracy: 0.4267\n",
      "Epoch 2877/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2668 - accuracy: 0.9300 - val_loss: 4.0056 - val_accuracy: 0.4300\n",
      "Epoch 2878/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2669 - accuracy: 0.9300 - val_loss: 4.0109 - val_accuracy: 0.4300\n",
      "Epoch 2879/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2671 - accuracy: 0.9300 - val_loss: 3.9978 - val_accuracy: 0.4267\n",
      "Epoch 2880/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2668 - accuracy: 0.9300 - val_loss: 3.9712 - val_accuracy: 0.4300\n",
      "Epoch 2881/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2665 - accuracy: 0.9300 - val_loss: 3.9750 - val_accuracy: 0.4267\n",
      "Epoch 2882/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2666 - accuracy: 0.9300 - val_loss: 3.9992 - val_accuracy: 0.4267\n",
      "Epoch 2883/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2664 - accuracy: 0.9300 - val_loss: 3.9963 - val_accuracy: 0.4233\n",
      "Epoch 2884/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2672 - accuracy: 0.9300 - val_loss: 3.9966 - val_accuracy: 0.4267\n",
      "Epoch 2885/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2667 - accuracy: 0.9300 - val_loss: 4.0100 - val_accuracy: 0.4300\n",
      "Epoch 2886/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2664 - accuracy: 0.9300 - val_loss: 3.9785 - val_accuracy: 0.4367\n",
      "Epoch 2887/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2666 - accuracy: 0.9300 - val_loss: 3.9616 - val_accuracy: 0.4267\n",
      "Epoch 2888/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2666 - accuracy: 0.9300 - val_loss: 4.0045 - val_accuracy: 0.4267\n",
      "Epoch 2889/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2664 - accuracy: 0.9300 - val_loss: 3.9952 - val_accuracy: 0.4267\n",
      "Epoch 2890/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2661 - accuracy: 0.9300 - val_loss: 3.9881 - val_accuracy: 0.4300\n",
      "Epoch 2891/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2666 - accuracy: 0.9300 - val_loss: 4.0032 - val_accuracy: 0.4267\n",
      "Epoch 2892/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2667 - accuracy: 0.9300 - val_loss: 4.0143 - val_accuracy: 0.4267\n",
      "Epoch 2893/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2662 - accuracy: 0.9300 - val_loss: 4.0097 - val_accuracy: 0.4267\n",
      "Epoch 2894/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2665 - accuracy: 0.9300 - val_loss: 3.9833 - val_accuracy: 0.4233\n",
      "Epoch 2895/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2666 - accuracy: 0.9300 - val_loss: 4.0134 - val_accuracy: 0.4267\n",
      "Epoch 2896/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2663 - accuracy: 0.9300 - val_loss: 4.0306 - val_accuracy: 0.4267\n",
      "Epoch 2897/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2668 - accuracy: 0.9300 - val_loss: 3.9955 - val_accuracy: 0.4267\n",
      "Epoch 2898/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2666 - accuracy: 0.9300 - val_loss: 4.0034 - val_accuracy: 0.4267\n",
      "Epoch 2899/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2660 - accuracy: 0.9300 - val_loss: 4.0031 - val_accuracy: 0.4233\n",
      "Epoch 2900/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2662 - accuracy: 0.9300 - val_loss: 4.0249 - val_accuracy: 0.4267\n",
      "Epoch 2901/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2665 - accuracy: 0.9300 - val_loss: 4.0147 - val_accuracy: 0.4267\n",
      "Epoch 2902/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2661 - accuracy: 0.9300 - val_loss: 4.0352 - val_accuracy: 0.4233\n",
      "Epoch 2903/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2665 - accuracy: 0.9300 - val_loss: 4.0050 - val_accuracy: 0.4200\n",
      "Epoch 2904/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2664 - accuracy: 0.9300 - val_loss: 4.0199 - val_accuracy: 0.4300\n",
      "Epoch 2905/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2662 - accuracy: 0.9300 - val_loss: 4.0180 - val_accuracy: 0.4233\n",
      "Epoch 2906/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2662 - accuracy: 0.9300 - val_loss: 4.0016 - val_accuracy: 0.4333\n",
      "Epoch 2907/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2663 - accuracy: 0.9300 - val_loss: 4.0229 - val_accuracy: 0.4267\n",
      "Epoch 2908/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2662 - accuracy: 0.9300 - val_loss: 4.0168 - val_accuracy: 0.4267\n",
      "Epoch 2909/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2660 - accuracy: 0.9300 - val_loss: 4.0007 - val_accuracy: 0.4267\n",
      "Epoch 2910/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2657 - accuracy: 0.9300 - val_loss: 4.0240 - val_accuracy: 0.4300\n",
      "Epoch 2911/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2660 - accuracy: 0.9300 - val_loss: 4.0045 - val_accuracy: 0.4300\n",
      "Epoch 2912/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2660 - accuracy: 0.9300 - val_loss: 4.0150 - val_accuracy: 0.4300\n",
      "Epoch 2913/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2659 - accuracy: 0.9300 - val_loss: 4.0136 - val_accuracy: 0.4300\n",
      "Epoch 2914/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2656 - accuracy: 0.9300 - val_loss: 4.0032 - val_accuracy: 0.4333\n",
      "Epoch 2915/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2658 - accuracy: 0.9300 - val_loss: 4.0129 - val_accuracy: 0.4267\n",
      "Epoch 2916/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.2655 - accuracy: 0.9300 - val_loss: 4.0090 - val_accuracy: 0.4300\n",
      "Epoch 2917/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2656 - accuracy: 0.9300 - val_loss: 4.0149 - val_accuracy: 0.4300\n",
      "Epoch 2918/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2657 - accuracy: 0.9300 - val_loss: 4.0364 - val_accuracy: 0.4267\n",
      "Epoch 2919/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2657 - accuracy: 0.9300 - val_loss: 4.0342 - val_accuracy: 0.4267\n",
      "Epoch 2920/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2658 - accuracy: 0.9300 - val_loss: 4.0363 - val_accuracy: 0.4267\n",
      "Epoch 2921/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2657 - accuracy: 0.9300 - val_loss: 4.0281 - val_accuracy: 0.4233\n",
      "Epoch 2922/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2657 - accuracy: 0.9300 - val_loss: 4.0204 - val_accuracy: 0.4300\n",
      "Epoch 2923/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2658 - accuracy: 0.9300 - val_loss: 4.0301 - val_accuracy: 0.4267\n",
      "Epoch 2924/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2655 - accuracy: 0.9300 - val_loss: 4.0206 - val_accuracy: 0.4233\n",
      "Epoch 2925/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.2654 - accuracy: 0.9300 - val_loss: 4.0399 - val_accuracy: 0.4267\n",
      "Epoch 2926/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2654 - accuracy: 0.9300 - val_loss: 4.0394 - val_accuracy: 0.4233\n",
      "Epoch 2927/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2657 - accuracy: 0.9300 - val_loss: 4.0405 - val_accuracy: 0.4267\n",
      "Epoch 2928/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2653 - accuracy: 0.9300 - val_loss: 4.0369 - val_accuracy: 0.4267\n",
      "Epoch 2929/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2654 - accuracy: 0.9300 - val_loss: 4.0351 - val_accuracy: 0.4233\n",
      "Epoch 2930/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2654 - accuracy: 0.9300 - val_loss: 4.0335 - val_accuracy: 0.4267\n",
      "Epoch 2931/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2657 - accuracy: 0.9300 - val_loss: 4.0311 - val_accuracy: 0.4267\n",
      "Epoch 2932/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2653 - accuracy: 0.9300 - val_loss: 4.0394 - val_accuracy: 0.4233\n",
      "Epoch 2933/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2651 - accuracy: 0.9300 - val_loss: 4.0368 - val_accuracy: 0.4200\n",
      "Epoch 2934/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2652 - accuracy: 0.9300 - val_loss: 4.0490 - val_accuracy: 0.4267\n",
      "Epoch 2935/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2653 - accuracy: 0.9300 - val_loss: 4.0421 - val_accuracy: 0.4233\n",
      "Epoch 2936/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2651 - accuracy: 0.9300 - val_loss: 4.0147 - val_accuracy: 0.4333\n",
      "Epoch 2937/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2652 - accuracy: 0.9300 - val_loss: 4.0376 - val_accuracy: 0.4233\n",
      "Epoch 2938/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2653 - accuracy: 0.9300 - val_loss: 4.0512 - val_accuracy: 0.4233\n",
      "Epoch 2939/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2651 - accuracy: 0.9300 - val_loss: 4.0264 - val_accuracy: 0.4300\n",
      "Epoch 2940/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2654 - accuracy: 0.9300 - val_loss: 4.0356 - val_accuracy: 0.4233\n",
      "Epoch 2941/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2653 - accuracy: 0.9300 - val_loss: 4.0435 - val_accuracy: 0.4200\n",
      "Epoch 2942/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2652 - accuracy: 0.9300 - val_loss: 4.0251 - val_accuracy: 0.4267\n",
      "Epoch 2943/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2647 - accuracy: 0.9300 - val_loss: 4.0504 - val_accuracy: 0.4200\n",
      "Epoch 2944/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2651 - accuracy: 0.9300 - val_loss: 4.0399 - val_accuracy: 0.4267\n",
      "Epoch 2945/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2649 - accuracy: 0.9300 - val_loss: 4.0527 - val_accuracy: 0.4233\n",
      "Epoch 2946/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2648 - accuracy: 0.9300 - val_loss: 4.0365 - val_accuracy: 0.4267\n",
      "Epoch 2947/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2651 - accuracy: 0.9300 - val_loss: 4.0355 - val_accuracy: 0.4267\n",
      "Epoch 2948/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2649 - accuracy: 0.9300 - val_loss: 4.0552 - val_accuracy: 0.4233\n",
      "Epoch 2949/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2651 - accuracy: 0.9300 - val_loss: 4.0588 - val_accuracy: 0.4233\n",
      "Epoch 2950/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2652 - accuracy: 0.9300 - val_loss: 4.0528 - val_accuracy: 0.4233\n",
      "Epoch 2951/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2647 - accuracy: 0.9300 - val_loss: 4.0302 - val_accuracy: 0.4300\n",
      "Epoch 2952/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2648 - accuracy: 0.9300 - val_loss: 4.0291 - val_accuracy: 0.4367\n",
      "Epoch 2953/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2651 - accuracy: 0.9300 - val_loss: 4.0541 - val_accuracy: 0.4200\n",
      "Epoch 2954/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2649 - accuracy: 0.9300 - val_loss: 4.0508 - val_accuracy: 0.4267\n",
      "Epoch 2955/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2647 - accuracy: 0.9300 - val_loss: 4.0425 - val_accuracy: 0.4300\n",
      "Epoch 2956/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2647 - accuracy: 0.9300 - val_loss: 4.0549 - val_accuracy: 0.4267\n",
      "Epoch 2957/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2645 - accuracy: 0.9300 - val_loss: 4.0569 - val_accuracy: 0.4233\n",
      "Epoch 2958/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2649 - accuracy: 0.9300 - val_loss: 4.0525 - val_accuracy: 0.4233\n",
      "Epoch 2959/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2647 - accuracy: 0.9300 - val_loss: 4.0555 - val_accuracy: 0.4267\n",
      "Epoch 2960/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2644 - accuracy: 0.9300 - val_loss: 4.0336 - val_accuracy: 0.4333\n",
      "Epoch 2961/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2649 - accuracy: 0.9300 - val_loss: 4.0461 - val_accuracy: 0.4233\n",
      "Epoch 2962/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2647 - accuracy: 0.9300 - val_loss: 4.0638 - val_accuracy: 0.4233\n",
      "Epoch 2963/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2649 - accuracy: 0.9300 - val_loss: 4.0560 - val_accuracy: 0.4200\n",
      "Epoch 2964/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2646 - accuracy: 0.9300 - val_loss: 4.0646 - val_accuracy: 0.4233\n",
      "Epoch 2965/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2644 - accuracy: 0.9300 - val_loss: 4.0722 - val_accuracy: 0.4267\n",
      "Epoch 2966/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2646 - accuracy: 0.9300 - val_loss: 4.0596 - val_accuracy: 0.4233\n",
      "Epoch 2967/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.2644 - accuracy: 0.9300 - val_loss: 4.0662 - val_accuracy: 0.4233\n",
      "Epoch 2968/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2644 - accuracy: 0.9300 - val_loss: 4.0404 - val_accuracy: 0.4267\n",
      "Epoch 2969/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2644 - accuracy: 0.9300 - val_loss: 4.0568 - val_accuracy: 0.4233\n",
      "Epoch 2970/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2644 - accuracy: 0.9300 - val_loss: 4.0563 - val_accuracy: 0.4233\n",
      "Epoch 2971/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2641 - accuracy: 0.9300 - val_loss: 4.0605 - val_accuracy: 0.4267\n",
      "Epoch 2972/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2643 - accuracy: 0.9300 - val_loss: 4.0614 - val_accuracy: 0.4267\n",
      "Epoch 2973/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2643 - accuracy: 0.9300 - val_loss: 4.0682 - val_accuracy: 0.4233\n",
      "Epoch 2974/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2643 - accuracy: 0.9300 - val_loss: 4.0504 - val_accuracy: 0.4200\n",
      "Epoch 2975/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2641 - accuracy: 0.9300 - val_loss: 4.0630 - val_accuracy: 0.4233\n",
      "Epoch 2976/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2640 - accuracy: 0.9300 - val_loss: 4.0406 - val_accuracy: 0.4267\n",
      "Epoch 2977/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2643 - accuracy: 0.9300 - val_loss: 4.0712 - val_accuracy: 0.4200\n",
      "Epoch 2978/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2641 - accuracy: 0.9300 - val_loss: 4.0720 - val_accuracy: 0.4233\n",
      "Epoch 2979/3000\n",
      "700/700 [==============================] - 0s 87us/step - loss: 0.2646 - accuracy: 0.9300 - val_loss: 4.0511 - val_accuracy: 0.4267\n",
      "Epoch 2980/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 86us/step - loss: 0.2642 - accuracy: 0.9300 - val_loss: 4.0768 - val_accuracy: 0.4200\n",
      "Epoch 2981/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2642 - accuracy: 0.9300 - val_loss: 4.0625 - val_accuracy: 0.4200\n",
      "Epoch 2982/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.2644 - accuracy: 0.9300 - val_loss: 4.0727 - val_accuracy: 0.4267\n",
      "Epoch 2983/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2639 - accuracy: 0.9300 - val_loss: 4.0656 - val_accuracy: 0.4200\n",
      "Epoch 2984/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2643 - accuracy: 0.9300 - val_loss: 4.0897 - val_accuracy: 0.4267\n",
      "Epoch 2985/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2641 - accuracy: 0.9300 - val_loss: 4.0647 - val_accuracy: 0.4267\n",
      "Epoch 2986/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2640 - accuracy: 0.9300 - val_loss: 4.0481 - val_accuracy: 0.4300\n",
      "Epoch 2987/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2638 - accuracy: 0.9300 - val_loss: 4.0742 - val_accuracy: 0.4233\n",
      "Epoch 2988/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2637 - accuracy: 0.9300 - val_loss: 4.0581 - val_accuracy: 0.4300\n",
      "Epoch 2989/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2639 - accuracy: 0.9300 - val_loss: 4.0896 - val_accuracy: 0.4200\n",
      "Epoch 2990/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2641 - accuracy: 0.9300 - val_loss: 4.0820 - val_accuracy: 0.4233\n",
      "Epoch 2991/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2643 - accuracy: 0.9300 - val_loss: 4.0679 - val_accuracy: 0.4200\n",
      "Epoch 2992/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2637 - accuracy: 0.9300 - val_loss: 4.0742 - val_accuracy: 0.4267\n",
      "Epoch 2993/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2639 - accuracy: 0.9300 - val_loss: 4.0714 - val_accuracy: 0.4233\n",
      "Epoch 2994/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2638 - accuracy: 0.9300 - val_loss: 4.0664 - val_accuracy: 0.4233\n",
      "Epoch 2995/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2637 - accuracy: 0.9300 - val_loss: 4.0756 - val_accuracy: 0.4200\n",
      "Epoch 2996/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2639 - accuracy: 0.9300 - val_loss: 4.0753 - val_accuracy: 0.4267\n",
      "Epoch 2997/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2638 - accuracy: 0.9300 - val_loss: 4.0700 - val_accuracy: 0.4267\n",
      "Epoch 2998/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2636 - accuracy: 0.9300 - val_loss: 4.0831 - val_accuracy: 0.4200\n",
      "Epoch 2999/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2637 - accuracy: 0.9300 - val_loss: 4.0781 - val_accuracy: 0.4233\n",
      "Epoch 3000/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2636 - accuracy: 0.9300 - val_loss: 4.0536 - val_accuracy: 0.4300\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(xTrain,yTrain,epochs=3000, batch_size=10, validation_data=(xVal,yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax=plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 16us/step\n",
      "cost:4.592044577789307\n",
      "accuracy:0.44859999418258667\n"
     ]
    }
   ],
   "source": [
    "res=model.evaluate(xTest, yTest, batch_size=32)\n",
    "print(\"cost:\"+str(res[0]))\n",
    "print(\"accuracy:\"+str(res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#조기 종료 : earlystopping\n",
    "#콜백(함수):어떤 상황이 되었을때(val loss가 떨어지다가 올라가기 시작한 시점) 함수 내에서\n",
    "#또 다른 어떤 함수를 호출하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 2.2820 - accuracy: 0.1100 - val_loss: 2.2653 - val_accuracy: 0.0933\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 2.2281 - accuracy: 0.1314 - val_loss: 2.2198 - val_accuracy: 0.0767\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 2.1718 - accuracy: 0.1486 - val_loss: 2.1569 - val_accuracy: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 2.1202 - accuracy: 0.1957 - val_loss: 2.1079 - val_accuracy: 0.2200\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 2.0770 - accuracy: 0.2129 - val_loss: 2.0673 - val_accuracy: 0.2233\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 2.0413 - accuracy: 0.2314 - val_loss: 2.0320 - val_accuracy: 0.2267\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 2.0075 - accuracy: 0.2314 - val_loss: 1.9991 - val_accuracy: 0.2333\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.9779 - accuracy: 0.2343 - val_loss: 1.9733 - val_accuracy: 0.2267\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.9484 - accuracy: 0.2543 - val_loss: 1.9433 - val_accuracy: 0.2400\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.9215 - accuracy: 0.2686 - val_loss: 1.9182 - val_accuracy: 0.2467\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.8962 - accuracy: 0.2714 - val_loss: 1.8927 - val_accuracy: 0.2500\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.8717 - accuracy: 0.2814 - val_loss: 1.8702 - val_accuracy: 0.2767\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8473 - accuracy: 0.3071 - val_loss: 1.8478 - val_accuracy: 0.2900\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.8237 - accuracy: 0.3129 - val_loss: 1.8271 - val_accuracy: 0.3033\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.8016 - accuracy: 0.3243 - val_loss: 1.8063 - val_accuracy: 0.3067\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.7791 - accuracy: 0.3386 - val_loss: 1.7857 - val_accuracy: 0.3100\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7585 - accuracy: 0.3357 - val_loss: 1.7664 - val_accuracy: 0.3367\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.7375 - accuracy: 0.3529 - val_loss: 1.7479 - val_accuracy: 0.3667\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7178 - accuracy: 0.3514 - val_loss: 1.7305 - val_accuracy: 0.3800\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6969 - accuracy: 0.3843 - val_loss: 1.7136 - val_accuracy: 0.3900\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6771 - accuracy: 0.3943 - val_loss: 1.6975 - val_accuracy: 0.3933\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.6582 - accuracy: 0.3971 - val_loss: 1.6806 - val_accuracy: 0.3967\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.6418 - accuracy: 0.4000 - val_loss: 1.6669 - val_accuracy: 0.3933\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6236 - accuracy: 0.4086 - val_loss: 1.6533 - val_accuracy: 0.4000\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6066 - accuracy: 0.4100 - val_loss: 1.6417 - val_accuracy: 0.3967\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5906 - accuracy: 0.4229 - val_loss: 1.6279 - val_accuracy: 0.4000\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5737 - accuracy: 0.4143 - val_loss: 1.6142 - val_accuracy: 0.4000\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5579 - accuracy: 0.4286 - val_loss: 1.6038 - val_accuracy: 0.4000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.5450 - accuracy: 0.4257 - val_loss: 1.5916 - val_accuracy: 0.3967\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5314 - accuracy: 0.4314 - val_loss: 1.5796 - val_accuracy: 0.4033\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5170 - accuracy: 0.4286 - val_loss: 1.5717 - val_accuracy: 0.4067\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.5039 - accuracy: 0.4371 - val_loss: 1.5629 - val_accuracy: 0.4000\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4923 - accuracy: 0.4400 - val_loss: 1.5539 - val_accuracy: 0.3967\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4807 - accuracy: 0.4414 - val_loss: 1.5425 - val_accuracy: 0.3967\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4682 - accuracy: 0.4429 - val_loss: 1.5336 - val_accuracy: 0.4067\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4578 - accuracy: 0.4400 - val_loss: 1.5281 - val_accuracy: 0.4100\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4470 - accuracy: 0.4371 - val_loss: 1.5235 - val_accuracy: 0.4067\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4374 - accuracy: 0.4486 - val_loss: 1.5137 - val_accuracy: 0.4067\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4278 - accuracy: 0.4543 - val_loss: 1.5065 - val_accuracy: 0.4033\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.4186 - accuracy: 0.4500 - val_loss: 1.5040 - val_accuracy: 0.4067\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4077 - accuracy: 0.4457 - val_loss: 1.5014 - val_accuracy: 0.4033\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4022 - accuracy: 0.4471 - val_loss: 1.4919 - val_accuracy: 0.4067\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3943 - accuracy: 0.4557 - val_loss: 1.4877 - val_accuracy: 0.4500\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3865 - accuracy: 0.4614 - val_loss: 1.4858 - val_accuracy: 0.4467\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.3792 - accuracy: 0.4843 - val_loss: 1.4784 - val_accuracy: 0.4467\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3708 - accuracy: 0.4843 - val_loss: 1.4728 - val_accuracy: 0.4467\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3643 - accuracy: 0.4943 - val_loss: 1.4701 - val_accuracy: 0.4467\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3583 - accuracy: 0.4971 - val_loss: 1.4640 - val_accuracy: 0.4467\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3535 - accuracy: 0.4957 - val_loss: 1.4646 - val_accuracy: 0.4467\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(xTrain,yTrain,epochs=3000, batch_size=10, validation_data=(xVal,yVal), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax=plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping(patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.2635 - accuracy: 0.9300 - val_loss: 4.0938 - val_accuracy: 0.4200\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2637 - accuracy: 0.9300 - val_loss: 4.1007 - val_accuracy: 0.4233\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2632 - accuracy: 0.9300 - val_loss: 4.0811 - val_accuracy: 0.4200\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2635 - accuracy: 0.9300 - val_loss: 4.0759 - val_accuracy: 0.4267\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2637 - accuracy: 0.9300 - val_loss: 4.1015 - val_accuracy: 0.4233\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2638 - accuracy: 0.9300 - val_loss: 4.0835 - val_accuracy: 0.4200\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2636 - accuracy: 0.9300 - val_loss: 4.0816 - val_accuracy: 0.4200\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2637 - accuracy: 0.9300 - val_loss: 4.0803 - val_accuracy: 0.4233\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2634 - accuracy: 0.9300 - val_loss: 4.0828 - val_accuracy: 0.4233\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.2638 - accuracy: 0.9300 - val_loss: 4.0919 - val_accuracy: 0.4200\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.2634 - accuracy: 0.9300 - val_loss: 4.0991 - val_accuracy: 0.4233\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2633 - accuracy: 0.9300 - val_loss: 4.0770 - val_accuracy: 0.4233\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2633 - accuracy: 0.9300 - val_loss: 4.0912 - val_accuracy: 0.4200\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.2631 - accuracy: 0.9300 - val_loss: 4.0990 - val_accuracy: 0.4233\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2635 - accuracy: 0.9300 - val_loss: 4.0723 - val_accuracy: 0.4267\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 0.2633 - accuracy: 0.9300 - val_loss: 4.0835 - val_accuracy: 0.4233\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2635 - accuracy: 0.9300 - val_loss: 4.0956 - val_accuracy: 0.4233\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2630 - accuracy: 0.9300 - val_loss: 4.0769 - val_accuracy: 0.4233\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2633 - accuracy: 0.9300 - val_loss: 4.0780 - val_accuracy: 0.4267\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2633 - accuracy: 0.9300 - val_loss: 4.0726 - val_accuracy: 0.4233\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2633 - accuracy: 0.9300 - val_loss: 4.0944 - val_accuracy: 0.4200\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.2630 - accuracy: 0.9300 - val_loss: 4.0864 - val_accuracy: 0.4233\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2632 - accuracy: 0.9300 - val_loss: 4.0898 - val_accuracy: 0.4267\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.2632 - accuracy: 0.9300 - val_loss: 4.0828 - val_accuracy: 0.4300\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.2631 - accuracy: 0.9300 - val_loss: 4.0873 - val_accuracy: 0.4300\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.2632 - accuracy: 0.9300 - val_loss: 4.0832 - val_accuracy: 0.4233\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2630 - accuracy: 0.9300 - val_loss: 4.0847 - val_accuracy: 0.4300\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.2630 - accuracy: 0.9300 - val_loss: 4.0821 - val_accuracy: 0.4300\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2628 - accuracy: 0.9300 - val_loss: 4.1022 - val_accuracy: 0.4200\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.2624 - accuracy: 0.9300 - val_loss: 4.0769 - val_accuracy: 0.4300\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2630 - accuracy: 0.9300 - val_loss: 4.1042 - val_accuracy: 0.4233\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2628 - accuracy: 0.9300 - val_loss: 4.0909 - val_accuracy: 0.4267\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.2628 - accuracy: 0.9300 - val_loss: 4.0985 - val_accuracy: 0.4267\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2626 - accuracy: 0.9300 - val_loss: 4.1055 - val_accuracy: 0.4233\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.2629 - accuracy: 0.9300 - val_loss: 4.0993 - val_accuracy: 0.4233\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2627 - accuracy: 0.9300 - val_loss: 4.0939 - val_accuracy: 0.4267\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.2628 - accuracy: 0.9300 - val_loss: 4.1040 - val_accuracy: 0.4200\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.2624 - accuracy: 0.9300 - val_loss: 4.0936 - val_accuracy: 0.4233\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.2628 - accuracy: 0.9300 - val_loss: 4.1015 - val_accuracy: 0.4233\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.2626 - accuracy: 0.9300 - val_loss: 4.0860 - val_accuracy: 0.4233\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.2622 - accuracy: 0.9300 - val_loss: 4.1298 - val_accuracy: 0.4267\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.2626 - accuracy: 0.9300 - val_loss: 4.0899 - val_accuracy: 0.4300\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2628 - accuracy: 0.9300 - val_loss: 4.1163 - val_accuracy: 0.4233\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.2624 - accuracy: 0.9300 - val_loss: 4.0842 - val_accuracy: 0.4267\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.2624 - accuracy: 0.9300 - val_loss: 4.1142 - val_accuracy: 0.4233\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(xTrain,yTrain,epochs=3000, batch_size=10, validation_data=(xVal,yVal), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax=plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=np.loadtxt(\"ThoraricSurgery.csv\", \n",
    "                   delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470, 18)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset[:,0:17]\n",
    "y=dataset[:,17] #1:수술 후 생존, 0: 사망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(30, input_dim=17, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "470/470 [==============================] - 0s 515us/step - loss: 0.6513 - accuracy: 0.3213\n",
      "Epoch 2/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1501 - accuracy: 0.8489\n",
      "Epoch 3/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1485 - accuracy: 0.8511\n",
      "Epoch 4/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1483 - accuracy: 0.8511\n",
      "Epoch 5/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 6/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1485 - accuracy: 0.8511\n",
      "Epoch 7/30\n",
      "470/470 [==============================] - 0s 94us/step - loss: 0.1490 - accuracy: 0.8511\n",
      "Epoch 8/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1484 - accuracy: 0.8511\n",
      "Epoch 9/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1482 - accuracy: 0.8511\n",
      "Epoch 10/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1475 - accuracy: 0.8511\n",
      "Epoch 11/30\n",
      "470/470 [==============================] - 0s 96us/step - loss: 0.1482 - accuracy: 0.8511\n",
      "Epoch 12/30\n",
      "470/470 [==============================] - 0s 94us/step - loss: 0.1476 - accuracy: 0.8511\n",
      "Epoch 13/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1484 - accuracy: 0.8511\n",
      "Epoch 14/30\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1473 - accuracy: 0.8532\n",
      "Epoch 15/30\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1479 - accuracy: 0.8532\n",
      "Epoch 16/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1473 - accuracy: 0.8532\n",
      "Epoch 17/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1480 - accuracy: 0.8511\n",
      "Epoch 18/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1475 - accuracy: 0.8511\n",
      "Epoch 19/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1477 - accuracy: 0.8511\n",
      "Epoch 20/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1481 - accuracy: 0.8511\n",
      "Epoch 21/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1474 - accuracy: 0.8511\n",
      "Epoch 22/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1478 - accuracy: 0.8511\n",
      "Epoch 23/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 24/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 25/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 26/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1500 - accuracy: 0.8468\n",
      "Epoch 27/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1469 - accuracy: 0.8511\n",
      "Epoch 28/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1467 - accuracy: 0.8511\n",
      "Epoch 29/30\n",
      "470/470 [==============================] - 0s 77us/step - loss: 0.1487 - accuracy: 0.8511\n",
      "Epoch 30/30\n",
      "470/470 [==============================] - 0s 74us/step - loss: 0.1485 - accuracy: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26146779b08>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=30, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 21us/step\n",
      "0.8510638475418091\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(x,y)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.294118 ,  0.487437 ,  0.180328 , ..., -0.53117  , -0.0333333,\n",
       "         0.       ],\n",
       "       [-0.882353 , -0.145729 ,  0.0819672, ..., -0.766866 , -0.666667 ,\n",
       "         1.       ],\n",
       "       [-0.0588235,  0.839196 ,  0.0491803, ..., -0.492741 , -0.633333 ,\n",
       "         0.       ],\n",
       "       ...,\n",
       "       [-0.411765 ,  0.21608  ,  0.180328 , ..., -0.857387 , -0.7      ,\n",
       "         1.       ],\n",
       "       [-0.882353 ,  0.266332 , -0.0163934, ..., -0.768574 , -0.133333 ,\n",
       "         0.       ],\n",
       "       [-0.882353 , -0.0653266,  0.147541 , ..., -0.797609 , -0.933333 ,\n",
       "         1.       ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy=np.loadtxt('data-03-diabetes.csv', \n",
    "              delimiter=\",\")\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata=xy[:,0:-1]\n",
    "#xdata\n",
    "ydata=xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8) (759, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xdata.shape, ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.Variable(tf.random_normal([8,1]))\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "x=tf.placeholder(tf.float32, shape=[None,8])\n",
    "y=tf.placeholder(tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf=tf.sigmoid(tf.matmul(x,w)+b)\n",
    "cost=-tf.reduce_mean(y*tf.log(hf)+\n",
    "                     (1-y)*tf.log(1-hf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=tf.cast(hf>0.5,dtype=tf.float32)\n",
    "accuracy=tf.reduce_mean\n",
    "(tf.cast(tf.equal(predicted,y),\n",
    "         dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1094863\n",
      "200 0.70070773\n",
      "400 0.6253061\n",
      "600 0.60272974\n",
      "800 0.58896494\n",
      "1000 0.5776871\n",
      "1200 0.5678035\n",
      "1400 0.55902684\n",
      "1600 0.5512095\n",
      "1800 0.5442373\n",
      "2000 0.5380113\n",
      "2200 0.5324441\n",
      "2400 0.5274585\n",
      "2600 0.5229864\n",
      "2800 0.51896805\n",
      "3000 0.5153508\n",
      "3200 0.5120884\n",
      "3400 0.5091406\n",
      "3600 0.50647193\n",
      "3800 0.50405127\n",
      "4000 0.5018512\n",
      "4200 0.49984777\n",
      "4400 0.49802014\n",
      "4600 0.49634963\n",
      "4800 0.49482006\n",
      "5000 0.49341685\n",
      "5200 0.49212742\n",
      "5400 0.49094054\n",
      "5600 0.4898462\n",
      "5800 0.4888355\n",
      "6000 0.48790073\n",
      "6200 0.4870347\n",
      "6400 0.4862313\n",
      "6600 0.4854849\n",
      "6800 0.48479035\n",
      "7000 0.48414344\n",
      "7200 0.48353997\n",
      "7400 0.4829763\n",
      "7600 0.48244908\n",
      "7800 0.48195556\n",
      "8000 0.4814931\n",
      "8200 0.48105904\n",
      "8400 0.4806513\n",
      "8600 0.48026788\n",
      "8800 0.47990698\n",
      "9000 0.47956702\n",
      "9200 0.47924632\n",
      "9400 0.47894365\n",
      "9600 0.4786577\n",
      "9800 0.4783873\n",
      "10000 0.4781314\n",
      "[[0.43820193]\n",
      " [0.93581176]\n",
      " [0.25459132]\n",
      " [0.9514966 ]\n",
      " [0.2126536 ]\n",
      " [0.7686801 ]\n",
      " [0.94086003]\n",
      " [0.5619235 ]\n",
      " [0.26697546]\n",
      " [0.52510595]\n",
      " [0.6610118 ]\n",
      " [0.15458795]\n",
      " [0.33936924]\n",
      " [0.34252465]\n",
      " [0.7545746 ]\n",
      " [0.38536116]\n",
      " [0.72931534]\n",
      " [0.8358338 ]\n",
      " [0.814116  ]\n",
      " [0.55281353]\n",
      " [0.66983384]\n",
      " [0.0894056 ]\n",
      " [0.6510207 ]\n",
      " [0.6709076 ]\n",
      " [0.3305043 ]\n",
      " [0.94490254]\n",
      " [0.60261905]\n",
      " [0.62717235]\n",
      " [0.73205227]\n",
      " [0.4512422 ]\n",
      " [0.9561553 ]\n",
      " [0.8827032 ]\n",
      " [0.622846  ]\n",
      " [0.8643148 ]\n",
      " [0.35292   ]\n",
      " [0.6719727 ]\n",
      " [0.8131951 ]\n",
      " [0.6064009 ]\n",
      " [0.4223183 ]\n",
      " [0.34251505]\n",
      " [0.85885787]\n",
      " [0.1325016 ]\n",
      " [0.42550665]\n",
      " [0.06350341]\n",
      " [0.6032077 ]\n",
      " [0.93953335]\n",
      " [0.6841848 ]\n",
      " [0.69836223]\n",
      " [0.9483732 ]\n",
      " [0.94448805]\n",
      " [0.9389276 ]\n",
      " [0.24170473]\n",
      " [0.3675676 ]\n",
      " [0.9758369 ]\n",
      " [0.18597037]\n",
      " [0.41803885]\n",
      " [0.14942762]\n",
      " [0.6442608 ]\n",
      " [0.88521683]\n",
      " [0.4947133 ]\n",
      " [0.9600049 ]\n",
      " [0.7405862 ]\n",
      " [0.664081  ]\n",
      " [0.8567536 ]\n",
      " [0.6197006 ]\n",
      " [0.5819357 ]\n",
      " [0.96475124]\n",
      " [0.67568886]\n",
      " [0.8664943 ]\n",
      " [0.67069614]\n",
      " [0.22862694]\n",
      " [0.6839328 ]\n",
      " [0.9178666 ]\n",
      " [0.9359857 ]\n",
      " [0.88465714]\n",
      " [0.7713032 ]\n",
      " [0.3535415 ]\n",
      " [0.8799877 ]\n",
      " [0.91231173]\n",
      " [0.91226697]\n",
      " [0.8809167 ]\n",
      " [0.83470714]\n",
      " [0.2773979 ]\n",
      " [0.8188293 ]\n",
      " [0.50679123]\n",
      " [0.85310334]\n",
      " [0.3746767 ]\n",
      " [0.90492344]\n",
      " [0.9598122 ]\n",
      " [0.77273273]\n",
      " [0.7598349 ]\n",
      " [0.72398806]\n",
      " [0.77563655]\n",
      " [0.5675341 ]\n",
      " [0.90132296]\n",
      " [0.98114824]\n",
      " [0.8950459 ]\n",
      " [0.5000698 ]\n",
      " [0.2599585 ]\n",
      " [0.65652204]\n",
      " [0.66297185]\n",
      " [0.961498  ]\n",
      " [0.7724133 ]\n",
      " [0.81430537]\n",
      " [0.8893933 ]\n",
      " [0.6998954 ]\n",
      " [0.91688377]\n",
      " [0.77953625]\n",
      " [0.4538365 ]\n",
      " [0.37137944]\n",
      " [0.9262422 ]\n",
      " [0.8701607 ]\n",
      " [0.45282507]\n",
      " [0.4831661 ]\n",
      " [0.6204668 ]\n",
      " [0.84560025]\n",
      " [0.8774754 ]\n",
      " [0.93840915]\n",
      " [0.0941498 ]\n",
      " [0.7063519 ]\n",
      " [0.841988  ]\n",
      " [0.6842141 ]\n",
      " [0.5977838 ]\n",
      " [0.7521292 ]\n",
      " [0.6551233 ]\n",
      " [0.8281547 ]\n",
      " [0.81098056]\n",
      " [0.68547714]\n",
      " [0.51183045]\n",
      " [0.44767514]\n",
      " [0.4088278 ]\n",
      " [0.7674628 ]\n",
      " [0.94813657]\n",
      " [0.82084453]\n",
      " [0.8136561 ]\n",
      " [0.8552027 ]\n",
      " [0.45840096]\n",
      " [0.77243596]\n",
      " [0.7945143 ]\n",
      " [0.7021436 ]\n",
      " [0.8765533 ]\n",
      " [0.6366401 ]\n",
      " [0.5427561 ]\n",
      " [0.7284087 ]\n",
      " [0.9066516 ]\n",
      " [0.7969214 ]\n",
      " [0.47945714]\n",
      " [0.9334008 ]\n",
      " [0.5944693 ]\n",
      " [0.82217944]\n",
      " [0.2827874 ]\n",
      " [0.35216305]\n",
      " [0.08082342]\n",
      " [0.17693755]\n",
      " [0.93879604]\n",
      " [0.8986024 ]\n",
      " [0.9404906 ]\n",
      " [0.10079077]\n",
      " [0.52261984]\n",
      " [0.75609726]\n",
      " [0.5212637 ]\n",
      " [0.8920181 ]\n",
      " [0.42431712]\n",
      " [0.8278412 ]\n",
      " [0.5981366 ]\n",
      " [0.67479146]\n",
      " [0.7314101 ]\n",
      " [0.8696017 ]\n",
      " [0.7641871 ]\n",
      " [0.6038115 ]\n",
      " [0.90441984]\n",
      " [0.859131  ]\n",
      " [0.95440537]\n",
      " [0.22352818]\n",
      " [0.8282478 ]\n",
      " [0.12012175]\n",
      " [0.33633152]\n",
      " [0.39590335]\n",
      " [0.8912449 ]\n",
      " [0.65384954]\n",
      " [0.93576074]\n",
      " [0.9164045 ]\n",
      " [0.6178284 ]\n",
      " [0.1443784 ]\n",
      " [0.23176357]\n",
      " [0.63742816]\n",
      " [0.74933493]\n",
      " [0.6105891 ]\n",
      " [0.8694063 ]\n",
      " [0.6081563 ]\n",
      " [0.36598593]\n",
      " [0.16366652]\n",
      " [0.9185076 ]\n",
      " [0.33159128]\n",
      " [0.89765793]\n",
      " [0.9161429 ]\n",
      " [0.7222653 ]\n",
      " [0.6362071 ]\n",
      " [0.67386496]\n",
      " [0.513698  ]\n",
      " [0.7479743 ]\n",
      " [0.9542128 ]\n",
      " [0.7677161 ]\n",
      " [0.83483696]\n",
      " [0.13534203]\n",
      " [0.2882899 ]\n",
      " [0.91481817]\n",
      " [0.19464451]\n",
      " [0.94080603]\n",
      " [0.2146557 ]\n",
      " [0.25476208]\n",
      " [0.40106547]\n",
      " [0.68198097]\n",
      " [0.18664262]\n",
      " [0.7361989 ]\n",
      " [0.7263412 ]\n",
      " [0.84701836]\n",
      " [0.6556437 ]\n",
      " [0.17910808]\n",
      " [0.41525334]\n",
      " [0.7362042 ]\n",
      " [0.59522873]\n",
      " [0.93796575]\n",
      " [0.9252966 ]\n",
      " [0.6569823 ]\n",
      " [0.35984987]\n",
      " [0.05276161]\n",
      " [0.54811853]\n",
      " [0.29756862]\n",
      " [0.39415902]\n",
      " [0.95450675]\n",
      " [0.6236089 ]\n",
      " [0.9482132 ]\n",
      " [0.18502533]\n",
      " [0.10621914]\n",
      " [0.28898376]\n",
      " [0.79989505]\n",
      " [0.92967796]\n",
      " [0.8737845 ]\n",
      " [0.67494106]\n",
      " [0.73749673]\n",
      " [0.54844964]\n",
      " [0.18252674]\n",
      " [0.55579746]\n",
      " [0.08652624]\n",
      " [0.5519857 ]\n",
      " [0.861884  ]\n",
      " [0.693108  ]\n",
      " [0.7077193 ]\n",
      " [0.9526144 ]\n",
      " [0.790076  ]\n",
      " [0.8127706 ]\n",
      " [0.79583013]\n",
      " [0.7918341 ]\n",
      " [0.8608808 ]\n",
      " [0.43762553]\n",
      " [0.40824977]\n",
      " [0.54941595]\n",
      " [0.8228297 ]\n",
      " [0.68792546]\n",
      " [0.68936   ]\n",
      " [0.83383036]\n",
      " [0.3203881 ]\n",
      " [0.49318346]\n",
      " [0.7125585 ]\n",
      " [0.6425793 ]\n",
      " [0.39122286]\n",
      " [0.9210224 ]\n",
      " [0.79739684]\n",
      " [0.9350333 ]\n",
      " [0.5557525 ]\n",
      " [0.7488778 ]\n",
      " [0.83079743]\n",
      " [0.8240618 ]\n",
      " [0.7499752 ]\n",
      " [0.8881271 ]\n",
      " [0.3103772 ]\n",
      " [0.55016816]\n",
      " [0.66426337]\n",
      " [0.36133063]\n",
      " [0.8404803 ]\n",
      " [0.27319428]\n",
      " [0.5612491 ]\n",
      " [0.9477228 ]\n",
      " [0.76047575]\n",
      " [0.8447504 ]\n",
      " [0.6759528 ]\n",
      " [0.4773102 ]\n",
      " [0.6311709 ]\n",
      " [0.4991985 ]\n",
      " [0.4487706 ]\n",
      " [0.6588348 ]\n",
      " [0.6082936 ]\n",
      " [0.624829  ]\n",
      " [0.7084112 ]\n",
      " [0.21782026]\n",
      " [0.6803037 ]\n",
      " [0.8926158 ]\n",
      " [0.3698069 ]\n",
      " [0.67137307]\n",
      " [0.72173977]\n",
      " [0.5017252 ]\n",
      " [0.7513102 ]\n",
      " [0.5462938 ]\n",
      " [0.72694826]\n",
      " [0.9146458 ]\n",
      " [0.6161269 ]\n",
      " [0.70822513]\n",
      " [0.87469554]\n",
      " [0.58559555]\n",
      " [0.8458663 ]\n",
      " [0.9514655 ]\n",
      " [0.29936594]\n",
      " [0.7545123 ]\n",
      " [0.28941694]\n",
      " [0.7982224 ]\n",
      " [0.80369353]\n",
      " [0.71294296]\n",
      " [0.37108028]\n",
      " [0.79392844]\n",
      " [0.7406043 ]\n",
      " [0.7530724 ]\n",
      " [0.1638309 ]\n",
      " [0.74955463]\n",
      " [0.8457836 ]\n",
      " [0.68367475]\n",
      " [0.9396738 ]\n",
      " [0.23204729]\n",
      " [0.7171855 ]\n",
      " [0.9542455 ]\n",
      " [0.15230924]\n",
      " [0.5147032 ]\n",
      " [0.7020376 ]\n",
      " [0.32563818]\n",
      " [0.15267473]\n",
      " [0.8553928 ]\n",
      " [0.9317224 ]\n",
      " [0.8588072 ]\n",
      " [0.59503675]\n",
      " [0.685504  ]\n",
      " [0.54273707]\n",
      " [0.79143643]\n",
      " [0.8306099 ]\n",
      " [0.9430781 ]\n",
      " [0.71189153]\n",
      " [0.7214682 ]\n",
      " [0.57140124]\n",
      " [0.9385927 ]\n",
      " [0.94790477]\n",
      " [0.7298926 ]\n",
      " [0.27537408]\n",
      " [0.7214352 ]\n",
      " [0.34143984]\n",
      " [0.74780977]\n",
      " [0.20118451]\n",
      " [0.25498325]\n",
      " [0.46980497]\n",
      " [0.6893869 ]\n",
      " [0.40400672]\n",
      " [0.5485425 ]\n",
      " [0.8450879 ]\n",
      " [0.6615867 ]\n",
      " [0.8879372 ]\n",
      " [0.94613004]\n",
      " [0.74579936]\n",
      " [0.11046273]\n",
      " [0.5588614 ]\n",
      " [0.8504752 ]\n",
      " [0.848102  ]\n",
      " [0.68928266]\n",
      " [0.27381903]\n",
      " [0.8782463 ]\n",
      " [0.88927674]\n",
      " [0.23130795]\n",
      " [0.57202053]\n",
      " [0.8517371 ]\n",
      " [0.86288416]\n",
      " [0.9099138 ]\n",
      " [0.9289434 ]\n",
      " [0.8817738 ]\n",
      " [0.93011796]\n",
      " [0.7000384 ]\n",
      " [0.5543418 ]\n",
      " [0.5870983 ]\n",
      " [0.8527852 ]\n",
      " [0.89045846]\n",
      " [0.18058658]\n",
      " [0.8577277 ]\n",
      " [0.8969297 ]\n",
      " [0.3387159 ]\n",
      " [0.701413  ]\n",
      " [0.9015454 ]\n",
      " [0.5114235 ]\n",
      " [0.92766416]\n",
      " [0.2468707 ]\n",
      " [0.833112  ]\n",
      " [0.58934516]\n",
      " [0.8784306 ]\n",
      " [0.35683405]\n",
      " [0.6755085 ]\n",
      " [0.75170946]\n",
      " [0.812961  ]\n",
      " [0.12573674]\n",
      " [0.2080873 ]\n",
      " [0.66590536]\n",
      " [0.81430036]\n",
      " [0.43437684]\n",
      " [0.8161224 ]\n",
      " [0.51081973]\n",
      " [0.31944156]\n",
      " [0.8775792 ]\n",
      " [0.440415  ]\n",
      " [0.9422834 ]\n",
      " [0.8235421 ]\n",
      " [0.60243833]\n",
      " [0.9378253 ]\n",
      " [0.6546681 ]\n",
      " [0.8323765 ]\n",
      " [0.2881307 ]\n",
      " [0.24693415]\n",
      " [0.73675275]\n",
      " [0.42913318]\n",
      " [0.37813568]\n",
      " [0.8956769 ]\n",
      " [0.908695  ]\n",
      " [0.91993463]\n",
      " [0.951398  ]\n",
      " [0.7028218 ]\n",
      " [0.925804  ]\n",
      " [0.31050307]\n",
      " [0.3240863 ]\n",
      " [0.48099014]\n",
      " [0.9596435 ]\n",
      " [0.58324826]\n",
      " [0.15469956]\n",
      " [0.928699  ]\n",
      " [0.7993828 ]\n",
      " [0.61368823]\n",
      " [0.81781167]\n",
      " [0.01685506]\n",
      " [0.93217045]\n",
      " [0.7309207 ]\n",
      " [0.73574394]\n",
      " [0.7458874 ]\n",
      " [0.9707966 ]\n",
      " [0.6498013 ]\n",
      " [0.73702323]\n",
      " [0.83944213]\n",
      " [0.8475576 ]\n",
      " [0.17683867]\n",
      " [0.7240096 ]\n",
      " [0.90671897]\n",
      " [0.6873084 ]\n",
      " [0.8015877 ]\n",
      " [0.95542634]\n",
      " [0.8483918 ]\n",
      " [0.8919034 ]\n",
      " [0.5616937 ]\n",
      " [0.83285123]\n",
      " [0.9426961 ]\n",
      " [0.7274797 ]\n",
      " [0.65209395]\n",
      " [0.25039327]\n",
      " [0.43542498]\n",
      " [0.4891117 ]\n",
      " [0.5648712 ]\n",
      " [0.5343685 ]\n",
      " [0.77618873]\n",
      " [0.61262107]\n",
      " [0.7818993 ]\n",
      " [0.8433796 ]\n",
      " [0.74325776]\n",
      " [0.70502114]\n",
      " [0.4788391 ]\n",
      " [0.5391239 ]\n",
      " [0.9396497 ]\n",
      " [0.8026233 ]\n",
      " [0.22473484]\n",
      " [0.3710776 ]\n",
      " [0.5221417 ]\n",
      " [0.10799947]\n",
      " [0.89793235]\n",
      " [0.18730569]\n",
      " [0.8964503 ]\n",
      " [0.8776893 ]\n",
      " [0.83063173]\n",
      " [0.7451029 ]\n",
      " [0.88379896]\n",
      " [0.41868654]\n",
      " [0.7916355 ]\n",
      " [0.9417076 ]\n",
      " [0.33759558]\n",
      " [0.4733972 ]\n",
      " [0.89086354]\n",
      " [0.8625634 ]\n",
      " [0.6638039 ]\n",
      " [0.8276768 ]\n",
      " [0.80461466]\n",
      " [0.794304  ]\n",
      " [0.2317721 ]\n",
      " [0.8130528 ]\n",
      " [0.9282522 ]\n",
      " [0.68798625]\n",
      " [0.80386555]\n",
      " [0.7540449 ]\n",
      " [0.84729713]\n",
      " [0.88017285]\n",
      " [0.9358005 ]\n",
      " [0.5874526 ]\n",
      " [0.4452715 ]\n",
      " [0.7727472 ]\n",
      " [0.82073283]\n",
      " [0.9689888 ]\n",
      " [0.7451181 ]\n",
      " [0.6798898 ]\n",
      " [0.42865568]\n",
      " [0.709596  ]\n",
      " [0.94764805]\n",
      " [0.965654  ]\n",
      " [0.8909044 ]\n",
      " [0.689448  ]\n",
      " [0.7013359 ]\n",
      " [0.8224617 ]\n",
      " [0.41204292]\n",
      " [0.81007576]\n",
      " [0.8150029 ]\n",
      " [0.9122704 ]\n",
      " [0.6017345 ]\n",
      " [0.7071304 ]\n",
      " [0.93556523]\n",
      " [0.46189594]\n",
      " [0.52683437]\n",
      " [0.65017956]\n",
      " [0.7278379 ]\n",
      " [0.69018555]\n",
      " [0.8752558 ]\n",
      " [0.9215185 ]\n",
      " [0.18599734]\n",
      " [0.14097604]\n",
      " [0.7424255 ]\n",
      " [0.5307492 ]\n",
      " [0.2405285 ]\n",
      " [0.8675668 ]\n",
      " [0.9059528 ]\n",
      " [0.73841584]\n",
      " [0.9382169 ]\n",
      " [0.913514  ]\n",
      " [0.77208364]\n",
      " [0.82576704]\n",
      " [0.729999  ]\n",
      " [0.49421167]\n",
      " [0.76277053]\n",
      " [0.6142847 ]\n",
      " [0.09929678]\n",
      " [0.8924343 ]\n",
      " [0.8936093 ]\n",
      " [0.7102613 ]\n",
      " [0.9314242 ]\n",
      " [0.8666731 ]\n",
      " [0.886184  ]\n",
      " [0.58531314]\n",
      " [0.6676855 ]\n",
      " [0.890985  ]\n",
      " [0.7672546 ]\n",
      " [0.858595  ]\n",
      " [0.90098965]\n",
      " [0.6093909 ]\n",
      " [0.7973433 ]\n",
      " [0.8702347 ]\n",
      " [0.55023074]\n",
      " [0.53705066]\n",
      " [0.11202997]\n",
      " [0.2309568 ]\n",
      " [0.8453746 ]\n",
      " [0.6823646 ]\n",
      " [0.64771456]\n",
      " [0.61779904]\n",
      " [0.9490132 ]\n",
      " [0.4232914 ]\n",
      " [0.82689255]\n",
      " [0.31803992]\n",
      " [0.9105089 ]\n",
      " [0.31112808]\n",
      " [0.72988325]\n",
      " [0.5824914 ]\n",
      " [0.9026358 ]\n",
      " [0.5930778 ]\n",
      " [0.2193771 ]\n",
      " [0.7543553 ]\n",
      " [0.9582539 ]\n",
      " [0.35582012]\n",
      " [0.93686455]\n",
      " [0.8753504 ]\n",
      " [0.86486065]\n",
      " [0.8153902 ]\n",
      " [0.438444  ]\n",
      " [0.3341933 ]\n",
      " [0.72985095]\n",
      " [0.1811203 ]\n",
      " [0.96024704]\n",
      " [0.27606595]\n",
      " [0.9308579 ]\n",
      " [0.88181376]\n",
      " [0.44068372]\n",
      " [0.19505787]\n",
      " [0.7069649 ]\n",
      " [0.4349861 ]\n",
      " [0.84279317]\n",
      " [0.68637896]\n",
      " [0.9824423 ]\n",
      " [0.62967455]\n",
      " [0.60831386]\n",
      " [0.7450629 ]\n",
      " [0.86448085]\n",
      " [0.07921401]\n",
      " [0.72387534]\n",
      " [0.8291441 ]\n",
      " [0.81520367]\n",
      " [0.67637336]\n",
      " [0.4812102 ]\n",
      " [0.5915847 ]\n",
      " [0.92397314]\n",
      " [0.6756395 ]\n",
      " [0.7386378 ]\n",
      " [0.83185625]\n",
      " [0.85162705]\n",
      " [0.80931413]\n",
      " [0.5713546 ]\n",
      " [0.80832005]\n",
      " [0.9008064 ]\n",
      " [0.6820593 ]\n",
      " [0.96237195]\n",
      " [0.79557395]\n",
      " [0.59756976]\n",
      " [0.5060241 ]\n",
      " [0.85389566]\n",
      " [0.8640861 ]\n",
      " [0.4341408 ]\n",
      " [0.69215584]\n",
      " [0.21075854]\n",
      " [0.55562484]\n",
      " [0.81280667]\n",
      " [0.9526386 ]\n",
      " [0.8356711 ]\n",
      " [0.7009141 ]\n",
      " [0.7848084 ]\n",
      " [0.8729468 ]\n",
      " [0.47866935]\n",
      " [0.9373344 ]\n",
      " [0.597649  ]\n",
      " [0.8595418 ]\n",
      " [0.32700056]\n",
      " [0.08543053]\n",
      " [0.23127532]\n",
      " [0.32622695]\n",
      " [0.7060103 ]\n",
      " [0.80332965]\n",
      " [0.6339084 ]\n",
      " [0.75064695]\n",
      " [0.82182825]\n",
      " [0.48638675]\n",
      " [0.4016418 ]\n",
      " [0.9312382 ]\n",
      " [0.8747413 ]\n",
      " [0.29527998]\n",
      " [0.70861304]\n",
      " [0.18010575]\n",
      " [0.42158952]\n",
      " [0.72238386]\n",
      " [0.68958807]\n",
      " [0.91856813]\n",
      " [0.98006266]\n",
      " [0.13869011]\n",
      " [0.65683216]\n",
      " [0.6053187 ]\n",
      " [0.5016538 ]\n",
      " [0.7201704 ]\n",
      " [0.7549461 ]\n",
      " [0.90533406]\n",
      " [0.76104426]\n",
      " [0.44297808]\n",
      " [0.6982018 ]\n",
      " [0.11671975]\n",
      " [0.6663026 ]\n",
      " [0.51270306]\n",
      " [0.92029715]\n",
      " [0.56206065]\n",
      " [0.5597963 ]\n",
      " [0.79954195]\n",
      " [0.70741105]\n",
      " [0.4414915 ]\n",
      " [0.7361068 ]\n",
      " [0.6925392 ]\n",
      " [0.3674634 ]\n",
      " [0.6060563 ]\n",
      " [0.8781403 ]\n",
      " [0.80815613]\n",
      " [0.57152575]\n",
      " [0.78037417]\n",
      " [0.27799273]\n",
      " [0.83938503]\n",
      " [0.59206283]\n",
      " [0.7635575 ]\n",
      " [0.38659063]\n",
      " [0.70095927]\n",
      " [0.835541  ]\n",
      " [0.18765163]\n",
      " [0.3073896 ]\n",
      " [0.8539815 ]\n",
      " [0.80853385]\n",
      " [0.8047457 ]\n",
      " [0.91000974]\n",
      " [0.79426205]\n",
      " [0.7205061 ]\n",
      " [0.6951138 ]\n",
      " [0.77373505]\n",
      " [0.670894  ]\n",
      " [0.77833164]\n",
      " [0.45695648]\n",
      " [0.45234808]\n",
      " [0.887136  ]\n",
      " [0.79977727]\n",
      " [0.6192979 ]\n",
      " [0.2312625 ]\n",
      " [0.8860288 ]\n",
      " [0.86271954]\n",
      " [0.8300048 ]\n",
      " [0.6932268 ]\n",
      " [0.89665264]\n",
      " [0.88026524]\n",
      " [0.76512444]\n",
      " [0.39515913]\n",
      " [0.900228  ]\n",
      " [0.9131969 ]\n",
      " [0.3393662 ]\n",
      " [0.14816713]\n",
      " [0.72852594]\n",
      " [0.31619686]\n",
      " [0.78884363]\n",
      " [0.31170473]\n",
      " [0.501493  ]\n",
      " [0.4688855 ]\n",
      " [0.73639727]\n",
      " [0.87966835]\n",
      " [0.10301837]\n",
      " [0.38509917]\n",
      " [0.6212742 ]\n",
      " [0.4912384 ]\n",
      " [0.5152954 ]\n",
      " [0.7635497 ]\n",
      " [0.16381305]\n",
      " [0.92678165]\n",
      " [0.15934594]\n",
      " [0.86471355]\n",
      " [0.73227596]\n",
      " [0.7134114 ]\n",
      " [0.83254504]\n",
      " [0.7534912 ]\n",
      " [0.8975104 ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.7654809\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cv,_=sess.run([cost,train], \n",
    "                      feed_dict={x:xdata,y:ydata})\n",
    "        if step%200==0:\n",
    "            print(step,cv)\n",
    "    hv,pv,av=sess.run([hf,predicted,accuracy],\n",
    "                feed_dict={x:xdata,y:ydata})\n",
    "    print(hv,pv,av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
