{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape, yTrain.shape, xTest.shape, yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.reshape(60000,784).astype('float32')/255\n",
    "xTest = xTest.reshape(10000,784).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoding\n",
    "yTrain = np_utils.to_categorical(yTrain)\n",
    "yTest = np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 학습과정 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 2.0887 - accuracy: 0.3577\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.0984 - accuracy: 0.7307\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.5889 - accuracy: 0.8328\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.4667 - accuracy: 0.8652\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.4094 - accuracy: 0.8814\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3739 - accuracy: 0.8922\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.3476 - accuracy: 0.9003\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3269 - accuracy: 0.9063\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.3099 - accuracy: 0.9101\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.2945 - accuracy: 0.9146\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.2811 - accuracy: 0.9190\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.2693 - accuracy: 0.9219\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.2579 - accuracy: 0.9254\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.2477 - accuracy: 0.9280\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.2384 - accuracy: 0.9312\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.2296 - accuracy: 0.9333\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.2211 - accuracy: 0.9359\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.2140 - accuracy: 0.9374\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.2068 - accuracy: 0.9398\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.2004 - accuracy: 0.9416\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.1944 - accuracy: 0.9427\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 0.1889 - accuracy: 0.9454\n",
      "Epoch 23/50\n",
      "  256/60000 [..............................] - ETA: 1s - loss: 0.2178 - accuracy: 0.9180"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-98eb4230e01c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 4. 모델 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습\n",
    "hist = model.fit(xTrain, yTrain, batch_size = 256, epochs=50)\n",
    "# fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-439ce0fa5f36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 5. 훈련셋, 검증셋으로 cost 및 accuracy 확인\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(hist.history['val_loss'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "# 5. 훈련셋, 검증셋으로 cost 및 accuracy 확인\n",
    "print(hist.history['loss'])\n",
    "print(hist.history['accuracy'])\n",
    "# print(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f03901eba55b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# pd.Series(hist.history['val_loss']).plot()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(hist.history['loss']).plot()\n",
    "# pd.Series(hist.history['val_loss']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18650195754915475, 0.9458000063896179]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. 모델 평가\n",
    "model.evaluate(xTest, yTest, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.7253436e-04 1.3362978e-05 3.0084630e-03 3.2448219e-03 4.5640380e-07\n",
      "  1.8103773e-04 1.5522426e-08 9.9194920e-01 6.4175336e-05 5.6588347e-04]]\n"
     ]
    }
   ],
   "source": [
    "xhat = xTest[0:1]\n",
    "yhat = model.predict(xhat)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(xTrain.shape, yTrain.shape, xTest.shape, yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrain.reshape(60000,784).astype('float32')/255\n",
    "xTest = xTest.reshape(10000,784).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xTrain, yTrain, test_size=1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784) (10000, 784) (50000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tri = np.random.choice(50000,700)\n",
    "vri = np.random.choice(10000,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain_tri = X_train[tri]\n",
    "yTrain_tri = y_train[tri]\n",
    "xVal = X_test[vri]\n",
    "yVal = y_test[vri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain_tri = np_utils.to_categorical(yTrain_tri)\n",
    "yVal = np_utils.to_categorical(yVal)\n",
    "yTest = np_utils.to_categorical(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=128, activation='relu'))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=50)\n",
    "# EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 177us/step - loss: 2.3065 - accuracy: 0.0986 - val_loss: 2.3054 - val_accuracy: 0.1333\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 2.3030 - accuracy: 0.0971 - val_loss: 2.3029 - val_accuracy: 0.1367\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2997 - accuracy: 0.1029 - val_loss: 2.3005 - val_accuracy: 0.1367\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2966 - accuracy: 0.1057 - val_loss: 2.2982 - val_accuracy: 0.1400\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2935 - accuracy: 0.1129 - val_loss: 2.2958 - val_accuracy: 0.1300\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 2.2904 - accuracy: 0.1143 - val_loss: 2.2933 - val_accuracy: 0.1400\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 2.2874 - accuracy: 0.1171 - val_loss: 2.2908 - val_accuracy: 0.1500\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 47us/step - loss: 2.2842 - accuracy: 0.1243 - val_loss: 2.2883 - val_accuracy: 0.1367\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 46us/step - loss: 2.2809 - accuracy: 0.1400 - val_loss: 2.2857 - val_accuracy: 0.1367\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 47us/step - loss: 2.2777 - accuracy: 0.1529 - val_loss: 2.2830 - val_accuracy: 0.1367\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 48us/step - loss: 2.2744 - accuracy: 0.1629 - val_loss: 2.2802 - val_accuracy: 0.1400\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 48us/step - loss: 2.2710 - accuracy: 0.1700 - val_loss: 2.2771 - val_accuracy: 0.1400\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2672 - accuracy: 0.1786 - val_loss: 2.2739 - val_accuracy: 0.1367\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2634 - accuracy: 0.1686 - val_loss: 2.2707 - val_accuracy: 0.1367\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2595 - accuracy: 0.1686 - val_loss: 2.2672 - val_accuracy: 0.1400\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 46us/step - loss: 2.2556 - accuracy: 0.1729 - val_loss: 2.2635 - val_accuracy: 0.1433\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 2.2515 - accuracy: 0.1786 - val_loss: 2.2595 - val_accuracy: 0.1433\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 2.2472 - accuracy: 0.1857 - val_loss: 2.2555 - val_accuracy: 0.1433\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2425 - accuracy: 0.1929 - val_loss: 2.2512 - val_accuracy: 0.1467\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 47us/step - loss: 2.2378 - accuracy: 0.2014 - val_loss: 2.2466 - val_accuracy: 0.1567\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2329 - accuracy: 0.2086 - val_loss: 2.2419 - val_accuracy: 0.1633\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2278 - accuracy: 0.2086 - val_loss: 2.2368 - val_accuracy: 0.1667\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 2.2224 - accuracy: 0.2043 - val_loss: 2.2314 - val_accuracy: 0.1733\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2166 - accuracy: 0.2129 - val_loss: 2.2257 - val_accuracy: 0.1933\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.2105 - accuracy: 0.2371 - val_loss: 2.2197 - val_accuracy: 0.1900\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 2.2039 - accuracy: 0.2357 - val_loss: 2.2131 - val_accuracy: 0.2200\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 46us/step - loss: 2.1970 - accuracy: 0.2657 - val_loss: 2.2065 - val_accuracy: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.1898 - accuracy: 0.2729 - val_loss: 2.1995 - val_accuracy: 0.2267\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.1820 - accuracy: 0.2729 - val_loss: 2.1916 - val_accuracy: 0.2633\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 46us/step - loss: 2.1737 - accuracy: 0.2971 - val_loss: 2.1834 - val_accuracy: 0.2833\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.1645 - accuracy: 0.3371 - val_loss: 2.1747 - val_accuracy: 0.3100\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 48us/step - loss: 2.1549 - accuracy: 0.3500 - val_loss: 2.1654 - val_accuracy: 0.3367\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 48us/step - loss: 2.1447 - accuracy: 0.3586 - val_loss: 2.1554 - val_accuracy: 0.3500\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.1338 - accuracy: 0.3643 - val_loss: 2.1439 - val_accuracy: 0.4033\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.1219 - accuracy: 0.4143 - val_loss: 2.1322 - val_accuracy: 0.4100\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 2.1091 - accuracy: 0.4300 - val_loss: 2.1203 - val_accuracy: 0.4267\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 46us/step - loss: 2.0960 - accuracy: 0.4471 - val_loss: 2.1065 - val_accuracy: 0.4433\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 48us/step - loss: 2.0812 - accuracy: 0.4657 - val_loss: 2.0916 - val_accuracy: 0.4633\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 2.0658 - accuracy: 0.4886 - val_loss: 2.0760 - val_accuracy: 0.5000\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 2.0488 - accuracy: 0.5143 - val_loss: 2.0586 - val_accuracy: 0.4967\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 2.0307 - accuracy: 0.5329 - val_loss: 2.0406 - val_accuracy: 0.5300\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 2.0113 - accuracy: 0.5500 - val_loss: 2.0219 - val_accuracy: 0.5267\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.9900 - accuracy: 0.5429 - val_loss: 1.9995 - val_accuracy: 0.5433\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 1.9680 - accuracy: 0.5600 - val_loss: 1.9753 - val_accuracy: 0.5567\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 56us/step - loss: 1.9432 - accuracy: 0.6000 - val_loss: 1.9495 - val_accuracy: 0.5667\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 1.9164 - accuracy: 0.6057 - val_loss: 1.9225 - val_accuracy: 0.5667\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 1.8879 - accuracy: 0.6143 - val_loss: 1.8930 - val_accuracy: 0.5667\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 46us/step - loss: 1.8571 - accuracy: 0.6086 - val_loss: 1.8601 - val_accuracy: 0.6000\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 47us/step - loss: 1.8223 - accuracy: 0.6229 - val_loss: 1.8264 - val_accuracy: 0.5800\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 1.7861 - accuracy: 0.6229 - val_loss: 1.7881 - val_accuracy: 0.6000\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.7478 - accuracy: 0.6414 - val_loss: 1.7494 - val_accuracy: 0.5967\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.7080 - accuracy: 0.6471 - val_loss: 1.7060 - val_accuracy: 0.6200\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.6636 - accuracy: 0.6600 - val_loss: 1.6605 - val_accuracy: 0.6133\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 1.6182 - accuracy: 0.6757 - val_loss: 1.6158 - val_accuracy: 0.6233\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1.5705 - accuracy: 0.6814 - val_loss: 1.5672 - val_accuracy: 0.6533\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1.5218 - accuracy: 0.6857 - val_loss: 1.5186 - val_accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1.4748 - accuracy: 0.6986 - val_loss: 1.4685 - val_accuracy: 0.6500\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 1.4214 - accuracy: 0.7100 - val_loss: 1.4237 - val_accuracy: 0.6433\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 46us/step - loss: 1.3768 - accuracy: 0.7057 - val_loss: 1.3790 - val_accuracy: 0.6700\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 1.3265 - accuracy: 0.7057 - val_loss: 1.3270 - val_accuracy: 0.6800\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 1.2771 - accuracy: 0.7171 - val_loss: 1.2760 - val_accuracy: 0.7200\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 47us/step - loss: 1.2291 - accuracy: 0.7443 - val_loss: 1.2249 - val_accuracy: 0.7067\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 54us/step - loss: 1.1824 - accuracy: 0.7314 - val_loss: 1.1785 - val_accuracy: 0.7300\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 1.1396 - accuracy: 0.7543 - val_loss: 1.1481 - val_accuracy: 0.6867\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 1.1031 - accuracy: 0.7429 - val_loss: 1.0964 - val_accuracy: 0.7033\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 47us/step - loss: 1.0572 - accuracy: 0.7557 - val_loss: 1.0642 - val_accuracy: 0.7000\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 47us/step - loss: 1.0160 - accuracy: 0.7614 - val_loss: 1.0199 - val_accuracy: 0.7433\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 0.9813 - accuracy: 0.7600 - val_loss: 0.9876 - val_accuracy: 0.7333\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 50us/step - loss: 0.9484 - accuracy: 0.7743 - val_loss: 0.9552 - val_accuracy: 0.7500\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.9134 - accuracy: 0.7871 - val_loss: 0.9224 - val_accuracy: 0.7767\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 51us/step - loss: 0.8831 - accuracy: 0.7986 - val_loss: 0.9036 - val_accuracy: 0.7433\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 48us/step - loss: 0.8481 - accuracy: 0.7843 - val_loss: 0.8918 - val_accuracy: 0.7333\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 53us/step - loss: 0.8272 - accuracy: 0.7871 - val_loss: 0.8441 - val_accuracy: 0.7567\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 47us/step - loss: 0.7956 - accuracy: 0.8029 - val_loss: 0.8192 - val_accuracy: 0.7567\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.7737 - accuracy: 0.8043 - val_loss: 0.8052 - val_accuracy: 0.7833\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.7483 - accuracy: 0.8214 - val_loss: 0.7863 - val_accuracy: 0.7600\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.7290 - accuracy: 0.8243 - val_loss: 0.7590 - val_accuracy: 0.7700\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.7100 - accuracy: 0.8171 - val_loss: 0.7527 - val_accuracy: 0.7733\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.6914 - accuracy: 0.8229 - val_loss: 0.7397 - val_accuracy: 0.7700\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.6699 - accuracy: 0.8386 - val_loss: 0.7018 - val_accuracy: 0.7967\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.6481 - accuracy: 0.8343 - val_loss: 0.6885 - val_accuracy: 0.7900\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.6332 - accuracy: 0.8343 - val_loss: 0.6950 - val_accuracy: 0.7633\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.6216 - accuracy: 0.8414 - val_loss: 0.6729 - val_accuracy: 0.8000\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.5936 - accuracy: 0.8543 - val_loss: 0.6799 - val_accuracy: 0.7767\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.5910 - accuracy: 0.8557 - val_loss: 0.6310 - val_accuracy: 0.8133\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.5761 - accuracy: 0.8486 - val_loss: 0.6272 - val_accuracy: 0.8133\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.5561 - accuracy: 0.8629 - val_loss: 0.6199 - val_accuracy: 0.8000\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.5437 - accuracy: 0.8600 - val_loss: 0.6082 - val_accuracy: 0.8200\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.5285 - accuracy: 0.8729 - val_loss: 0.5873 - val_accuracy: 0.8300\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 0.5115 - accuracy: 0.8757 - val_loss: 0.5733 - val_accuracy: 0.8400\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 0.5111 - accuracy: 0.8743 - val_loss: 0.5756 - val_accuracy: 0.8300\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 0.4880 - accuracy: 0.8857 - val_loss: 0.5802 - val_accuracy: 0.8133\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 46us/step - loss: 0.5103 - accuracy: 0.8457 - val_loss: 0.5613 - val_accuracy: 0.8267\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 46us/step - loss: 0.4786 - accuracy: 0.8857 - val_loss: 0.5542 - val_accuracy: 0.8233\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 48us/step - loss: 0.4577 - accuracy: 0.9014 - val_loss: 0.5533 - val_accuracy: 0.8300\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 48us/step - loss: 0.4486 - accuracy: 0.8957 - val_loss: 0.5443 - val_accuracy: 0.8400\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 0.4379 - accuracy: 0.8900 - val_loss: 0.5293 - val_accuracy: 0.8333\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 0.4238 - accuracy: 0.8986 - val_loss: 0.5426 - val_accuracy: 0.8267\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.4232 - accuracy: 0.8929 - val_loss: 0.5226 - val_accuracy: 0.8333\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 0.4089 - accuracy: 0.9057 - val_loss: 0.5300 - val_accuracy: 0.8333\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.4137 - accuracy: 0.8957 - val_loss: 0.5395 - val_accuracy: 0.8333\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.3973 - accuracy: 0.8986 - val_loss: 0.5295 - val_accuracy: 0.8367\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.4023 - accuracy: 0.8957 - val_loss: 0.5144 - val_accuracy: 0.8467\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.3763 - accuracy: 0.9171 - val_loss: 0.4981 - val_accuracy: 0.8567\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.3833 - accuracy: 0.9000 - val_loss: 0.5038 - val_accuracy: 0.8467\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.3733 - accuracy: 0.9143 - val_loss: 0.4804 - val_accuracy: 0.8600\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.3589 - accuracy: 0.9171 - val_loss: 0.4749 - val_accuracy: 0.8533\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.3570 - accuracy: 0.9114 - val_loss: 0.4892 - val_accuracy: 0.8467\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.3539 - accuracy: 0.9071 - val_loss: 0.5062 - val_accuracy: 0.8333\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.3409 - accuracy: 0.9200 - val_loss: 0.4949 - val_accuracy: 0.8500\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.3391 - accuracy: 0.9157 - val_loss: 0.4601 - val_accuracy: 0.8533\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 0.3333 - accuracy: 0.9186 - val_loss: 0.4686 - val_accuracy: 0.8633\n",
      "Epoch 113/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 36us/step - loss: 0.3382 - accuracy: 0.9129 - val_loss: 0.4691 - val_accuracy: 0.8500\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.3194 - accuracy: 0.9186 - val_loss: 0.4589 - val_accuracy: 0.8600\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.3213 - accuracy: 0.9143 - val_loss: 0.4843 - val_accuracy: 0.8467\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 34us/step - loss: 0.3093 - accuracy: 0.9229 - val_loss: 0.4644 - val_accuracy: 0.8600\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.2987 - accuracy: 0.9243 - val_loss: 0.4401 - val_accuracy: 0.8633\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.2896 - accuracy: 0.9271 - val_loss: 0.4561 - val_accuracy: 0.8533\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.2971 - accuracy: 0.9300 - val_loss: 0.4426 - val_accuracy: 0.8600\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.2826 - accuracy: 0.9300 - val_loss: 0.4328 - val_accuracy: 0.8700\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.2746 - accuracy: 0.9314 - val_loss: 0.4829 - val_accuracy: 0.8433\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.2808 - accuracy: 0.9343 - val_loss: 0.4817 - val_accuracy: 0.8400\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.2874 - accuracy: 0.9286 - val_loss: 0.4214 - val_accuracy: 0.8600\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.2616 - accuracy: 0.9386 - val_loss: 0.4439 - val_accuracy: 0.8667\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.2592 - accuracy: 0.9443 - val_loss: 0.4210 - val_accuracy: 0.8633\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.2537 - accuracy: 0.9371 - val_loss: 0.4379 - val_accuracy: 0.8500\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.2506 - accuracy: 0.9500 - val_loss: 0.4325 - val_accuracy: 0.8633\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.2457 - accuracy: 0.9400 - val_loss: 0.4570 - val_accuracy: 0.8667\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.2513 - accuracy: 0.9457 - val_loss: 0.4265 - val_accuracy: 0.8600\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.2375 - accuracy: 0.9457 - val_loss: 0.4462 - val_accuracy: 0.8467\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 0.2407 - accuracy: 0.9429 - val_loss: 0.4124 - val_accuracy: 0.8767\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.2325 - accuracy: 0.9457 - val_loss: 0.4042 - val_accuracy: 0.8733\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.2198 - accuracy: 0.9529 - val_loss: 0.4197 - val_accuracy: 0.8667\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.2176 - accuracy: 0.9571 - val_loss: 0.4201 - val_accuracy: 0.8567\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.2227 - accuracy: 0.9486 - val_loss: 0.4162 - val_accuracy: 0.8567\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.2185 - accuracy: 0.9457 - val_loss: 0.4223 - val_accuracy: 0.8633\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.2107 - accuracy: 0.9586 - val_loss: 0.4200 - val_accuracy: 0.8767\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.2032 - accuracy: 0.9629 - val_loss: 0.4325 - val_accuracy: 0.8700\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.2039 - accuracy: 0.9571 - val_loss: 0.4035 - val_accuracy: 0.8733\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.1974 - accuracy: 0.9614 - val_loss: 0.4073 - val_accuracy: 0.8833\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1962 - accuracy: 0.9671 - val_loss: 0.4186 - val_accuracy: 0.8667\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 0.2016 - accuracy: 0.9557 - val_loss: 0.4156 - val_accuracy: 0.8600\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 47us/step - loss: 0.1863 - accuracy: 0.9629 - val_loss: 0.4238 - val_accuracy: 0.8633\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 47us/step - loss: 0.1871 - accuracy: 0.9629 - val_loss: 0.3927 - val_accuracy: 0.8800\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 0.1897 - accuracy: 0.9643 - val_loss: 0.4139 - val_accuracy: 0.8633\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.1784 - accuracy: 0.9657 - val_loss: 0.4333 - val_accuracy: 0.8800\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.1762 - accuracy: 0.9657 - val_loss: 0.3988 - val_accuracy: 0.8600\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 0.1729 - accuracy: 0.9686 - val_loss: 0.3920 - val_accuracy: 0.8667\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1658 - accuracy: 0.9671 - val_loss: 0.4026 - val_accuracy: 0.8633\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1677 - accuracy: 0.9686 - val_loss: 0.4287 - val_accuracy: 0.8867\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.1778 - accuracy: 0.9614 - val_loss: 0.4083 - val_accuracy: 0.8667\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.1611 - accuracy: 0.9671 - val_loss: 0.3960 - val_accuracy: 0.8733\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1543 - accuracy: 0.9714 - val_loss: 0.4146 - val_accuracy: 0.8933\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.1559 - accuracy: 0.9714 - val_loss: 0.3857 - val_accuracy: 0.8667\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1460 - accuracy: 0.9743 - val_loss: 0.3995 - val_accuracy: 0.8733\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1462 - accuracy: 0.9729 - val_loss: 0.3891 - val_accuracy: 0.8933\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.1492 - accuracy: 0.9714 - val_loss: 0.3896 - val_accuracy: 0.8833\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1394 - accuracy: 0.9743 - val_loss: 0.3982 - val_accuracy: 0.8833\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1411 - accuracy: 0.9757 - val_loss: 0.3895 - val_accuracy: 0.8967\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.1391 - accuracy: 0.9729 - val_loss: 0.3932 - val_accuracy: 0.8733\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1429 - accuracy: 0.9714 - val_loss: 0.3979 - val_accuracy: 0.8900\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.1315 - accuracy: 0.9743 - val_loss: 0.3873 - val_accuracy: 0.8967\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 0.1287 - accuracy: 0.9743 - val_loss: 0.4287 - val_accuracy: 0.8700\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1366 - accuracy: 0.9714 - val_loss: 0.3969 - val_accuracy: 0.8800\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.1246 - accuracy: 0.9800 - val_loss: 0.3983 - val_accuracy: 0.8900\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.1229 - accuracy: 0.9771 - val_loss: 0.3856 - val_accuracy: 0.8867\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.1188 - accuracy: 0.9800 - val_loss: 0.4022 - val_accuracy: 0.8700\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.1174 - accuracy: 0.9814 - val_loss: 0.3804 - val_accuracy: 0.8833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1141 - accuracy: 0.9786 - val_loss: 0.4004 - val_accuracy: 0.8767\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.1187 - accuracy: 0.9800 - val_loss: 0.3910 - val_accuracy: 0.8900\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.1114 - accuracy: 0.9843 - val_loss: 0.3767 - val_accuracy: 0.8833\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.1169 - accuracy: 0.9786 - val_loss: 0.3928 - val_accuracy: 0.8700\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.1082 - accuracy: 0.9829 - val_loss: 0.3906 - val_accuracy: 0.8867\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.1078 - accuracy: 0.9786 - val_loss: 0.3893 - val_accuracy: 0.8800\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.1030 - accuracy: 0.9843 - val_loss: 0.4013 - val_accuracy: 0.8900\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.1007 - accuracy: 0.9886 - val_loss: 0.3867 - val_accuracy: 0.8800\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 34us/step - loss: 0.1000 - accuracy: 0.9800 - val_loss: 0.3972 - val_accuracy: 0.8667\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 34us/step - loss: 0.0967 - accuracy: 0.9871 - val_loss: 0.3902 - val_accuracy: 0.8900\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0962 - accuracy: 0.9900 - val_loss: 0.3945 - val_accuracy: 0.8733\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.0973 - accuracy: 0.9843 - val_loss: 0.4252 - val_accuracy: 0.8700\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.1014 - accuracy: 0.9857 - val_loss: 0.3880 - val_accuracy: 0.8900\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.0905 - accuracy: 0.9871 - val_loss: 0.3787 - val_accuracy: 0.9000\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0900 - accuracy: 0.9886 - val_loss: 0.3943 - val_accuracy: 0.8800\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0909 - accuracy: 0.9871 - val_loss: 0.3808 - val_accuracy: 0.8833\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0864 - accuracy: 0.9929 - val_loss: 0.3909 - val_accuracy: 0.8767\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0848 - accuracy: 0.9929 - val_loss: 0.3788 - val_accuracy: 0.8933\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0851 - accuracy: 0.9900 - val_loss: 0.3942 - val_accuracy: 0.8833\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0801 - accuracy: 0.9943 - val_loss: 0.3862 - val_accuracy: 0.8900\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0836 - accuracy: 0.9900 - val_loss: 0.3932 - val_accuracy: 0.8800\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.0783 - accuracy: 0.9929 - val_loss: 0.3763 - val_accuracy: 0.8967\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 44us/step - loss: 0.0771 - accuracy: 0.9929 - val_loss: 0.3971 - val_accuracy: 0.8767\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0762 - accuracy: 0.9957 - val_loss: 0.3822 - val_accuracy: 0.8933\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0761 - accuracy: 0.9914 - val_loss: 0.3734 - val_accuracy: 0.8933\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0734 - accuracy: 0.9914 - val_loss: 0.3859 - val_accuracy: 0.8833\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0710 - accuracy: 0.9957 - val_loss: 0.3765 - val_accuracy: 0.8967\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0711 - accuracy: 0.9943 - val_loss: 0.3905 - val_accuracy: 0.8967\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.0694 - accuracy: 0.9957 - val_loss: 0.3749 - val_accuracy: 0.9033\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.0674 - accuracy: 0.9943 - val_loss: 0.3946 - val_accuracy: 0.9000\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0696 - accuracy: 0.9943 - val_loss: 0.4005 - val_accuracy: 0.8667\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0677 - accuracy: 0.9943 - val_loss: 0.3864 - val_accuracy: 0.8967\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0631 - accuracy: 0.9971 - val_loss: 0.3857 - val_accuracy: 0.8933\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.0617 - accuracy: 0.9971 - val_loss: 0.3823 - val_accuracy: 0.8933\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.0618 - accuracy: 0.9971 - val_loss: 0.3842 - val_accuracy: 0.9033\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0608 - accuracy: 0.9971 - val_loss: 0.3879 - val_accuracy: 0.8833\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0581 - accuracy: 0.9971 - val_loss: 0.3764 - val_accuracy: 0.8933\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.0588 - accuracy: 0.9957 - val_loss: 0.3840 - val_accuracy: 0.9000\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0561 - accuracy: 0.9971 - val_loss: 0.3848 - val_accuracy: 0.9000\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0556 - accuracy: 0.9957 - val_loss: 0.3819 - val_accuracy: 0.8900\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0540 - accuracy: 0.9971 - val_loss: 0.3772 - val_accuracy: 0.8967\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0544 - accuracy: 0.9971 - val_loss: 0.3857 - val_accuracy: 0.8933\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0527 - accuracy: 0.9971 - val_loss: 0.3941 - val_accuracy: 0.8900\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.0525 - accuracy: 0.9971 - val_loss: 0.3844 - val_accuracy: 0.8967\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.0533 - accuracy: 0.9971 - val_loss: 0.3796 - val_accuracy: 0.8933\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.0501 - accuracy: 0.9971 - val_loss: 0.3825 - val_accuracy: 0.8967\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0493 - accuracy: 0.9971 - val_loss: 0.3833 - val_accuracy: 0.8933\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0507 - accuracy: 0.9971 - val_loss: 0.3803 - val_accuracy: 0.8967\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0482 - accuracy: 0.9971 - val_loss: 0.3959 - val_accuracy: 0.8900\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.0474 - accuracy: 0.9971 - val_loss: 0.3855 - val_accuracy: 0.9067\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0467 - accuracy: 0.9971 - val_loss: 0.3846 - val_accuracy: 0.8967\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0456 - accuracy: 0.9971 - val_loss: 0.3845 - val_accuracy: 0.9067\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.0446 - accuracy: 0.9971 - val_loss: 0.3921 - val_accuracy: 0.8933\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0452 - accuracy: 0.9971 - val_loss: 0.3844 - val_accuracy: 0.9000\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0429 - accuracy: 0.9971 - val_loss: 0.3818 - val_accuracy: 0.9000\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0429 - accuracy: 0.9971 - val_loss: 0.3828 - val_accuracy: 0.9067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.0424 - accuracy: 0.9971 - val_loss: 0.3919 - val_accuracy: 0.8867\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0414 - accuracy: 0.9986 - val_loss: 0.3863 - val_accuracy: 0.9000\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0415 - accuracy: 0.9986 - val_loss: 0.3855 - val_accuracy: 0.8967\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0404 - accuracy: 0.9986 - val_loss: 0.3862 - val_accuracy: 0.9000\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 37us/step - loss: 0.0394 - accuracy: 0.9971 - val_loss: 0.3829 - val_accuracy: 0.8967\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0382 - accuracy: 0.9986 - val_loss: 0.3854 - val_accuracy: 0.9033\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 36us/step - loss: 0.0383 - accuracy: 0.9986 - val_loss: 0.3839 - val_accuracy: 0.9033\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.8933\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.8800\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.8867\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0373 - accuracy: 0.9986 - val_loss: 0.3854 - val_accuracy: 0.9033\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.8967\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0346 - accuracy: 0.9986 - val_loss: 0.3962 - val_accuracy: 0.8900\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9067\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 43us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9067\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.8967\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 38us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9033\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 40us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.8967\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 41us/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9033\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(xTrain_tri, yTrain_tri, epochs=3000, batch_size=128,validation_data=(xVal, yVal), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train_loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='test_loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figs, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx() # 동일안 axis를 만들 수 있음\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train_loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='train_loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train_accuracy')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val_accuracy')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 20us/step\n",
      "cost :  0.5259587879300117\n",
      "accuracy :  0.8593000173568726\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(xTest, yTest, batch_size=64)\n",
    "print('cost : ', res[0])\n",
    "print('accuracy : ', res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15878108212978378680]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "폐암 데이터 활용 실용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(r'C:\\Users\\chan\\Desktop\\dataset\\ThoraricSurgery.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 , ...,   0.  ,  62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88, ...,   0.  ,  60.  ,   0.  ],\n",
       "       [  8.  ,   2.  ,   3.19, ...,   0.  ,  66.  ,   1.  ],\n",
       "       ...,\n",
       "       [406.  ,   6.  ,   5.36, ...,   0.  ,  62.  ,   0.  ],\n",
       "       [ 25.  ,   8.  ,   4.32, ...,   0.  ,  58.  ,   1.  ],\n",
       "       [447.  ,   8.  ,   5.2 , ...,   0.  ,  49.  ,   0.  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:,:17]\n",
    "y = data[:,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(17,), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) # 출력 노드 1 : 0또는 1을 나타내는 값이 1개 있다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "             optimizer='adam', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "470/470 [==============================] - 5s 10ms/step - loss: 0.1496 - accuracy: 0.8426\n",
      "Epoch 2/30\n",
      "470/470 [==============================] - 4s 10ms/step - loss: 0.1489 - accuracy: 0.8511\n",
      "Epoch 3/30\n",
      " 90/470 [====>.........................] - ETA: 3s - loss: 0.1000 - accuracy: 0.9000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-4b630a106589>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x,y,epochs=30, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt(r\"C:\\Users\\chan\\Desktop\\dataset\" + '\\data-03-diabetes.csv',delimiter=',')\n",
    "xdata = xy[:,0:-1]\n",
    "ydata = xy[:,[-1]] # -1을 []로 묶어주어야 열로 잡힘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8) (759, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xdata.shape, ydata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multinomial classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 class 에 대해서 분류하는 분류기준이 필요함\n",
    "\n",
    "softmax_cross_entropy with logistic regressions\n",
    "A : 분류를 위한 w1*x1+b1\n",
    "B : 분류를 위한 w2*x2+b2\n",
    "C : 분류를 위한 w3*x3+b3\n",
    "이런 식으로 3개가 필요함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759, 8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([8,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "x = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "cost = -tf.reduce_mean(y*tf.log(hf)+(1-y)*tf.log(1-hf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(1e-2).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hf>0.5, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y),dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1407136\n",
      "200 0.69895405\n",
      "400 0.6129875\n",
      "600 0.58966464\n",
      "800 0.5775765\n",
      "1000 0.5683252\n",
      "1200 0.56033146\n",
      "1400 0.5532171\n",
      "1600 0.5468364\n",
      "1800 0.5410971\n",
      "2000 0.5359249\n",
      "2200 0.5312555\n",
      "2400 0.527033\n",
      "2600 0.52320784\n",
      "2800 0.5197369\n",
      "3000 0.51658195\n",
      "3200 0.5137094\n",
      "3400 0.51108956\n",
      "3600 0.5086962\n",
      "3800 0.50650626\n",
      "4000 0.5044991\n",
      "4200 0.50265646\n",
      "4400 0.5009622\n",
      "4600 0.49940205\n",
      "4800 0.49796295\n",
      "5000 0.4966337\n",
      "5200 0.49540386\n",
      "5400 0.49426457\n",
      "5600 0.49320737\n",
      "5800 0.49222496\n",
      "6000 0.49131086\n",
      "6200 0.49045902\n",
      "6400 0.48966414\n",
      "6600 0.48892146\n",
      "6800 0.48822647\n",
      "7000 0.4875754\n",
      "7200 0.4869646\n",
      "7400 0.4863909\n",
      "7600 0.48585123\n",
      "7800 0.48534313\n",
      "8000 0.4848641\n",
      "8200 0.48441195\n",
      "8400 0.4839845\n",
      "8600 0.48358017\n",
      "8800 0.48319724\n",
      "9000 0.48283404\n",
      "9200 0.48248935\n",
      "9400 0.48216176\n",
      "9600 0.4818502\n",
      "9800 0.48155352\n",
      "10000 0.48127064\n",
      "[[0.43019226]\n",
      " [0.9499494 ]\n",
      " [0.14363043]\n",
      " [0.9513266 ]\n",
      " [0.14334138]\n",
      " [0.7518556 ]\n",
      " [0.937652  ]\n",
      " [0.5681068 ]\n",
      " [0.23565125]\n",
      " [0.55907446]\n",
      " [0.7555232 ]\n",
      " [0.1374787 ]\n",
      " [0.2355926 ]\n",
      " [0.39964998]\n",
      " [0.7416595 ]\n",
      " [0.45283103]\n",
      " [0.7328037 ]\n",
      " [0.844156  ]\n",
      " [0.81778485]\n",
      " [0.6079186 ]\n",
      " [0.7160802 ]\n",
      " [0.08658897]\n",
      " [0.66390634]\n",
      " [0.6130624 ]\n",
      " [0.3577945 ]\n",
      " [0.94070554]\n",
      " [0.45325333]\n",
      " [0.68368876]\n",
      " [0.79314625]\n",
      " [0.39585748]\n",
      " [0.9517058 ]\n",
      " [0.8774449 ]\n",
      " [0.6028065 ]\n",
      " [0.81085205]\n",
      " [0.32266912]\n",
      " [0.6953545 ]\n",
      " [0.8743496 ]\n",
      " [0.56604797]\n",
      " [0.34705293]\n",
      " [0.38934162]\n",
      " [0.8764314 ]\n",
      " [0.17035894]\n",
      " [0.33298057]\n",
      " [0.05129058]\n",
      " [0.55451566]\n",
      " [0.9575326 ]\n",
      " [0.76487637]\n",
      " [0.7125221 ]\n",
      " [0.94013715]\n",
      " [0.9267468 ]\n",
      " [0.9229506 ]\n",
      " [0.20827709]\n",
      " [0.32016453]\n",
      " [0.9806886 ]\n",
      " [0.15648209]\n",
      " [0.44767606]\n",
      " [0.13614735]\n",
      " [0.67014635]\n",
      " [0.9063066 ]\n",
      " [0.4796844 ]\n",
      " [0.96255386]\n",
      " [0.63237375]\n",
      " [0.6652671 ]\n",
      " [0.8872495 ]\n",
      " [0.66478044]\n",
      " [0.69706154]\n",
      " [0.9552982 ]\n",
      " [0.63756955]\n",
      " [0.86832005]\n",
      " [0.5834511 ]\n",
      " [0.27495354]\n",
      " [0.7532144 ]\n",
      " [0.94979626]\n",
      " [0.94401735]\n",
      " [0.9125433 ]\n",
      " [0.8455354 ]\n",
      " [0.40368155]\n",
      " [0.8941584 ]\n",
      " [0.91145253]\n",
      " [0.9378991 ]\n",
      " [0.8679973 ]\n",
      " [0.833504  ]\n",
      " [0.44760078]\n",
      " [0.8190726 ]\n",
      " [0.5155375 ]\n",
      " [0.8813787 ]\n",
      " [0.31123862]\n",
      " [0.9277433 ]\n",
      " [0.9505733 ]\n",
      " [0.79279596]\n",
      " [0.8218046 ]\n",
      " [0.6594167 ]\n",
      " [0.7042015 ]\n",
      " [0.5555903 ]\n",
      " [0.9315818 ]\n",
      " [0.97651064]\n",
      " [0.86444515]\n",
      " [0.6443483 ]\n",
      " [0.25867757]\n",
      " [0.6041203 ]\n",
      " [0.612241  ]\n",
      " [0.96338725]\n",
      " [0.83210707]\n",
      " [0.7585446 ]\n",
      " [0.91791546]\n",
      " [0.6258626 ]\n",
      " [0.917     ]\n",
      " [0.809429  ]\n",
      " [0.3988428 ]\n",
      " [0.37179697]\n",
      " [0.9309059 ]\n",
      " [0.8986433 ]\n",
      " [0.32757896]\n",
      " [0.47285563]\n",
      " [0.64644563]\n",
      " [0.8575758 ]\n",
      " [0.89719737]\n",
      " [0.92614484]\n",
      " [0.09543514]\n",
      " [0.7455812 ]\n",
      " [0.8525054 ]\n",
      " [0.6459658 ]\n",
      " [0.6208225 ]\n",
      " [0.82532626]\n",
      " [0.71368986]\n",
      " [0.81401676]\n",
      " [0.84490967]\n",
      " [0.6530111 ]\n",
      " [0.4509232 ]\n",
      " [0.38321057]\n",
      " [0.3569429 ]\n",
      " [0.84134793]\n",
      " [0.93364406]\n",
      " [0.83053106]\n",
      " [0.7701169 ]\n",
      " [0.8228059 ]\n",
      " [0.43196097]\n",
      " [0.83235294]\n",
      " [0.74450886]\n",
      " [0.80687493]\n",
      " [0.86580944]\n",
      " [0.6247816 ]\n",
      " [0.5207617 ]\n",
      " [0.7755635 ]\n",
      " [0.9389641 ]\n",
      " [0.74347675]\n",
      " [0.46997204]\n",
      " [0.95568544]\n",
      " [0.6007642 ]\n",
      " [0.7751626 ]\n",
      " [0.22239369]\n",
      " [0.44809347]\n",
      " [0.09727818]\n",
      " [0.27284887]\n",
      " [0.91919506]\n",
      " [0.87244433]\n",
      " [0.9460246 ]\n",
      " [0.06237153]\n",
      " [0.53905153]\n",
      " [0.75851095]\n",
      " [0.63266546]\n",
      " [0.9142355 ]\n",
      " [0.40900117]\n",
      " [0.81993395]\n",
      " [0.6383248 ]\n",
      " [0.65169483]\n",
      " [0.7422877 ]\n",
      " [0.87849206]\n",
      " [0.7917344 ]\n",
      " [0.5889341 ]\n",
      " [0.92432356]\n",
      " [0.88705313]\n",
      " [0.9557453 ]\n",
      " [0.13689391]\n",
      " [0.8519657 ]\n",
      " [0.2764811 ]\n",
      " [0.42541075]\n",
      " [0.4367608 ]\n",
      " [0.8917577 ]\n",
      " [0.62560093]\n",
      " [0.93059886]\n",
      " [0.92010576]\n",
      " [0.5805983 ]\n",
      " [0.12404148]\n",
      " [0.17847337]\n",
      " [0.5901003 ]\n",
      " [0.67773616]\n",
      " [0.5769501 ]\n",
      " [0.8406177 ]\n",
      " [0.5216428 ]\n",
      " [0.30077815]\n",
      " [0.21493018]\n",
      " [0.92179567]\n",
      " [0.33794305]\n",
      " [0.88407964]\n",
      " [0.88782495]\n",
      " [0.67669713]\n",
      " [0.62146646]\n",
      " [0.7076595 ]\n",
      " [0.612455  ]\n",
      " [0.7495242 ]\n",
      " [0.9423766 ]\n",
      " [0.7920876 ]\n",
      " [0.8361774 ]\n",
      " [0.10709822]\n",
      " [0.33848494]\n",
      " [0.91844094]\n",
      " [0.19438128]\n",
      " [0.95689243]\n",
      " [0.25737002]\n",
      " [0.26750943]\n",
      " [0.4128688 ]\n",
      " [0.68746024]\n",
      " [0.16727278]\n",
      " [0.71720874]\n",
      " [0.6714155 ]\n",
      " [0.8711017 ]\n",
      " [0.7034254 ]\n",
      " [0.1443745 ]\n",
      " [0.38842946]\n",
      " [0.6802794 ]\n",
      " [0.46783724]\n",
      " [0.9248686 ]\n",
      " [0.94198066]\n",
      " [0.70826846]\n",
      " [0.35381582]\n",
      " [0.04767177]\n",
      " [0.6172963 ]\n",
      " [0.38801593]\n",
      " [0.5154996 ]\n",
      " [0.95315963]\n",
      " [0.6521009 ]\n",
      " [0.949796  ]\n",
      " [0.21330023]\n",
      " [0.14142913]\n",
      " [0.2752689 ]\n",
      " [0.73017687]\n",
      " [0.9483696 ]\n",
      " [0.8775122 ]\n",
      " [0.60337967]\n",
      " [0.6348981 ]\n",
      " [0.5750076 ]\n",
      " [0.14970079]\n",
      " [0.52176434]\n",
      " [0.19026028]\n",
      " [0.5878162 ]\n",
      " [0.91319716]\n",
      " [0.6556383 ]\n",
      " [0.7180911 ]\n",
      " [0.95376486]\n",
      " [0.84818166]\n",
      " [0.7904113 ]\n",
      " [0.8277135 ]\n",
      " [0.79478246]\n",
      " [0.8928908 ]\n",
      " [0.3507095 ]\n",
      " [0.33358088]\n",
      " [0.49709585]\n",
      " [0.8612201 ]\n",
      " [0.7474403 ]\n",
      " [0.6894999 ]\n",
      " [0.8309032 ]\n",
      " [0.28808284]\n",
      " [0.54707944]\n",
      " [0.59909606]\n",
      " [0.5959927 ]\n",
      " [0.5117016 ]\n",
      " [0.89238566]\n",
      " [0.77037805]\n",
      " [0.9355383 ]\n",
      " [0.5445289 ]\n",
      " [0.7539392 ]\n",
      " [0.83560926]\n",
      " [0.7862902 ]\n",
      " [0.6980716 ]\n",
      " [0.88764536]\n",
      " [0.31498986]\n",
      " [0.5257969 ]\n",
      " [0.68018925]\n",
      " [0.32711583]\n",
      " [0.84610975]\n",
      " [0.33338585]\n",
      " [0.67142034]\n",
      " [0.9255256 ]\n",
      " [0.7500114 ]\n",
      " [0.863286  ]\n",
      " [0.641804  ]\n",
      " [0.5208636 ]\n",
      " [0.62557274]\n",
      " [0.31923997]\n",
      " [0.37745723]\n",
      " [0.63366437]\n",
      " [0.58877265]\n",
      " [0.6321906 ]\n",
      " [0.6208781 ]\n",
      " [0.15591542]\n",
      " [0.6203809 ]\n",
      " [0.90600485]\n",
      " [0.5991196 ]\n",
      " [0.58894646]\n",
      " [0.7587585 ]\n",
      " [0.35454667]\n",
      " [0.677213  ]\n",
      " [0.4668685 ]\n",
      " [0.7190617 ]\n",
      " [0.9246602 ]\n",
      " [0.62714726]\n",
      " [0.64743567]\n",
      " [0.8561732 ]\n",
      " [0.6367403 ]\n",
      " [0.8585424 ]\n",
      " [0.9421242 ]\n",
      " [0.25325736]\n",
      " [0.77393293]\n",
      " [0.18624164]\n",
      " [0.7787873 ]\n",
      " [0.8508898 ]\n",
      " [0.72012734]\n",
      " [0.22806624]\n",
      " [0.8551469 ]\n",
      " [0.6987257 ]\n",
      " [0.75034153]\n",
      " [0.13190006]\n",
      " [0.8425355 ]\n",
      " [0.8257595 ]\n",
      " [0.6208536 ]\n",
      " [0.9472872 ]\n",
      " [0.25459337]\n",
      " [0.66429436]\n",
      " [0.9470047 ]\n",
      " [0.17781489]\n",
      " [0.47180265]\n",
      " [0.71153843]\n",
      " [0.2595862 ]\n",
      " [0.1571798 ]\n",
      " [0.8372007 ]\n",
      " [0.92441237]\n",
      " [0.89534444]\n",
      " [0.64762485]\n",
      " [0.7201515 ]\n",
      " [0.5459226 ]\n",
      " [0.7251811 ]\n",
      " [0.8033117 ]\n",
      " [0.92629826]\n",
      " [0.81999975]\n",
      " [0.8255135 ]\n",
      " [0.5873388 ]\n",
      " [0.96793824]\n",
      " [0.94582105]\n",
      " [0.8214267 ]\n",
      " [0.23147137]\n",
      " [0.6620271 ]\n",
      " [0.35998756]\n",
      " [0.71127796]\n",
      " [0.16941682]\n",
      " [0.19200644]\n",
      " [0.40561914]\n",
      " [0.8074194 ]\n",
      " [0.4239054 ]\n",
      " [0.575474  ]\n",
      " [0.8304561 ]\n",
      " [0.63130385]\n",
      " [0.87716436]\n",
      " [0.9542798 ]\n",
      " [0.77953345]\n",
      " [0.09718192]\n",
      " [0.44816113]\n",
      " [0.84858876]\n",
      " [0.8431541 ]\n",
      " [0.6469357 ]\n",
      " [0.26308885]\n",
      " [0.86617696]\n",
      " [0.9003682 ]\n",
      " [0.31997487]\n",
      " [0.63030016]\n",
      " [0.8397543 ]\n",
      " [0.850334  ]\n",
      " [0.89659804]\n",
      " [0.9093176 ]\n",
      " [0.85775614]\n",
      " [0.9060569 ]\n",
      " [0.7387464 ]\n",
      " [0.7133917 ]\n",
      " [0.5811332 ]\n",
      " [0.8420892 ]\n",
      " [0.8989757 ]\n",
      " [0.22821753]\n",
      " [0.858195  ]\n",
      " [0.8669457 ]\n",
      " [0.31164622]\n",
      " [0.6350177 ]\n",
      " [0.85500014]\n",
      " [0.5284393 ]\n",
      " [0.922496  ]\n",
      " [0.24785456]\n",
      " [0.8552231 ]\n",
      " [0.55962646]\n",
      " [0.9157678 ]\n",
      " [0.3140057 ]\n",
      " [0.70034915]\n",
      " [0.74406844]\n",
      " [0.76057136]\n",
      " [0.06444138]\n",
      " [0.2610225 ]\n",
      " [0.7450251 ]\n",
      " [0.8349208 ]\n",
      " [0.54116   ]\n",
      " [0.7654348 ]\n",
      " [0.42655584]\n",
      " [0.3785208 ]\n",
      " [0.8966299 ]\n",
      " [0.52029216]\n",
      " [0.9314407 ]\n",
      " [0.7764637 ]\n",
      " [0.7071487 ]\n",
      " [0.928423  ]\n",
      " [0.6258174 ]\n",
      " [0.8604515 ]\n",
      " [0.3085092 ]\n",
      " [0.23144712]\n",
      " [0.7542695 ]\n",
      " [0.37178603]\n",
      " [0.39770028]\n",
      " [0.9255233 ]\n",
      " [0.899604  ]\n",
      " [0.9259066 ]\n",
      " [0.96044266]\n",
      " [0.67777157]\n",
      " [0.93886197]\n",
      " [0.3425196 ]\n",
      " [0.36428234]\n",
      " [0.44713908]\n",
      " [0.96256405]\n",
      " [0.6488202 ]\n",
      " [0.16680022]\n",
      " [0.93438566]\n",
      " [0.7961247 ]\n",
      " [0.5801992 ]\n",
      " [0.85173285]\n",
      " [0.01248314]\n",
      " [0.9272378 ]\n",
      " [0.7299984 ]\n",
      " [0.68768954]\n",
      " [0.71560425]\n",
      " [0.9677862 ]\n",
      " [0.63178796]\n",
      " [0.7838698 ]\n",
      " [0.75703746]\n",
      " [0.86146224]\n",
      " [0.14027038]\n",
      " [0.6492882 ]\n",
      " [0.90293294]\n",
      " [0.53370106]\n",
      " [0.67817837]\n",
      " [0.95477027]\n",
      " [0.8355097 ]\n",
      " [0.91494447]\n",
      " [0.50063086]\n",
      " [0.738187  ]\n",
      " [0.9358558 ]\n",
      " [0.71157354]\n",
      " [0.6181724 ]\n",
      " [0.26864234]\n",
      " [0.54071134]\n",
      " [0.50246197]\n",
      " [0.6507375 ]\n",
      " [0.5256139 ]\n",
      " [0.77651745]\n",
      " [0.60382867]\n",
      " [0.7881433 ]\n",
      " [0.80369496]\n",
      " [0.6434945 ]\n",
      " [0.7158009 ]\n",
      " [0.4945397 ]\n",
      " [0.6108862 ]\n",
      " [0.93177   ]\n",
      " [0.8441193 ]\n",
      " [0.24311313]\n",
      " [0.3915747 ]\n",
      " [0.59687245]\n",
      " [0.10671715]\n",
      " [0.9187825 ]\n",
      " [0.1102416 ]\n",
      " [0.91152203]\n",
      " [0.92764467]\n",
      " [0.8680907 ]\n",
      " [0.6872023 ]\n",
      " [0.9119226 ]\n",
      " [0.32134917]\n",
      " [0.7731752 ]\n",
      " [0.94943   ]\n",
      " [0.19341238]\n",
      " [0.37474716]\n",
      " [0.8803167 ]\n",
      " [0.9190062 ]\n",
      " [0.7258566 ]\n",
      " [0.80832446]\n",
      " [0.87174773]\n",
      " [0.8328048 ]\n",
      " [0.19718073]\n",
      " [0.773529  ]\n",
      " [0.9135734 ]\n",
      " [0.6241407 ]\n",
      " [0.82084715]\n",
      " [0.65644395]\n",
      " [0.81788826]\n",
      " [0.8830329 ]\n",
      " [0.924584  ]\n",
      " [0.5425455 ]\n",
      " [0.35712612]\n",
      " [0.77661294]\n",
      " [0.7990662 ]\n",
      " [0.9675877 ]\n",
      " [0.7493728 ]\n",
      " [0.6938448 ]\n",
      " [0.398731  ]\n",
      " [0.71200734]\n",
      " [0.9498881 ]\n",
      " [0.95108134]\n",
      " [0.8874398 ]\n",
      " [0.64672947]\n",
      " [0.62866974]\n",
      " [0.7986981 ]\n",
      " [0.51767313]\n",
      " [0.8208249 ]\n",
      " [0.81357616]\n",
      " [0.9053876 ]\n",
      " [0.5996764 ]\n",
      " [0.723327  ]\n",
      " [0.9160429 ]\n",
      " [0.4477686 ]\n",
      " [0.51288646]\n",
      " [0.67312795]\n",
      " [0.7286355 ]\n",
      " [0.7422925 ]\n",
      " [0.91976047]\n",
      " [0.9317242 ]\n",
      " [0.15163244]\n",
      " [0.13063617]\n",
      " [0.7493869 ]\n",
      " [0.44977057]\n",
      " [0.23503016]\n",
      " [0.88482815]\n",
      " [0.90945625]\n",
      " [0.7330585 ]\n",
      " [0.93741256]\n",
      " [0.93439597]\n",
      " [0.7166873 ]\n",
      " [0.8895575 ]\n",
      " [0.7061214 ]\n",
      " [0.61686325]\n",
      " [0.7678764 ]\n",
      " [0.6317451 ]\n",
      " [0.08384891]\n",
      " [0.91234213]\n",
      " [0.86480755]\n",
      " [0.7371494 ]\n",
      " [0.91943   ]\n",
      " [0.88208413]\n",
      " [0.8805088 ]\n",
      " [0.5212979 ]\n",
      " [0.6475629 ]\n",
      " [0.9163306 ]\n",
      " [0.75074226]\n",
      " [0.8230542 ]\n",
      " [0.9195833 ]\n",
      " [0.6215196 ]\n",
      " [0.7526646 ]\n",
      " [0.8011267 ]\n",
      " [0.6500194 ]\n",
      " [0.46020994]\n",
      " [0.05941187]\n",
      " [0.27592373]\n",
      " [0.84439576]\n",
      " [0.6740797 ]\n",
      " [0.7157183 ]\n",
      " [0.6556327 ]\n",
      " [0.95718896]\n",
      " [0.40741438]\n",
      " [0.80350304]\n",
      " [0.25403133]\n",
      " [0.89158463]\n",
      " [0.4122027 ]\n",
      " [0.7643476 ]\n",
      " [0.61332595]\n",
      " [0.87671894]\n",
      " [0.5502281 ]\n",
      " [0.17476998]\n",
      " [0.85565096]\n",
      " [0.9385205 ]\n",
      " [0.37493137]\n",
      " [0.91119295]\n",
      " [0.9135097 ]\n",
      " [0.84474677]\n",
      " [0.8382461 ]\n",
      " [0.37882686]\n",
      " [0.2507887 ]\n",
      " [0.7723567 ]\n",
      " [0.1704596 ]\n",
      " [0.9426485 ]\n",
      " [0.3035808 ]\n",
      " [0.9290497 ]\n",
      " [0.8809366 ]\n",
      " [0.36983845]\n",
      " [0.18498135]\n",
      " [0.75728655]\n",
      " [0.38508886]\n",
      " [0.8427909 ]\n",
      " [0.71470326]\n",
      " [0.9794841 ]\n",
      " [0.61587495]\n",
      " [0.59867024]\n",
      " [0.7929381 ]\n",
      " [0.86900985]\n",
      " [0.07354138]\n",
      " [0.77345103]\n",
      " [0.83916473]\n",
      " [0.83662766]\n",
      " [0.59982765]\n",
      " [0.45888412]\n",
      " [0.62752825]\n",
      " [0.93291515]\n",
      " [0.6198139 ]\n",
      " [0.72790784]\n",
      " [0.8195058 ]\n",
      " [0.8652497 ]\n",
      " [0.78289765]\n",
      " [0.54073024]\n",
      " [0.8136595 ]\n",
      " [0.9105378 ]\n",
      " [0.70883983]\n",
      " [0.9554184 ]\n",
      " [0.7876003 ]\n",
      " [0.62456065]\n",
      " [0.47115734]\n",
      " [0.8496032 ]\n",
      " [0.84695035]\n",
      " [0.52417123]\n",
      " [0.60591584]\n",
      " [0.14643562]\n",
      " [0.45842323]\n",
      " [0.81669873]\n",
      " [0.9455072 ]\n",
      " [0.8371505 ]\n",
      " [0.67055774]\n",
      " [0.75290257]\n",
      " [0.8936864 ]\n",
      " [0.56762505]\n",
      " [0.91147393]\n",
      " [0.6047313 ]\n",
      " [0.86596704]\n",
      " [0.25644153]\n",
      " [0.08677562]\n",
      " [0.23147702]\n",
      " [0.27064645]\n",
      " [0.7269992 ]\n",
      " [0.8187491 ]\n",
      " [0.68500805]\n",
      " [0.75438356]\n",
      " [0.8148611 ]\n",
      " [0.39592022]\n",
      " [0.32658163]\n",
      " [0.9419423 ]\n",
      " [0.90703255]\n",
      " [0.5126001 ]\n",
      " [0.7431728 ]\n",
      " [0.1307133 ]\n",
      " [0.33388042]\n",
      " [0.7502946 ]\n",
      " [0.7166628 ]\n",
      " [0.9141252 ]\n",
      " [0.9776372 ]\n",
      " [0.20353384]\n",
      " [0.7012502 ]\n",
      " [0.6255461 ]\n",
      " [0.4898979 ]\n",
      " [0.7331116 ]\n",
      " [0.7032694 ]\n",
      " [0.92250586]\n",
      " [0.6996778 ]\n",
      " [0.5145741 ]\n",
      " [0.64642817]\n",
      " [0.14848891]\n",
      " [0.67770773]\n",
      " [0.46103504]\n",
      " [0.9167587 ]\n",
      " [0.62181896]\n",
      " [0.5021443 ]\n",
      " [0.76693195]\n",
      " [0.7523984 ]\n",
      " [0.5334351 ]\n",
      " [0.77322495]\n",
      " [0.68744653]\n",
      " [0.39973223]\n",
      " [0.6500363 ]\n",
      " [0.87763876]\n",
      " [0.8908187 ]\n",
      " [0.55811536]\n",
      " [0.8087892 ]\n",
      " [0.24247576]\n",
      " [0.8661703 ]\n",
      " [0.62030685]\n",
      " [0.7103915 ]\n",
      " [0.43146703]\n",
      " [0.6322943 ]\n",
      " [0.8555326 ]\n",
      " [0.13416229]\n",
      " [0.24201657]\n",
      " [0.84564334]\n",
      " [0.8097662 ]\n",
      " [0.86365503]\n",
      " [0.94374007]\n",
      " [0.8206423 ]\n",
      " [0.6636301 ]\n",
      " [0.73760444]\n",
      " [0.8281616 ]\n",
      " [0.76422447]\n",
      " [0.8163542 ]\n",
      " [0.49582908]\n",
      " [0.38006577]\n",
      " [0.89775074]\n",
      " [0.7727741 ]\n",
      " [0.6182285 ]\n",
      " [0.25258705]\n",
      " [0.8763512 ]\n",
      " [0.8440711 ]\n",
      " [0.8765876 ]\n",
      " [0.62401336]\n",
      " [0.9274194 ]\n",
      " [0.9011715 ]\n",
      " [0.8377636 ]\n",
      " [0.39386702]\n",
      " [0.88680106]\n",
      " [0.9112166 ]\n",
      " [0.3241456 ]\n",
      " [0.11738712]\n",
      " [0.67708474]\n",
      " [0.50215507]\n",
      " [0.8412857 ]\n",
      " [0.28540292]\n",
      " [0.37958783]\n",
      " [0.42572728]\n",
      " [0.7643177 ]\n",
      " [0.89352286]\n",
      " [0.13471694]\n",
      " [0.3765799 ]\n",
      " [0.616661  ]\n",
      " [0.51290905]\n",
      " [0.5293846 ]\n",
      " [0.8343367 ]\n",
      " [0.14710289]\n",
      " [0.9107392 ]\n",
      " [0.19105284]\n",
      " [0.8352502 ]\n",
      " [0.6923152 ]\n",
      " [0.7940861 ]\n",
      " [0.7998671 ]\n",
      " [0.7412155 ]\n",
      " [0.9275265 ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] 0.770751\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cv, _ = sess.run([cost, train], feed_dict={x:xdata, y:ydata})\n",
    "        if step%200 == 0:\n",
    "            print(step, cv)\n",
    "    hv,pv,av = sess.run([hf, predicted, accuracy],\n",
    "                       feed_dict={x:xdata, y:ydata})\n",
    "    print(hv, pv, av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2353618095034279500]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
