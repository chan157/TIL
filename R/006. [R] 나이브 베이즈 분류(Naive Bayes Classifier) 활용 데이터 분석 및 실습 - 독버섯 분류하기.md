# [R] 나이브 베이즈 분류(Naive Bayes Classifier) 활용 데이터 분석 및 실습 - 독버섯 분류하기

R을 확용한 나이브 베이즈 분류기를 만들어 보겠습니다. 배우는 단계에서 기초적인 내용임을 사전에 알려드립니다. 데이터는 UCI의 공개데이터인 Mushroom를 csv파일로 배포된 것을 사용하였습니다.



## 1. 라이브러리 

```R
library(gmodels)
library(e1071)
```

사용한 라이브러리는 위의 두 개입니다. `e1071`은 나이브 베이즈 분류기를 사용하기 위해서 불러왔습니다. 그 외에도 다양한 머신러닝 알고리즘이 들어있다고 합니다. `gmodels`는 평가할 때, `CrossTable`을 사용해서 평가하기 위해서 불러왔습니다. 



## 2. 데이터 확인하기

```R
mushroom <- read.csv('Data/dataset_for_ml/mushrooms.csv')
names(mushroom)
str(mushroom)
dim(mushroom)
```

데이터를 가져온 후 structure와 dimention을 확인합니다. `names`함수를 사용해서 열에는 어떤 것들이 있는지 확인해봅니다.

![image-20200211180744382](C:\Users\Administrator\Desktop\TIL\R\images\2020.02.11.0001.png)

열의 구분이 상당히 많은 것을 확인할 수 있습니다. 각 feature들이 어떤 상태인지 확인이 필요합니다.



```R
colSums(is.na(mushroom))
```

`N/A` 결측치가 있는지 확인해봅니다. 

![image-20200211180944330](C:\Users\Administrator\Desktop\TIL\R\images\2020.02.11.0002.png)

결측치가 전혀 없습니다. 더 불안해집니다. 각 열에 어떤 factor들로 분류되어있는지 확인해봐야합니다.



```R
name <- names(mushroom)
for(i in 1:length(name)){
  print(name[i])
  print(table(mushroom[name[i]]))
}
```

모든 Col에 table 함수를 적용해서 그 결과를 출력해 확인하도록 합니다.

![image-20200211181301872](C:\Users\Administrator\Desktop\TIL\R\images\2020.02.11.0003.png)

위와 같은 방식으로 결과를 확인할 수 있습니다. 독버섯 여부를 판단하기 위한 label값, 정답은 `type`열에 있습니다. `odor`열의 `none`는 결측값을 표현하는 `N/A`같은 값이 아닌 ''맛이 없는', 'No taste' 정도로 쓰인 것으로 보입니다. 

데이터를 전체적으로 살펴봤는데 특별한 문제는 없어 보입니다. `none`범주가 몇 개 더 확인되었는데, 값이 없는 것이 아닌 해당 특징이 없는 것을 표현한 것으로 보여서 그대로 두었습니다. 

일부의 특정 범주들은 해당되는 값이 매우 미미해서 그런 부분까지 잘 잡아낼 수 있을지 조금 걱정되는 정도입니다.



## 3. 데이터 나누기

```R
# 8124 행
train <- mushroom[1:6500,-1]
test <- mushroom[6501:8124,-1]
train_labels <- mushroom[1:6500,1]
test_labels <- mushroom[6501:8124,1]
```

train data와 test data를 80대 20 비율로 나누었습니다. 또한, feature와 label도 나누어주었습니다.



## 4. 나이브 베이즈 분류 적용

```R
# 모델/분류기 생성
mushroom_classifier <- naiveBayes(train, train_labels, laplace = 1)
# test 데이터 예측
m_pred <- predict(mushroom_classifier, test)
# CrossTable 확인 및 정답률 확인
CrossTable(m_pred, test_labels)
print(sum(m_pred==test_labels)*100/length(m_pred))
>> 92.42611%
```

test 데이터에 모델을 적용해서 분석해 보았습니다. 92.42%의 정답률을 확인했습니다. 

![image-20200211183317820](C:\Users\Administrator\Desktop\TIL\R\images\2020.02.11.0004.png)

예측값과 실제 정답을 비교하는 `CrossTable`입니다. `edible`인데 `poisonous`라고 판단한 비율이 `poisonous`인데 `edibe`로 판단한 경우보다 더 높은 것을 확인할 수 있습니다. 



## 5. 학습 데이터 비율에 따른 변화

```R
n <- nrow(mushroom) # 행 개수
result <- c(0,0,0,0,0,0,0,0,0,0) # 빈칸
for(i in 1:10){
x <- round(n*i/10)
train <- mushroom[1:x,-1]
test <- mushroom[x:n,-1]
train_labels <- mushroom[1:x,1]
test_labels <- mushroom[x:n,1]

mushroom_classifier <- naiveBayes(train, train_labels, laplace = 1)
m_pred <- predict(mushroom_classifier, test)
result[i] <- sum(m_pred==test_labels)*100/length(m_pred)
}
# 결과물
> result
 [1]  70.08068  44.78462  65.17229  79.63077  81.86069  87.75761  91.79655
 [8]  92.43542  97.29397 100.00000
```

10% ~ 100% 까지 train data의 비율을 바꿔가면서 분류기를 만들었을 때 어떻게 결과가 바뀌는지 확인했습니다. 너무 적어도 많아도 문제입니다. train 데이터를 90% 100%에 해당하는 값은 overfitting될 확률이 매우 높으므로 역시 고전적으로 많이 쓰는 80%가 가장 적절한 것 같습니다.



지금까지 나이브베이즈분류(Naive Bayes Classifier)를 사용하여 독버섯 분류를 진행하였습니다. 다음 시간에는 나이브 베이즈 분류를 사용한 텍스트 분석을 진행해보겠습니다. 